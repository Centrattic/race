{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46ab1310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 2.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.24.2)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.60.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.5.4)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (2.1.0)\n",
      "Installing collected packages: skorch\n",
      "Successfully installed skorch-0.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4266ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.morphology import skeletonize\n",
    "from PIL import Image\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import LRScheduler, Checkpoint, EpochScoring, EarlyStopping\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df435fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3319940e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_69 (ZeroPadding2 (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_69[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_70 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_70[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_71 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_71[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_72 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_72[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_73 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_73[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_74 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_74[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_75 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_75[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_76 (ZeroPadding2 (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_76[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_77 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_77[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_78 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_78[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_79 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_79[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_80 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_80[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_81 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_81[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_82 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_82[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_83 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_83[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_84 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_84[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_85 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_85[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_86 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_86[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_87 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_87[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_88 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_88[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_89 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_89[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 16, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_90 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_90[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_91 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_91[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 16, 16, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_92[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_93[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 16, 16, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_94[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_95[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 16, 16, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_96[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_97[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_98[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_99[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_100[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_101[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 8, 8, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_logits (Dense)            (None, 2)            1026        global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 2)            0           dense_logits[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 21,303,499\n",
      "Trainable params: 21,288,133\n",
      "Non-trainable params: 15,366\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "segmentation_classifier = keras.models.load_model('models/MIMIC-256x25680-20-split-resnet-Float16_2-race_detection_rop_seg_data_rop_seg-0.001_20220321-054140_epoch:011.hdf5')\n",
    "segmentation_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "82673a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in one place, running in another directory\n",
    "# code is to be run in below directory\n",
    "\n",
    "os.chdir(\"/users/riya/race/classifier_experiments/CNN_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508e656",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "We'll try a 70/10/20 split (train/val/test). We don't have access to info outside of black/white, so we'll just do a simple split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff75c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "743e8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    \n",
    "    csv_path = \"/users/riya/race/csv/image_race_data.csv\"\n",
    "    data_path = \"/users/riya/race/dataset/segmentations/\"\n",
    "    save_path = \"/users/riya/race/classifier_experiments/CNN_train/dataset/\"\n",
    "    \n",
    "    race_data = pd.read_csv(csv_path)\n",
    "    race_data['stratify'] = race_data['race'] + '_' + race_data['variable'] \n",
    "    # new column so I can account for both variable and race in my stratification\n",
    "    \n",
    "    ratio_train = 0.7\n",
    "    ratio_val = 0.1\n",
    "    ratio_test = 0.2\n",
    "    \n",
    "    # split into 80% train and val, 20% test\n",
    "    \n",
    "    X_intermediate, X_test, y_intermediate, y_test = train_test_split(race_data, race_data['race'], test_size=ratio_test, \n",
    "                                                        stratify = race_data['stratify'], random_state=86)\n",
    "    \n",
    "    ratio_remaining = 1 - ratio_test\n",
    "    ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "    \n",
    "    # split into 70% train and 10% val\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_intermediate, X_intermediate['race'], test_size=ratio_val_adjusted, \n",
    "                                                        stratify = X_intermediate['stratify'], random_state=86)\n",
    "\n",
    "    \n",
    "    def populate_folders(data_df, data_type):\n",
    "    \n",
    "        for i in tqdm(range(len(data_df))):\n",
    "            data_df.reset_index(drop=True, inplace=True)\n",
    "            img_id = data_df['image_id'][i]\n",
    "            race = data_df['race'][i]\n",
    "\n",
    "            img = np.array(Image.open(data_path + str(img_id) + '.bmp'))\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "            img.save(save_path + str(data_type) + '/' + str(race) + '/' + str(img_id) + '.bmp')\n",
    "    \n",
    "    populate_folders(X_train, 'train')\n",
    "    populate_folders(X_val, 'val')\n",
    "    populate_folders(X_test, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ce2fd112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3181/3181 [00:23<00:00, 137.97it/s]\n",
      "100%|██████████| 455/455 [00:04<00:00, 113.36it/s]\n",
      "100%|██████████| 910/910 [00:08<00:00, 112.69it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48857f",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edec98",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8e3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already done this, before I saved my images\n",
    "# Yay, we did the same thing, repeating the image thrice to create the three layers. I can just do that part.\n",
    "\n",
    "# Oh, I see. Rather than saving ALL the images (as I wrongly did), it's so much easier to just make them in the train code!\n",
    "\n",
    "# depending on the inputs, I can run this code 8 times to train this model. It'll be easy to train at that point!\n",
    "\n",
    "def shadow_regions(img, skeleton, shadow, radius, region, image_size = (224, 224)):\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img = cv2.resize(img, image_size)\n",
    "\n",
    "    if skeleton is True:\n",
    "        img[img > 0] = 255\n",
    "        img = skeletonize(img, method='lee')\n",
    "    \n",
    "    if shadow is True:\n",
    "        # developing mask that darkens center portion\n",
    "        center_mask = np.full(image_size, 255, dtype=np.uint8) \n",
    "        # radius i changes, center, color, fill is the same\n",
    "        cv2.circle(center_mask, (image_size[0]/2, image_size[0]/2), radius, (0, 0, 0), -1)\n",
    "\n",
    "        # developing mask that darkens background region\n",
    "        back_mask = cv2.bitwise_not(center_mask)\n",
    "\n",
    "        if (region == 'dark_center'):\n",
    "            img = cv2.bitwise_or(img, img, mask=center_mask)\n",
    "\n",
    "        if (region == 'dark_background'):\n",
    "            img = cv2.bitwise_or(img, img, mask=back_mask)\n",
    "\n",
    "    img = np.repeat(img[:, :, np.newaxis], 3, axis=2).reshape((image_size[0],image_size[1],3)) # (1, 224, 224, 3)?\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18edef64",
   "metadata": {},
   "source": [
    "Options for different saving:\n",
    "1. Skeleton = True,\n",
    "    Shadow = True then\n",
    "    Region has two options \n",
    "    Radius has two options\n",
    "2. Original Training: shadow = False & Skeleton = False\n",
    "3. no skeletonization training: Skeleton = false & Shadow = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9a2c58c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-74c29ca2dbb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/users/riya/race/classifier_experiments/CNN_train/dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m    145\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "val_folder = os.path.join(\"/users/riya/race/classifier_experiments/CNN_train/dataset\", 'val')\n",
    "val_dataset = datasets.ImageFolder(val_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "093cd871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\t    19757.bmp  31240.bmp  44765.bmp  7394.bmp\t85889.bmp  96156.bmp\r\n",
      "..\t    19760.bmp  31330.bmp  45047.bmp  74081.bmp\t87358.bmp  96175.bmp\r\n",
      "101724.bmp  19761.bmp  31335.bmp  45050.bmp  74085.bmp\t87402.bmp  96239.bmp\r\n",
      "101738.bmp  19767.bmp  31338.bmp  45253.bmp  7419.bmp\t87406.bmp  96248.bmp\r\n",
      "101915.bmp  19768.bmp  31339.bmp  45258.bmp  74709.bmp\t87411.bmp  96257.bmp\r\n",
      "101921.bmp  24132.bmp  31341.bmp  45262.bmp  74711.bmp\t87432.bmp  96631.bmp\r\n",
      "105469.bmp  24133.bmp  33987.bmp  45267.bmp  74723.bmp\t88464.bmp  96635.bmp\r\n",
      "105646.bmp  25503.bmp  34075.bmp  45283.bmp  74727.bmp\t88762.bmp  96850.bmp\r\n",
      "105655.bmp  25506.bmp  34424.bmp  45286.bmp  74883.bmp\t91925.bmp  96859.bmp\r\n",
      "105667.bmp  25804.bmp  35273.bmp  45340.bmp  75661.bmp\t91929.bmp  96870.bmp\r\n",
      "107480.bmp  25813.bmp  37053.bmp  47256.bmp  75667.bmp\t91946.bmp  96979.bmp\r\n",
      "112614.bmp  25815.bmp  37988.bmp  47275.bmp  75669.bmp\t91951.bmp  96982.bmp\r\n",
      "112616.bmp  25822.bmp  37993.bmp  49165.bmp  75670.bmp\t91964.bmp  96983.bmp\r\n",
      "16522.bmp   25835.bmp  38456.bmp  49200.bmp  76793.bmp\t92605.bmp  96990.bmp\r\n",
      "17362.bmp   25837.bmp  39425.bmp  49215.bmp  76803.bmp\t92750.bmp  98033.bmp\r\n",
      "17363.bmp   25840.bmp  39426.bmp  49235.bmp  76804.bmp\t92753.bmp  98035.bmp\r\n",
      "17378.bmp   26905.bmp  39429.bmp  50957.bmp  77042.bmp\t92766.bmp  98117.bmp\r\n",
      "17390.bmp   27317.bmp  39538.bmp  50961.bmp  77045.bmp\t92797.bmp  98138.bmp\r\n",
      "17395.bmp   28452.bmp  39545.bmp  50980.bmp  77083.bmp\t92805.bmp  98269.bmp\r\n",
      "17400.bmp   29436.bmp  39563.bmp  55209.bmp  77094.bmp\t93153.bmp  98270.bmp\r\n",
      "18845.bmp   29972.bmp  42174.bmp  58294.bmp  77112.bmp\t93762.bmp  98319.bmp\r\n",
      "18849.bmp   29990.bmp  42180.bmp  58296.bmp  79778.bmp\t93763.bmp  98328.bmp\r\n",
      "18850.bmp   30028.bmp  44655.bmp  60175.bmp  80925.bmp\t93770.bmp\r\n",
      "18853.bmp   30055.bmp  44745.bmp  62396.bmp  83854.bmp\t9477.bmp\r\n",
      "19754.bmp   31006.bmp  44758.bmp  65504.bmp  83875.bmp\t95299.bmp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a dataset/val/black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f437406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  dataset\toutputs\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c0872e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dataset/val/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "98ff4485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6369c70",
   "metadata": {},
   "source": [
    "### Train Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da875db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, skeleton=False, shadow = False, radius, region, num_classes=2, batch_size=64, num_epochs=10, lr=0.001):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda:0':\n",
    "        torch.cuda.empty_cache()\n",
    "    if skeleton is True: # Experiment #2: skeleton true, shadow true\n",
    "        shadow = True\n",
    "        f_params = f'./outputs/checkpoints/model_shadow_regions_{region}_{radius}_skeletonized.pt'\n",
    "        f_history = f'./outputs/histories/model_shadow_regions_{region}_{radius}_skeletonized.json'\n",
    "        csv_name = f'./outputs/probabilities/shadow_regions_{region}_{radius}_skeletonized.csv'\n",
    "    elif shadow is True: # Experiment #3: skeleton false, shadow true\n",
    "        f_params = f'./outputs/checkpoints/model_shadow_regions_{region}_{radius}.pt'\n",
    "        f_history = f'./outputs/histories/model_shadow_regions_{region}_{radius}.json'\n",
    "        csv_name = f'./outputs/probabilities/shadow_regions_{region}_{radius}.csv'\n",
    "    else: # Original training: skeleton false, shadow false\n",
    "        f_params = f'./outputs/checkpoints/model_original.pt'\n",
    "        f_history = f'./outputs/histories/model_original.json'\n",
    "        csv_name = f'./outputs/probabilities/original.csv'\n",
    "        \n",
    "    train_transforms = transforms.Compose([transforms.Lambda(lambda img: filter(img, skeleton,\n",
    "                                                                                shadow, radius,\n",
    "                                                                                region)), # image size pre-defined\n",
    "                                           # transforms.Resize(image_size),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.RandomVerticalFlip(),\n",
    "                                           transforms.RandomRotation(25),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                                [0.5, 0.5, 0.5])]) # why this normalizing?\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.Lambda(lambda img: filter(img, skeleton,\n",
    "                                                                                shadow, radius,\n",
    "                                                                                region)),\n",
    "                                          # transforms.Resize(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                               [0.5, 0.5, 0.5])])\n",
    "\n",
    "    train_folder = os.path.join(data_dir, 'train') # only training on segmentations      \n",
    "    val_folder = os.path.join(data_dir, 'val')\n",
    "    test_folder = os.path.join(data_dir, 'test')\n",
    "\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(train_folder, train_transforms)\n",
    "    val_dataset = datasets.ImageFolder(val_folder, test_transforms)\n",
    "    test_dataset = datasets.ImageFolder(test_folder, test_transforms)\n",
    "\n",
    "    \n",
    "    labels = np.array(train_dataset.samples)[:,1]\n",
    "    \n",
    "    # what even does the below code do?    \n",
    "    labels = labels.astype(int)\n",
    "    black_weight = 1 / len(labels[labels == 0])\n",
    "    white_weight = 1 / len(labels[labels == 1])\n",
    "    sample_weights = np.array([black_weight, white_weight])\n",
    "    weights = sample_weights[labels]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
    "\n",
    "    print()\n",
    "    print(f'Data Directory: {data_dir}')\n",
    "    print(f'Image Type: {image_type}')\n",
    "    print(f'Threshold: {threshold}')\n",
    "    print(f'Binarize: {binary}')\n",
    "    print(f'Skeletonize: {skeleton}')\n",
    "    print(f'Number of Classes: {num_classes}')\n",
    "    print(f'Number of black eyes: {len(labels[labels == 0])}')\n",
    "    print(f'Number of white eyes: {len(labels[labels == 1])}')\n",
    "    print(f'Batch Size: {batch_size}')\n",
    "    print(f'Number of Epochs: {num_epochs}')\n",
    "    print(f'Initial Learning Rate: {lr}')\n",
    "    print(f'Device: {device}')\n",
    "    print()\n",
    "\n",
    "    checkpoint = Checkpoint(monitor='valid_loss_best',\n",
    "                            f_params=f_params,\n",
    "                            f_history=f_history,\n",
    "                            f_optimizer=None,\n",
    "                            f_criterion=None)\n",
    "\n",
    "    train_acc = EpochScoring(scoring='accuracy',\n",
    "                             on_train=True,\n",
    "                             name='train_acc',\n",
    "                             lower_is_better=False)\n",
    "\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    callbacks = [checkpoint, train_acc, early_stopping]\n",
    "\n",
    "    net = NeuralNetClassifier(PretrainedModel,\n",
    "                              criterion=nn.CrossEntropyLoss,\n",
    "                              lr=lr,\n",
    "                              batch_size=batch_size,\n",
    "                              max_epochs=num_epochs,\n",
    "                              module__output_features=num_classes,\n",
    "                              optimizer=optim.SGD,\n",
    "                              optimizer__momentum=0.9,\n",
    "                              iterator_train__num_workers=16,\n",
    "                              iterator_train__sampler=sampler,\n",
    "                              iterator_valid__shuffle=False,\n",
    "                              iterator_valid__num_workers=16,\n",
    "                              train_split=predefined_split(val_dataset),\n",
    "                              callbacks=callbacks,\n",
    "                              device=device)\n",
    "\n",
    "    net.fit(train_dataset, y=None)\n",
    "\n",
    "    img_locs = [loc for loc, _ in test_dataset.samples]\n",
    "    test_probs = net.predict_proba(test_dataset)\n",
    "    test_probs = [prob[0] for prob in test_probs]\n",
    "    data = {'img_loc' : img_locs, 'probability' : test_probs}\n",
    "    pd.DataFrame(data=data).to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e84d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_classification(img_id, img_path, race, radius):\n",
    "    \n",
    "    if (radius != None):\n",
    "        img = Image.open(img_path + str(race) + '/' + str(radius) + '/' + str(img_id) + '.bmp')\n",
    "    else: # case of original images\n",
    "        img = Image.open(img_path + str(img_id) + '.bmp')\n",
    "        \n",
    "    arr = np.array(img)\n",
    "    channels = np.repeat(resized[:, :, np.newaxis], 3, axis=2).reshape((1,256,256,3))\n",
    "    \n",
    "    return channels\n",
    "\n",
    "# will replace this with train transforms from monai as Aaron did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16603297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(data, img_path, race, radius):\n",
    "    \n",
    "    img_arr = np.zeros([1, 256, 256, 3], dtype='int')\n",
    "\n",
    "    for i in tqdm(range(len(data))):\n",
    "        img_id = data['image_id'][i] # because of this, predictions are in the right order, IMPORTANT\n",
    "        # original preds\n",
    "        img_prepared = prepare_for_classification(img_id, img_path, race, radius)\n",
    "        img_arr = np.concatenate((img_arr, img_prepared), axis = 0)\n",
    "        \n",
    "    img_arr = img_arr[1:] # removing the unnecessary first element\n",
    "    \n",
    "    return img_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
