{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cc1365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.60.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.24.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.9)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (2.1.0)\n",
      "Installing collected packages: skorch\n",
      "Successfully installed skorch-0.11.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "896ce793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmdnn\n",
      "  Downloading mmdnn-0.3.1-py2.py3-none-any.whl (318 kB)\n",
      "     |████████████████████████████████| 318 kB 2.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn) (1.19.5)\n",
      "Requirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.6/dist-packages (from mmdnn) (8.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn) (1.15.0)\n",
      "Installing collected packages: mmdnn\n",
      "Successfully installed mmdnn-0.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mmdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762b1823",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp36-cp36m-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1982.2 MB 4.1 kB/s eta 0:00:011  |█                               | 61.6 MB 8.6 MB/s eta 0:03:44     |█████▌                          | 342.8 MB 10.5 MB/s eta 0:02:36     |██████████████████████▌         | 1393.1 MB 9.6 MB/s eta 0:01:02     |█████████████████████████████▉  | 1847.7 MB 8.6 MB/s eta 0:00:16\n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp36-cp36m-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.6 MB 144 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.8.0+cu111) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.9.0+cu111) (8.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0.dev20210415+cu101\n",
      "    Uninstalling torch-1.9.0.dev20210415+cu101:\n",
      "      Successfully uninstalled torch-1.9.0.dev20210415+cu101\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.10.0.dev20210510+cu101\n",
      "    Uninstalling torchvision-0.10.0.dev20210510+cu101:\n",
      "      Successfully uninstalled torchvision-0.10.0.dev20210510+cu101\n",
      "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d58d43cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "     |████████████████████████████████| 458.3 MB 16 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.46.3)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (5.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.17.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (56.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (1.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow-gpu) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (4.0.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (1.26.4)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (0.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow-gpu) (3.4.1)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-gpu\n",
      "    Found existing installation: tensorflow-gpu 2.5.0\n",
      "    Uninstalling tensorflow-gpu-2.5.0:\n",
      "      Successfully uninstalled tensorflow-gpu-2.5.0\n",
      "Successfully installed tensorflow-gpu-2.6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "27bacb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "     |████████████████████████████████| 458.3 MB 16 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.17.0)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 31.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 38.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 38.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.46.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "     |████████████████████████████████| 4.4 MB 40.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (56.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.30.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.1)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30693 sha256=f1854b277822580858432aebb70fc38e7977469ffdb500e60342f16871f35570\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "Successfully built clang\n",
      "Installing collected packages: grpcio, tensorflow-estimator, tensorboard, keras, gast, clang, tensorflow\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.46.3 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed clang-5.0 gast-0.4.0 grpcio-1.46.3 keras-2.6.0 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1888ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.morphology import skeletonize\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import LRScheduler, Checkpoint, EpochScoring, EarlyStopping\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5d3557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 12 04:18:32 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K80           Off  | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   24C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla K80           Off  | 00000000:85:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla K80           Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   24C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "893038fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/experimental/loss_scale.py:208: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_69 (ZeroPadding2 (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_69[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_70 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_70[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_71 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_71[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_72 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_72[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_73 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_73[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_74 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_74[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_75 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_75[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_76 (ZeroPadding2 (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_76[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_77 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_77[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_78 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_78[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_79 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_79[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_80 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_80[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_81 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_81[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_82 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_82[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_83 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_83[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_84 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_84[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_85 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_85[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_86 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_86[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_87 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_87[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_88 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_88[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_89 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_89[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 16, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_90 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_90[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_91 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_91[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 16, 16, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_92[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_93[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 16, 16, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_94[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_95[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 16, 16, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_96[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_97[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_98[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_99[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_100[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_101[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 8, 8, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_logits (Dense)            (None, 2)            1026        global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 2)            0           dense_logits[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 21,303,499\n",
      "Trainable params: 21,288,133\n",
      "Non-trainable params: 15,366\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "segmentation_classifier = keras.models.load_model('../models/MIMIC-256x25680-20-split-resnet-Float16_2-race_detection_rop_seg_data_rop_seg-0.001_20220321-054140_epoch:011.hdf5')\n",
    "segmentation_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ce96a050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 480, 480) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 32, 480, 480) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_2 (BatchNormalization)    (None, 32, 480, 480) 128         conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_3 (Dropout)               (None, 32, 480, 480) 0           conv1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_4 (Conv2D)                (None, 32, 480, 480) 9248        conv1_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_5 (BatchNormalization)    (None, 32, 480, 480) 128         conv1_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_6 (MaxPooling2D)          (None, 32, 240, 240) 0           conv1_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 64, 240, 240) 18496       conv1_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2 (BatchNormalization)    (None, 64, 240, 240) 256         conv2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3 (Dropout)               (None, 64, 240, 240) 0           conv2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_4 (Conv2D)                (None, 64, 240, 240) 36928       conv2_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_5 (BatchNormalization)    (None, 64, 240, 240) 256         conv2_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_6 (MaxPooling2D)          (None, 64, 120, 120) 0           conv2_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1 (Conv2D)                (None, 64, 120, 120) 36928       conv2_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2 (BatchNormalization)    (None, 64, 120, 120) 256         conv3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3 (Dropout)               (None, 64, 120, 120) 0           conv3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4 (Conv2D)                (None, 64, 120, 120) 36928       conv3_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_5 (BatchNormalization)    (None, 64, 120, 120) 256         conv3_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_6 (MaxPooling2D)          (None, 64, 60, 60)   0           conv3_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1 (Conv2D)                (None, 64, 60, 60)   36928       conv3_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2 (BatchNormalization)    (None, 64, 60, 60)   256         conv4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3 (Dropout)               (None, 64, 60, 60)   0           conv4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4 (Conv2D)                (None, 64, 60, 60)   36928       conv4_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5 (BatchNormalization)    (None, 64, 60, 60)   256         conv4_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6 (MaxPooling2D)          (None, 64, 30, 30)   0           conv4_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1 (Conv2D)                (None, 64, 30, 30)   36928       conv4_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2 (BatchNormalization)    (None, 64, 30, 30)   256         conv5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3 (Dropout)               (None, 64, 30, 30)   0           conv5_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_4 (Conv2D)                (None, 64, 30, 30)   36928       conv5_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_5 (BatchNormalization)    (None, 64, 30, 30)   256         conv5_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 60, 60)   0           conv5_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 60, 60)  0           conv4_5[0][0]                    \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 60, 60)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 60, 60)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 60, 60)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 60, 60)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 60, 60)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 120, 120) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 120, 120 0           conv3_5[0][0]                    \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 120, 120) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 120, 120) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 120, 120) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 120, 120) 36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 120, 120) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 240, 240) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 240, 240 0           conv2_5[0][0]                    \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 240, 240) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 240, 240) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 240, 240) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 240, 240) 36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 240, 240) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 480, 480) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 480, 480) 0           conv1_5[0][0]                    \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 480, 480) 27680       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 480, 480) 128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 480, 480) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 480, 480) 9248        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 480, 480) 128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1, 480, 480)  33          batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 480, 480)  4           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 480, 480)  0           batch_normalization_9[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 659,781\n",
      "Trainable params: 657,731\n",
      "Non-trainable params: 2,050\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# log dice loss is custom, so can't load. but since I only want inference, will ignore the loss func. (might have to retrain?)\n",
    "\n",
    "optic_disk = load_model('../models/optic_disk/aug_segmenter_adam3_best_weights.h5', compile=False) # failed :(\n",
    "optic_disk.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "473519b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_assurance = load_model('../models/quality_assurance/IQA_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "db71fbf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 74, 74, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 74, 74, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 32)   9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 32)   96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 32)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 72, 72, 64)   18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 72, 72, 64)   192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 72, 72, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 35, 35, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 35, 35, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 33, 33, 192)  138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 33, 33, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 33, 33, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 96)   82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 96)   82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 96)   82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 16, 16, 96)   55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 96)     82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 7, 7, 384)    1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 96)     288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 7, 7, 384)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 96)     0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 128)    114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 128)    114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 128)    384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 128)    384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 128)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 128)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 192)    172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 192)    576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 192)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 160)    179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 160)    179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 160)    480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 160)    480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 160)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 160)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 192)    215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 192)    576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 192)    576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 192)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 192)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 160)    179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 160)    179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 160)    480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 160)    480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 160)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 160)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 192)    215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 192)    576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 192)    576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 192)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 192)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 7, 7, 192)    258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 7, 7, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 7, 7, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 7, 7, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 7, 7, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 3, 3, 320)    552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 192)    331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 3, 3, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 3, 3, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 448)    1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 448)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 384)    1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 384)    1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 320)    960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 384)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 384)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 320)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 1)            37752833    mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 59,555,617\n",
      "Trainable params: 59,521,185\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qual_assurance.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509dbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in one place, running in another directory\n",
    "# code is to be run in below directory\n",
    "\n",
    "os.chdir(\"/users/riya/race/classifier_experiments/CNN_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaeced42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset  outputs\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04430e9",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b2cce",
   "metadata": {},
   "source": [
    "### Prepare Optic Disk Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9983772",
   "metadata": {},
   "source": [
    "Code in Markdown form (don't run again!)\n",
    "\n",
    "```python\n",
    "# will generate a csv of all the centers of the optic disks per id, this will speed up classification \n",
    "    \n",
    "csv_path = \"/users/riya/race/csv/image_race_data.csv\" \n",
    "data_path = \"/users/riya/race/dataset/fundus/\" # takes in fundus images\n",
    "save_path = \"/users/riya/race/optic_disk/DeepROP/dataset/\" \n",
    "\n",
    "# 1. Copy DeepROP folder into \n",
    "# 2. get all the fundus images into DeepROP folder in the dataset location, just copy from data_path \n",
    "# 3. run the DeepROP folder using docker. Use docker mount. Get the output\n",
    "# 4. Save the .csv. \n",
    "# 5. Extract image id from full path column and create new image id column. Save the .csv and now you can use that.\n",
    "    \n",
    "# 1 Done\n",
    "# 2\n",
    "\n",
    "# getting all the files in the source directory\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "for i in files:\n",
    "    img_id = os.path.splitext(i)[0]\n",
    "    img = Image.open(data_path + img_id + \".png\")\n",
    "    img.save(save_path + img_id + \".bmp\") \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270716f",
   "metadata": {},
   "source": [
    "### Prepare Race Dataset\n",
    "\n",
    "We'll try a 70/10/20 split (train/val/test). We don't have access to info outside of black/white and posterior, so we'll just do a simple split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_data = pd.read_csv(\"/users/riya/race/csv/image_race_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ebf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(race_data['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441258f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1cbdcd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    \n",
    "    csv_path = \"/users/riya/race/csv/image_race_data.csv\"\n",
    "    data_path = \"/users/riya/race/dataset/segmentations/\"\n",
    "    save_path = \"/users/riya/race/classifier_experiments/CNN_train/dataset/\"\n",
    "    QA_csv_path = \"../optic_disk/DeepROP/quality_assurance/QA.csv\"\n",
    "    \n",
    "    race_data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # only choose race_data ids that have (x,y) coordinates\n",
    "    \n",
    "    QA_csv = pd.read_csv(QAcsv_path)\n",
    "    QA_csv.columns.values[0] = \"img_id\"\n",
    "    QA_csv.columns = QA_csv.columns.to_series().apply(lambda x: x.strip())\n",
    "    QA_csv[['img_id', 'Full path', 'x', 'y', 'is_posterior']]\n",
    "    \n",
    "    is_posterior_True = QA_csv[QA_csv['is_posterior'] == True]\n",
    "    working_ids = np.array(is_posterior_True['img_id'])\n",
    "    \n",
    "    race_optic_data = pd.DataFrame(columns = ['subject_id', 'race', 'variable', 'value', \n",
    "                                          'image_id', 'fundus_location', 'segmentation_location'])\n",
    "\n",
    "    for i in range(len(race_data)):\n",
    "        row = race_data.loc[(i)]\n",
    "        if row['image_id'] in working_ids:\n",
    "            race_optic_data = race_optic_data.append(row)\n",
    "    \n",
    "    race_data = race_optic_data # reassign original\n",
    "    \n",
    "    race_data['stratify'] = race_data['race'] + '_' + race_data['variable'] \n",
    "    # new column so I can account for both variable and race in my stratification\n",
    "    \n",
    "    ratio_train = 0.7\n",
    "    ratio_val = 0.1\n",
    "    ratio_test = 0.2\n",
    "    \n",
    "    # split into 80% train and val, 20% test\n",
    "    \n",
    "    X_intermediate, X_test, y_intermediate, y_test = train_test_split(race_data, race_data['race'], test_size=ratio_test, \n",
    "                                                        stratify = race_data['stratify'], random_state=86)\n",
    "    \n",
    "    ratio_remaining = 1 - ratio_test\n",
    "    ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "    \n",
    "    # split into 70% train and 10% val\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_intermediate, X_intermediate['race'], test_size=ratio_val_adjusted, \n",
    "                                                        stratify = X_intermediate['stratify'], random_state=86)\n",
    "\n",
    "    \n",
    "    def populate_folders(data_df, data_type):\n",
    "    \n",
    "        for i in tqdm(range(len(data_df))):\n",
    "            data_df.reset_index(drop=True, inplace=True)\n",
    "            img_id = data_df['image_id'][i]\n",
    "            race = data_df['race'][i]\n",
    "\n",
    "            img = np.array(Image.open(data_path + str(img_id) + '.bmp'))\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "            img.save(save_path + str(data_type) + '/' + str(race) + '/' + str(img_id) + '.bmp')\n",
    "    \n",
    "    populate_folders(X_train, 'train')\n",
    "    populate_folders(X_val, 'val')\n",
    "    populate_folders(X_test, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "478d3a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2359/2359 [00:15<00:00, 156.83it/s]\n",
      "100%|██████████| 337/337 [00:02<00:00, 160.54it/s]\n",
      "100%|██████████| 675/675 [00:04<00:00, 156.43it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset() # proper train test split getting completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22853a22",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5662523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "35d61db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fail :( class OpticDiskSegmenter(nn.Module):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e1c42",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678e451",
   "metadata": {},
   "source": [
    "Options for different tests:\n",
    "1. Skeleton = True,\n",
    "    Shadow = True then\n",
    "    Region has two options \n",
    "    Radius has two options\n",
    "2. Original Training: shadow = False & Skeleton = False\n",
    "3. skeletonization training: shadow = False & skeleton = True & ring = False\n",
    "4. no skeletonization training: Skeleton = false & Shadow = true\n",
    "5. training with a ring: shadow is true, skeleton is true/False, ring is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "38f04d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello.bmp.bmp'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello.bmp' + '.bmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3d155",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "86cf2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3371"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checksum_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2139cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checksum(optic_csv_path):\n",
    "    \n",
    "    # Turns out that around 31 of the images are actual duplicates! I looked at 10 and saw that they were \n",
    "    # (or VERY close to duplicates), with difference image having very few nonzero pixels\n",
    "    # Checksum is getting the best of it, then.\n",
    "    \n",
    "    checksum_arr = []\n",
    "    id_arr = []\n",
    "\n",
    "    # optic_csv_path = \"../../optic_disk/DeepROP/quality_assurance/QA.csv\"\n",
    "    data_compare_path = \"/users/riya/race/dataset/segmentations/\"\n",
    "\n",
    "    QA_csv = pd.read_csv(optic_csv_path)\n",
    "\n",
    "    QA_csv.columns.values[0] = \"img_id\"\n",
    "    QA_csv.columns = QA_csv.columns.to_series().apply(lambda x: x.strip())\n",
    "    QA_csv[['img_id', 'Full path', 'x', 'y', 'is_posterior']]\n",
    "\n",
    "    QA_csv = QA_csv[QA_csv['is_posterior'] == True]\n",
    "\n",
    "    for i in tqdm(QA_csv['img_id']):\n",
    "        img_compare = np.array(Image.open(data_compare_path + str(i) + '.bmp'))\n",
    "        all_sum = np.concatenate(img_compare).sum()\n",
    "        col_sum = img_compare[:,100:240].sum()\n",
    "        \n",
    "        checksum_arr.append(all_sum + col_sum)\n",
    "        id_arr.append(i)\n",
    "    \n",
    "    checksum_dict = {id_arr[i]: checksum_arr[i] for i in range(len(id_arr))}\n",
    "    \n",
    "    return QA_csv, checksum_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275acf7b",
   "metadata": {},
   "source": [
    "### Functions to be Lamda Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a347a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_image_center(img, img_size, QA_csv, checksum_dict): # using optic disk\n",
    "    \n",
    "    id_og = '' # original id of image, for comparison\n",
    "    \n",
    "    img_og = np.array(img) # our original image\n",
    "    img_og = img_og[:,:,0]\n",
    "    \n",
    "    checksum_og = np.concatenate(img_og).sum() + img_og[:,100:240].sum()\n",
    "    \n",
    "    id_og = list(checksum_dict.keys())[list(checksum_dict.values()).index(checksum_og)] # finding id for which checksum_og matches\n",
    "    \n",
    "    # all images are of size 480 x 480\n",
    "    \n",
    "    img_row = QA_csv[QA_csv['img_id'] == id_og] # check if string\n",
    "    \n",
    "    y_og = img_row['y'].reset_index(drop=True)[0]\n",
    "    x_og = img_row['x'].reset_index(drop=True)[0]\n",
    "    \n",
    "    x_pos = (80 + y_og) * img_size[1]/640 # x size is 640, cropped that way\n",
    "    y_pos = (x_og)* img_size[0]/480 # y size is 480 (also, height is first in img size tuple, so the 0)\n",
    "    \n",
    "    # never subtract 480 because from the top :( and image orientation is naturally from the top)\n",
    "    \n",
    "    disk_center = (int(x_pos), int(y_pos)) # for (224, 224) image that will be created soon\n",
    "    \n",
    "    return disk_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cad54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_ring_mask(disk_center, num_rings, ring_radiuses,\n",
    "                       image_size = (224, 224)):\n",
    "    \n",
    "    # ex. ring_radiuses: [[0, 15], [75, 90]]\n",
    "    \n",
    "    center_mask = np.full(image_size, 0, dtype=np.uint8) \n",
    "\n",
    "    for i in range(num_rings):\n",
    "        ring_mask = np.full(image_size, 0, dtype=np.uint8)  \n",
    "        # for each of the radiuses given dark around the outer circle\n",
    "        cv2.circle(ring_mask, disk_center, ring_radiuses[i][1], (255, 255, 255), -1) \n",
    "        cv2.circle(ring_mask, disk_center, ring_radiuses[i][0], (0,0, 0), -1) # the white for that region\n",
    "    \n",
    "        center_mask = center_mask + ring_mask \n",
    "\n",
    "    # idk why exactly this is needed...? \n",
    "    # probably related to the fact that adding the original center_mask does NOT make sense, but appears to work\n",
    "    center_mask = cv2.bitwise_not(center_mask) \n",
    "    \n",
    "    # back_mask = cv2.bitwise_not(center_mask)\n",
    "    # return cv2.bitwise_or(img, img, mask=back_mask)\n",
    "    \n",
    "    return center_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_img2 = cv2.bitwise_or(modified_img, modified_img, mask=center_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdf3e6",
   "metadata": {},
   "source": [
    "### Good code next steps: functionalize all of this code MORE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbdd268",
   "metadata": {},
   "source": [
    "#### Goal of Half-Skeletonize:\n",
    "\n",
    "Goal: trying to prove the theory that skeletonizing only the exterior regions will get a higher AUC, possibly by using thinner pixels in exterior regions and thicker pixels in interior regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "753e2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_skeletonize(img, disk_center, skeleton_radiuses, region,\n",
    "                    image_size = (224, 224)): \n",
    "    # skeletonize inside these radiuses.\n",
    "    # let region be skeletonized center or skeletonized outside\n",
    "    \n",
    "    # Ideas: 0 - 60 no skeletonize, 60 - 120 skeletonize\n",
    "    # 0 - 45 no skeletonize, 45 and on skeletonize\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    \n",
    "    # defining channel which will be duplicated late (in case it's not already with Image Folder??)\n",
    "    channel = img[:,:,0]\n",
    "    \n",
    "    # created duplicate image to skeletonize\n",
    "    skeleton_channel = np.copy(channel)\n",
    "    skeleton_channel[skeleton_channel > 0] = 255       \n",
    "    skeleton_channel = skeletonize(skeleton_channel, method='lee')\n",
    "    \n",
    "    # create masks to shadow channel & skeleton_channel\n",
    "    center_mask = np.full(image_size, 255, dtype=np.uint8)\n",
    "    # large black circle on outside\n",
    "    cv2.circle(center_mask, disk_center, skeleton_radiuses[1], (0, 0, 0), -1)\n",
    "    # smaller white circle on inside\n",
    "    cv2.circle(center_mask, disk_center, skeleton_radiuses[0], (255, 255, 255), -1)\n",
    "    \n",
    "    back_mask = cv2.bitwise_not(center_mask)\n",
    "    \n",
    "    if (region == 'skeleton_center'): # could be for ring or not for ring\n",
    "        channel = cv2.bitwise_or(channel, channel, mask=center_mask)\n",
    "        skeleton_channel = cv2.bitwise_or(skeleton_channel, skeleton_channel, mask=back_mask)\n",
    "\n",
    "    if (region == 'skeleton_background'):\n",
    "        # masking the center region\n",
    "        channel = cv2.bitwise_or(channel, channel, mask=back_mask)\n",
    "        skeleton_channel = cv2.bitwise_or(skeleton_channel, skeleton_channel, mask=center_mask)\n",
    "    \n",
    "    final_channel = channel + skeleton_channel\n",
    "    \n",
    "    img[:,:,0] = final_channel\n",
    "    img[:,:,1] = final_channel\n",
    "    img[:,:,2] = final_channel\n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01fc48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_img = np.array(Image.open(\"/users/riya/race/dataset/segmentations/27313.bmp\"))\n",
    "test_channels = np.repeat(my_test_img[:, :, np.newaxis], 3, axis=2).reshape((480,640,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de812cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_img = half_skeletonize(test_channels, (58, 129), (0, 60), 'skeleton_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a36e801e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2ed8b8bd68>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(return_img, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f01e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c0f43e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already done this, before I saved my images\n",
    "# Yay, we did the same thing, repeating the image thrice to create the three layers. I can just do that part.\n",
    "\n",
    "# Oh, I see. Rather than saving ALL the images (as I wrongly did), it's so much easier to just make them in the train code!\n",
    "\n",
    "# depending on the inputs, I can run this code 8 times to train this model. It'll be easy to train at that point!\n",
    "\n",
    "def shadow_regions(img, skeleton, disk_center, shadow, radius, \n",
    "                   shadow_ring, num_rings, ring_radiuses, region, \n",
    "                   image_size = (224, 224)):\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    \n",
    "    # defining channel which will be duplicated late (in case it's not already with Image Folder??)\n",
    "    channel = img[:,:,0]\n",
    "    \n",
    "    if skeleton is True:\n",
    "        # can binarize all 3 channels, but will go 1 at a time\n",
    "        channel[channel > 0] = 255       \n",
    "        modified_img = skeletonize(channel, method='lee')\n",
    "        \n",
    "    elif skeleton is not True:\n",
    "        modified_img = channel\n",
    "    \n",
    "    if shadow is True: # want to do either shadow or shadow_ring, not both\n",
    "        \n",
    "        if shadow_ring is True:\n",
    "            # ring_radiuses is [inner_radius, outer_radius]\n",
    "            \n",
    "            # for cases of multiple rings, we're just going to pop over to another function lol. \n",
    "            # ring_radiuses will be array of arrays.\n",
    "            if num_rings > 1: \n",
    "                center_mask = multiple_ring_mask(disk_center, num_rings, ring_radiuses,\n",
    "                                                image_size = (224, 224))\n",
    "        \n",
    "            elif num_rings <= 1: # 1 ring only or no ring, only 1 ring really applies here\n",
    "                # developing mask that darkens ring portion\n",
    "                center_mask = np.full(image_size, 255, dtype=np.uint8) \n",
    "                # radius i changes, center, color, fill is the same\n",
    "                cv2.circle(center_mask, disk_center, ring_radiuses[1], (0, 0, 0), -1)\n",
    "                # adding circle to darken inside region\n",
    "                cv2.circle(center_mask, disk_center, ring_radiuses[0], (255,255, 255), -1)\n",
    "        \n",
    "        elif shadow_ring is not True:\n",
    "            # developing mask that darkens center portion\n",
    "            center_mask = np.full(image_size, 255, dtype=np.uint8)\n",
    "            # radius i changes, center, color, fill is the same\n",
    "            cv2.circle(center_mask, disk_center, radius, (0, 0, 0), -1) # disk_center received from optic disk segmenter, tuple\n",
    "\n",
    "        # developing mask that darkens background region (same in case of ring)\n",
    "        back_mask = cv2.bitwise_not(center_mask)\n",
    "\n",
    "        if (region == 'dark_center'): # could be for ring or not for ring\n",
    "            modified_img2 = cv2.bitwise_or(modified_img, modified_img, mask=center_mask)\n",
    "            \n",
    "        if (region == 'dark_background'):\n",
    "            modified_img2 = cv2.bitwise_or(modified_img, modified_img, mask=back_mask)\n",
    "            \n",
    "    elif shadow is not True: # if condition here for clarity     \n",
    "        modified_img2 = modified_img\n",
    "        \n",
    "    img[:,:,0] = modified_img2\n",
    "    img[:,:,1] = modified_img2\n",
    "    img[:,:,2] = modified_img2\n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57226b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb7ece35",
   "metadata": {},
   "source": [
    "### Testing The Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b122d",
   "metadata": {},
   "source": [
    "#### Shadow Center & Optic Disk Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05aca8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_img = np.array(Image.open(\"/users/riya/race/dataset/segmentations/27313.bmp\"))\n",
    "# my_test_img = cv2.resize(my_test_img, (224, 224)) at that point, images are NOT resized yet\n",
    "test_channels = np.repeat(my_test_img[:, :, np.newaxis], 3, axis=2).reshape((480,640,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ca8bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3371/3371 [00:12<00:00, 260.02it/s]\n"
     ]
    }
   ],
   "source": [
    "QA_csv, checksum_dict = checksum(\"../../optic_disk/DeepROP/quality_assurance/QA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a862bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_center = determine_image_center(test_channels, (224, 224), QA_csv, checksum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f173eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 94)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af08900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AABXkklEQVR4nO29eXxV1bU4fs6599x5yhxCRgIkhDAJSBgEBwqiRZxAtFCHWlE/Vmv10/r0vW/79LXv+bGvPttibWv7WhWttogooIwyx0CUmSQQMpDpJrm5ufN8z/n9sX53v82Z7rlTEi3rj3xuztln77X3XnvttdZea22CuApX4SpchatwFa7CVbgKV2FkgRxtBJIBkiQJgmBZVvBfwfIkSUIBiWJXYQzCGCVQQRKEHxRFURQVjUZZlmVZFl6hAhRFMQxDxIgSilEUpVQqoTzDMGwM0IcURcEP9C20jorhTSCgKEqtVqvVaoZhwuFwJBJBn0A9AHhDqK1oNMopgJeJu4r4yHDgG7MOlaONwBUAfA5oizPH8JCI0RAqjGaCoii8JP6WYZhQKERRFLyFH3g9JEkqFAr4FyiYwPgu/AuEhVMwRVFarZamaZ1OF41GfT4fwzBerzcSiSCGzaFLkiRpmlYoFNFolMGAwOg4aerkPBerR3AZ4BxBDg4jBmOFgyJGiPgiZ4zwbZoQH0REOgRB4FwKAJEaMFrODHGYMYdAARiGwZEEslYoFDRNA6X29/cD20aVqFQqKENRlEKhCIVCBEGo1WqtVgvFQqFQMBgMBoOIuxMi5IXTVlwmyu+4BIwposRhrHBQhUKBMycAzqjhM4evdfQXniNWBz+AWBmGQfSKkyYumyKyg0+IGLfm0Cj6zbIsbOvhcDgYDJIk6fV6EXWipaJUKhGbJAgiFAoBR49EIiqViqZp4Kby6YNPwXzCxYdxbFKeTBgTHBRtu/g+jqYB3y4lti2cHKEYbKbALMPhcDgcjkajnLnkTCS+uRNX0iLeFl4D5xVnZycIArqGmsNXAiAMKwdnivzll9BgcsbqKoGmCmjmYBME/oemDcpIjzJFUTRNI86HGCEQRyQSiUQifOEVmgOeB/OKuOyIcSBp+uOsE/l1ot9igubXBUafQPmSH2I56AmuqQAFUxQFNId2c2UM0LYbDocJbENEDSGtSKVSRSKRcDjMF0YRn0NPkKZP0zQ8Ac2dIAj4i2pWKpUKhUKpVMInsHJAhYL1AAsGfQIlkXACnF6hUGg0GpZlg8FgIBBA6LExowQSilBVUIC/DvHeccaWL+rg4zAWSHnUCJTTf8T80K6Hjx1SgRFThGlGBVQqlcViUavVIA5GIpFAIBAMBvlDTGJalIQ6QmA7LLSrUChAYGBZlmEYRGTElTSB/0VEA5/Dt0qlkiCIaDSKK/KogyqVSqPRoGUD44CvNFxE5tOZmCyEr38OzmMcRkdJQhKn2BCj31AGOCXar2FSOZ8UFxc7HA5QopGVVAwBRJqCEiSndUAAiBK9QhPM+YQQoXgO7aK/qH4ipnWFQiEyZigVHBbcLMVHWxABvB5cABj7MGoEivNIBJwJxpUGRKb4EyLGqIxGo1arbWpqCgQCEhwRMWDiSiLDWxd7AgpW0rueIO1yDgigANih5NQmhnbcb+PS6BjZ3wmCoEalVY6hhxRXmYkr90oWs8OjhyqVavny5Tqdzu/383UCBLDPEjHSlNjj8MpxSPucJWRdQjikjoZEDZyxHXUYHQIV5JGcAghwkxOiLZyD5uTkLFu2rKmpiWOZ5ww0G1PnJeyOIz89SdBoRgHfl8YCmY40gUK3JfgcgRnb8QKC4wW7dm1trcVisdvteAGSJJFaQ2I6uFijUAYp1IJlJDols2SGqopLTDAaNE0rlUqxkUS/8e7z96sRhpGWQTlqppjWiW9kqCR/mICUb7jhhtOnT/t8Po5khqRGAEGdjNNicrptGllgclWJiZXoIU3TBEFIbB2chxw9bBRhlLd49BuZTqS/QoAeqtXqqVOn7t+/X/DkPRVlQg6MhU0QgLMpIbsYYMg5qpBT21igTmKMnMWzLKvRaJB5SM6so+HLy8vT6/UXL14UK5bRgR4js4gDrnHixoExiKocGCsECtsx7ET4viw9rBRFFRcX9/X1ORyOsWMZGXkQlF5SHA2OaWW0YHQIlE9M4XAYREzcVEmIq/lIhM/JyTGbzQqFQrAA3hxfORvh0UcKYqbbJa88AyNJEo5/k6sKr3Pk6XX0OShHf8StSBLDgbawoaGhrKwsaamAT51EUrwhRZpGulrSNUjUzP8XjaEc+V662tGiTmK0lCQOIENGXGMQH7xer1arNRqN/A/Ta/1JV20ZolGJ5pIwTZC8U9+0IpUAjA4H5Wy14JgD2zS+UuWMi9frZRhGq9Vy6ucbpJLAk2OLTeM8xWXGuAFS8FhYPiTxLX/PGS0aHTUZlMDICFnd4sY8cIBl2eHhYYqiioqKmpqaOK9kViJdfyqfS1crRqNgUdfpdKAyqlSqgYEBFJGXOazGJowQgeJ6D8HzucRlJpkVotn1eDw9PT0FBQVpkTLFQGZVCQmpgiUpisrOzjYajTRNa7Var9fLd65LLxpiNXzDtXh8jPgSIfQfPCORARlnD4iCxSpHPxiGcblchYWFeNAmQRBJbIt8nDmLihOrBMA3OIjVKdYRVACs6z6fD7ybUUPBYDChjvBblEmynC7wQwtHHjJCoIIUiX6AIQm9SnTb4tj8IpGIzWbTarVosjmelPKBI3LxVxQnPpj/iXSdgvhzXjEMwzmzTQskQZ2jpbZzICMEymLxFfhznCv8/80rlXh5fOYEmSifS0Wj0e7u7vHjxxPp3o84tfGdR5NQxtGwCBIuMarOTWOBHPmQKTMTeyVAEBz6jQC4neB+Cto9nwj4u3BXV1dZWVmi1j455IX0aJncMS5wzBSctsYI0xpTkFk7aFzFE/f15GJGUUajESX84BAKbjS1Wq0Q1iMTKzLmS5FQF8SqktloXJSITPIw3GiVoSYyBBnX4gU3NcG9myPPMQwDKWU8Hg/HAx9+IIoMBoP5+fnSBIfPDcuyHKuCGMQtkzpJ4VhJ14aGiNOXRFUiwcUgrZLKF2HTvsYyTqDSmrhErxiG8fv9+fn54XAYjzRCk8TGopSsVqvJZIIMM3IwAV1k1DdTnODkm7HwH2Kf82tLZaUlhFvaR3V0jjpx2Q43znPA6/Uqlcrc3Fz+9o1Lt3a7fWBgQK1WS7SImkDjOBYIFEkpcvDBZXoUtTwWOgLAJuvuLQ2ZIlC+uIP/i4+1RCXhcNhutxcWFnJOMlEl8CMSiXi9XmnpCpm3xoIuQpKkWq02m80mkwmOi8YgJCqzZmhI07zFkyKObYSIxw3+Fb82lmUdDofRaMzPz/f7/fyYOPiBJ9gQRAnyfIDRYNQ3d4VCYTKZZs2aZTQaOzs7L126BK6GY4QRIkAbDh6ojRfgTGuGupBmDsohO5QwQ/orEjukQU/IWKwCiJg5OTl8SzL8iEQibreb73QH1er1+sLCwuLiYqDRuIoIACR7Srvaq1AoysrKli5dOnXqVLvd3tXV5ff7R2XNyOwXLheNCqSHg3KUYk4uRUE1Eww9yJFWqVRCshdceQL6CAQCnZ2dlZWVgUAAzgA5CxrSxup0Orx+2EYtFktpaanT6bTb7RKZcHDtGAJB1Wq1TqcbGhripJ7jrEDENsQYCdpSlEqlXq+vqKi44447BgYGtm3b1tPTAzltOPiMQVZKYoDLZhxUIWSUjZd2ICFI2xaPcm8DIEQFC7MsC9m/oKskSep0OshNzCkGNbjdbrvdXlZWNjg46PF4QqEQbNZoOsEDCEfGYDBMmDBBq9X29fX19fVBVk7pLrCYFzoQPSfpEl9KkUNMFEXpdLrp06dPmjRp+vTpjY2Ne/futdvtErlVMg0JLQOOzIZbuDjF+HGLqUPaCJTEstKJISqoJxExes3KysI5Fv5hNBrt7e3NysoyGo06nc7tdnu9Xr/fj1eVn58P/yoUiry8vNmzZxMEUV9f73a7pQMekICBYsYhDROLpUxKelgUCoXZbF65cuV1111HEERjY+OOHTvcbvco5u6Kq03CD8HFw0oe8GZidaWHQGHblegbeo5rNqgYy7KBQKC0tNTj8Qimr4ECAwMD4P3J8LJ3R6NRjUYD5DVu3Ljly5cPDw/v27fP5XJJ8DmoHKgT5QUXzEwmHziiTnZ29i233LJmzZoDBw4cPnz43LlzgFJCdaYOSJiW0GnQ1PBf4Ux0hJFPGweNK00j8UWwTCgUCgQCeXl53d3deB5knOhhW+e0CGV8Ph8IednZ2cuXLx8cHDx48KDT6Yw7msA1o9EoyifKQTh+z0U6CxbcG2+8ccmSJQcOHNiyZUtXV5egHDwCIEcawQsIEmhGMIsHaSBQfGnCX448SmBKjxiNRqNRl8s1Z84ch8PB4TF4CjhW6JQSCpSXl9fW1lZWVp44ceLs2bN8UuATHKQ2AIdUwcKCGk/c0SBJUqPRlJSU1NXV5eXl/eMf//jyyy+HhobEDGFjEHCOK8g4xdTf9GOShipk4AobKOeCAc7cK5XKefPmTZky5Y9//GNymIC5FFduCHGqAjUf0hnHrRldzBBXlgWr1vXXX3/zzTdbrdbdu3cfPnx4eHh4ZKgTV7QT/RAxDjAbs7FDPjSYnNzNgjWk3AMeYqlXwQ9j52sAEBDHUYqJzC9BicUDFiU5jvdyVqBCodBqtbm5uXV1ddddd11OTk5jY+OHH344ODjIWTCZhrTwNkEOMirCSRoIFCXdJLBNnL8LJ7GsMwdI5EiddEiSVKlURUVFkydPnj9/vl6vP378+IULF9ra2oA0R0UlGjtDnSKkKoNylDuOqoT+HVNDhmzOaaFOrVY7ZcqUO++8s6CgwOPxfPDBB+fOnfP5fIK2LUHb/lWQgPRs8YIqEREjXyp2O+VYmBJ0Twgbu4Yr6apAip03b96dd97JsmxHR8fhw4fPnz8fCATikn5CKzbR5Z0WdpDKWkojP0rPWTxfK8c3elwGkANr1669/fbbLRaLhGkDks3CIFZXVx85ciQ7O1tO5QzDhMNhdBgr1gukxkqAUqmcM2fOmjVrAoHAZ5999sknn1y6dAkiMNHnabHOiBksZZYXBDKWsBeOdgW9JtjYVVJwJRqJAb82zkOxkolCeuygfLMZ+kGSpJxbAQBAcTly5MiGDRv6+/uPHTsmpmLjsl1OTo7X600oNhedQgmiLRPVnJyc22+//eTJk/X19WDj5GeVEqszFQaTFuaEck8TQjZm1Eo0GkXkK9E0x/zHCrkuJAfpIVAJli5zNaOtJBqN9vX1nT59+vbbb29tbR0aGhLbZVgsMQnfGY+ILeKEBE35m5per7/rrruGh4c/+eQTZOMcCzKMTEDXTcXFWSJuDAcxJpUipGGLxzUh+VxdrCSIhgcOHGBZ9lvf+pZarZaoEGhUr9cLin3QBFw/lwpKnDIEQSgUitmzZ19zzTUffvihzWYDP6zkpiQtMkASAHeF4ZeJSRQeRQtMemTQRDsApIDvHRwYHh7evn379OnTDQaDdLgmSZJ5eXlQISduDtghREcQskU3OTRqMBgWLlx46tQpOJiVLp8QJJ0qMVEYRW+VhCCdwyFoARUEtJMi6ZtTIBKJtLS0sCw7derUuOGaLMv29PTwqZDFAF5NmjRp/vz50l2QbgtOR4uKiiZNmnTkyBGJe8OSgHQpv6PClQVtaqlXmwyBqlQqtVqtUqlAB5SDB189BN4G92riJ0wIfD5fb2/vihUrDAaDRM3RaHRoaMhisYBijg8TZ7XAvgwXDYrVJmeBURQ1a9Ysr9d76dIl+eyT5AFeIVIpUOtxN5m4zYnp5ukCmeJQipAMgSKND3U+UVQkNCpEu4FA4NSpU6WlpZzktHzQ6/Vyzmw0Gk1hYWF7e3vSXApZzebPn3/06FEI2Jf/LQfw5/BbsJtJ0CjUybnxLO0Qt1o2HT5QSRIoiNjybzZJYoyi0WhHR4dGoxk/frxEP8HcY7PZBK+Zwz8sLCx0Op1utztRTHBgGAZ89evr69MlfQrSECIy+TeffCMh+ezlaAQztEZZlrXZbF1dXXPmzOFYiXHKg427r68P/xY2OJVKpVKp4FuFQpGTk9PQ0JAiVVEUVVlZGQqFrFZr2nstWCGbVIhP5nb2EUYjbWamTEAwGDx16tT06dPB2IR6i295er1+5syZDQ0NBMY1lUqlTqczGAxZWVn5+fl6vd5oNObl5Q0ODiZtDAKwWCy33nrrwYMH4fRhLBCBIADX4G8jo4VD0pWM8iUKYqhDrxiGOXbs2IQJE0AMZTEPRdTzcePGBQKBjo4OmqaBZWq1Wr1eT5Kk3+/3eDw+n4+iqLy8PKPRiJ9pkbxMpRKYQGGtVnvTTTdVVFTs2LEjc8uSM6NIyk9O4s8EjcqvE+2ucoZaENKfm4nj8R53IlE/ScyXFH0FR4gTJkwYGBjAFQvUVnV1tdvt9vv9cLIMuyEcLKHdnKKo/Px8sBiQ2FmRHCJDJiq1Wl1VVbVq1apNmza1t7enHk8np1H4F/9BJmKK4tSTCuDtJtRrNNrJtZswUUuvHtQNvrAoCDjeZCxYHt/B/X5/U1PTwoULBeshSXLq1Kmtra0Mw4RCIa/X6/P5AoFAMBhE6UihidmzZ3d1dYXD4eQsLwaDobq6+p577tm3b9/+/fvlexekAnzFHyKtE0KezUzKpBGDxAgUFA6J3IX4UHLCIwHQdkleeSsS0lg5WlckEjly5MiCBQsEzfU0Tc+aNevcuXP8b/F2aZqurq62Wq1wJpmEZdHlcq1duzY/Px+ocxRFz9GitsyJNNKQAIFed911kyZN0uv1MlO/igGiIVy8I0Xu52RZtqOjw2g08rMrkiRpNBorKiqam5ulh89isej1eofDwcpzjxCkv7KysqamJr1er9Pp4Fr5DJFpXPSSEOa+voaqBGRQs9lcWVk5MDCwY8cOziv5ghHO3nAZUbA2+OFwOEwmU25ursvl4hTLy8tTKpUdHR2CbZExlb+4uNhms6F9GZfMODIGAE3T48aNa29vx2u75557xo0bp9FoiouLIW2E1+sNBAJx72xISGqUA3IWGL/MaLHAFEEugZIkee7cuWuvvZZPnWazmZO1hj/3+CvBsUPrG9TwUCgEyWpYlh0YGDh79uzixYtBiET1mM3mhx566NSpU3a7XcyCCD/Gjx+Pf4tTPwc3SOe0bNmydevW6XS6hQsX4gX6+vpAGwXzKlSIR0XzmwZvX3AV5WOYBMTV7ZLglLAskzC18jHBH6ZlZSbAQXt6enbu3Ml/TpKkRqNBV/sAJKHoob3e7/fjlyf5/X673T5jxoxNmzbhjU6aNGnlypX3338/CIViLdI0vXjx4i1btgg65CIAK1J1dfW3v/3tm2+++ciRI9u3b+fXhmRrMpbVkSRJvV7PMIxSqYQ8e7gUEY1Gwb9EptFADqSXF6bXCMURz1KnUbkEyrJsOBx2OByc54WFhT6fT6/XRyIROWkz4hYIhUKcuYxGoxcvXly5cqVKpUJckKbpxx57rL29/cyZM0AugrWRJJmdnV1RUQG+UWKNApEtWLDg4YcfNhqNv/nNb/bs2eNyuVQqlaDCjvKW0TSt0Wi0Wi2kLoOdhDNJoVAIvGrkhMbLmVHpAokShMR2lwoaySHDhwQ4KL+xbdu27d27d9euXTabjaZplHMrOVTENBiGYQ4cOHDHHXdkZWWhS65MJtOiRYsee+wxv98vMalghzp9+rTT6RRrF7It3HnnnatXr45Goxs3bvz888/BkirBWmAVgRwCLBxcFAQFGLC/8qMLBauVLpBeQPGMI9loQpCSoV6j0axcuXLChAmbN2++ePFiJBLRarWDg4PhcJhzZoOUdInaJOhsYGDAbrdPnTq1t7cXNo6pU6d6vd7jx49LsE+CIJRKZXZ29ueffy7IvYBoLBbL6tWr77333mPHjv31r39tb29Hy0AOM+MndRIshsxbY0dZQeleBN9yRvVrYGbigMViefnll4eGhmbOnPn888+vWLHCbDZXVVVdf/31lZWVglEWYtZ7tMuI2W58Pt+lS5dqa2tVKhVo2fPnz//88899Ph+nErwhgiD0en1+fv6lS5f4+pBCoYCMsk8++eRDDz20e/fujRs3trW14en1UhfO8BrwpL6cAum1AcWtjYwd80r4KMIYgpyd0EElGnw+GiNq6gKFd/bs2e+9957VanU4HDt37pw3b97TTz/91ltvTZo0iXM9ADJ5ojhX/DeUgX/5bSmVyg0bNnz22Wc33XSTQqGwWCwfffRRXV2dRIehreLi4meffRYlX0YIaDSaioqKH//4x2fOnLl48eLzzz+fn58POb85lSQ6LBRF0TRN0zSKipbzFT44Yss4vZBo/ckZB9JbYQIAlAQ2lPz8/DvuuKOhocHpdG7duvXaa6/99NNPf/KTnxQXFyNqw1cVOmxE6xgVE+OgJEnm5+f/+c9/fuONN4qKihYuXHj06FGTyYSXQQSBNzRt2rRHH30UbqiBJxqNpqysbN26dZ9//nlLS8sHH3xw8803m81mdD976iOT3FyKdTx1lMRaTPrtSEKSMig68mEYZnh4eO/evVar9eWXX168ePHJkyd//etff+973wsGg++88w4nbph/UMSpWVBKY1nWZrP98pe/3LBhw/r163NzcwcGBvBAeJIkdTpdKBQKh8NIKiVJMjc3d3BwEO2tBoPh29/+9v33319ZWXn69OmNGzfu37/f6XRGIhFYJKnLiMklYxL7JHOSX3qtlWMLEJ/DuaBWq12wYMGlS5eGhobuv//+O++887PPPvve975nNpv5/hliC5SSvEKToqiSkpINGzYcP378d7/7HaRURm+VSiUeKaVQKFQq1erVqxcsWAACsclkeuihh86dO7dr166HHnpo/PjxnJjmtLCNscB7Mr13ow/HQmcFAKGFS0tAo2vXrm1ra+vo6Lj//vsfeOCBTz/99Lvf/S5cFSeTQEEkF2uaoqjy8vIvv/xy3bp1er1eq9VqtVogSny1KJVKlUql0+nWrFlTU1MDtLt06dLTp0+/8cYb1dXVWq1WZrB8uiAJsTJpSTTuJ2lZlmQsxjWjZJqMFo92BLRfw49AILB169Ynn3wyGAz++7//u8lk+uijj9avX19XV2c0GjmV8HtFYgeGYsoKbN9qtRqsWiRJarXagoICxKfhmCcSiYA/aFtbm81mU6lUkyZNevzxx0+fPv3KK69cunQJJXpIkQ2kd27QvoT/5Q8FR9SWwEHsFd+mISYBS9TPxhz5+K4zpFA86ghxXOnhAOpZsWJFV1dXf3//ww8//NJLL3344YeLFi3CVRC+ti7YJX6jJEnOmzfv0qVLpaWl0JxCoYCdnd9/uDUrOzu7vLz89ddf3759OzJUcSClEZEH8tvCOytdQLqY9Ku4dcpHGHRlMY6TIiTDQTk+xRwIh8N79+59+OGH/X7/Sy+91NXVNTQ0tGbNmrKyMkSUnFtBCNnppkiSnD59usvlQp5NEFwvmHyGZVmXy0VR1PTp06+//vrf/va3HR0dyOd3ZOiSj79MGiVTS3eVaEmxz+XUAJsVXzBLi+6V5BaPzEN8bgR3xu3bt++BBx4IBALPPfdce3u7wWB45JFHcnJyoBuCqMsxBdM0fe2113Z0dMC5Py5sCJYPh8NarfaJJ5744osvvvzyS+QhxWLxqJnWYRNdDIliJVgy0eXHX9sJDUvmhjEZ11fkvk5cOfqAJTCzSCRy9OjRf/u3f1OpVGvXrt2/f39dXd1dd90FKUD4c4YfA4ptFiRJms3murq6+vp6mY4XNE3PnTu3uLh448aNPp9P+grrDPFUFoMR84cfYctR5rqWalw8G8txirLUIrUpFApt3br117/+dXZ29o033vjmm2+uX7/+7rvvtlgsghIC/i3/FQipcLvh4cOH5UwASZIWi2X9+vU7d+5sb2+XcxviGIRREUXGDiRDoDjLJGJ6N5KUEbcjSdLn87377rv19fW33Xaby+V64403Hnvssccff7ygoADZIMmY8i7hcgENqdXqtWvX2mw2OFuHY2K1Wq3RaCAQBZ9LkiT1ev0NN9xQVVW1Z88ev98PrF2iX6yMuIi0kAsZSwopp7a08MK4YoagkpR6u5mrMAFAp+ow6JyTTJqmb7zxxsHBwfPnz1dUVDzyyCPnzp178cUX8/Ly4ARSJpAkWVZWdvbs2eeff56mabxRQVOcQqGora09ePDg5s2bIUw+LZ1NvR5cfE8LSnIATccoEsqoESgZ83kBJgpmc3wCLBbLO++84/F4/vM//zMvL+/ZZ589e/bsk08+mZeXJyiPCjahVCoffvjh8+fPz507V3p2oXBZWdmmTZtOnjw5bdq0MbVLjiJ9kCmky0sLAiPfKEHEjn8g0ycAZ/+iKKqioqK9vd1ms9XU1OTm5j733HPnz59/9NFHc3Jy5BxFUBRVUFBw+PDhP/3pT3q9XrqwTqebMWPG+++/39zcvHr16rjpRRPq7D8zpDJWZOxK6VEA8soId/QQ/5em6TvuuMPhcGzdurWoqMhisfzkJz9pbGz84Q9/mJWVFRd1nU73wAMPtLS0XHfddRKFSZI0Go333ntvQ0NDY2Pjk08+yTmv5wOOeerb32hKWpkH6WmKK+NmnHOLjX7chuHDrKysXbt2DQ0NPfbYY3q93mQyPfLII0ePHv3xj388btw4vvMo+q1QKObMmfPVV1/96le/kpAmSZLUaDRr1649ceLE+++/f9tttxkMBj7O+BN8yyNj17IkN4joc/zGFjlffY0ImuM8Kc2SOK84Qy1YQ6ZA8JiLDxRFffvb3x4cHGxubi4vL6coSq/Xr169uqGh4ac//enEiRPxBYqLB6Wlpdu2bWtsbKytrZXw8ADvz6amprfeequmpkYsLzNIzHj96GCMTES5Th0SnWb8K7F/RwaSaJQUgTSjJfhcfqIRo9H4l7/8xeVyvf7661qtliRJtVr9ne9859ChQ7/97W9zcnI4Qw+i5+9///umpqannnpK2qHYZDK9+uqrhw4dqqysVKlUcfcjtKxxeuWQr9i3MvubBCRU+deI+wpCmvEXUwCRg5zYKsE/gdzEvb298+fPh+fgXHLo0KFnnnkGd3oiSTI7O/vFF19saWl59NFHs7OzpTeR2bNnNzU13XfffcBl+YX5vArRKKebqRBoKoM+KuzwGwWCW5LZbDaZTCBWWiyW3NzckpKSSZMmlZeXFxQUGI1GnU6H2JJCoVi7di3cf6XRaKAGk8l0++23Hz169Pbbb0e5atVq9c0339zc3PyrX/0KDFISiKlUqmefffbAgQNms1kCeTnPpakkLg0lQWH4UvlGctC44ylRIDGnXfyshYyl2S4oKNBqtTk5OWVlZYWFhRUVFTNnzszJyYHz2Z6enpaWln379h07dmxwcDAQCHz66acnTpxYsGDB0qVLd+/eDUlEPv/88zlz5tx3331nz57t7e1lGGbKlCn/9V//1dfX99prr9ntdjw6lsT8nshYcNyaNWteeeWVuCnoOd+iMUKnoCnGQvBdLRP1uohbhrwyd5VEgdEFhIYEMmLeF/9XSRKtgqVTq9UajcYJEyasWrWqtLRUr9fDpVvBYNBqtXo8Hpqmi4uLCwsLoWQwGOzu7v7www+3bNlSV1f36quvXrhw4aabbgoEAkBk48eP/+tf//rBBx9s2rSJYZhf/OIX11xzzVNPPXXy5EmUQwH+UhSF3JEIglAqlQ888MCSJUt+8IMfeL1eMbcMkhebD0/IK51UOLPLLx93fKQ/wSeDlZEchsNfITcE6rhYvD/Bm3sOVpyHctCQKMDplMw65UDCYQ8sy4Lzn0qlys7Opmn62LFjhw4d8ng8Ho/H5XL5/X632w3jCLHnpaWlkydPXrhw4fTp059++umVK1f++c9/9nq9IAZA8kSGYaxW65tvvvncc88dOnTIbrcvWrRoy5YtTU1NeC5j/l+CIBQKxaJFiz744AN+DjOJFcx/y/nBH185wx33E07lMlkmRVH8fKti9I02OqBssRUitg7l9EvO29Hk4nCqqdVqdTpddna2RqPBjTUcgBN5YLdr1qzZtWtXS0uL1WodHBx88cUXkZWKJMmsrKyPP/74D3/4w7XXXtvS0jJ37lw5JgKLxXLy5MnJkyfjngBglZS4akzsIS7DJCdQJvqJnDoFq5VjcICzPfBeSDtiXw+QPyUkSapUquLi4p/+9KctLS1er/fMmTP5+fl4XPySJUsuXrz4xBNPfP755/grGGic/lC1RUVFZ86cgVNTFDRH07TJZDIYDLiKhtAQm3J+sURHYyQhroZBxszj4CORhBKGQzpQ/joASZI6nW7evHmtra1ut/vee+8FdR5ArVZv2rRp27Ztb7/9dlZWFoef4dwR2bamTZt2/Phx3DeKJEmtVpuXlwfZkPkIyCHQsQ/ySQdYqcwjFSJ2foHH9ozWyAiz/UTXGfoh50OWZf1+/5dffvncc8+xLPviiy9WVFSgrTwUCv3yl78sLS09e/Ysvr9z/NJRHjySJCdMmNDV1cVR87OysrRaLdw4LadTfOQFu5NeXpJibbg6Erckfu2JND4ouiHFW9riYiWn78IEmhBOqBm+jiz2CcuykUhk586dBw4cKC4ufvPNN4uKitCufeHChePHj8+ePVvM1QPtXKCrzZ49+6uvvsLVdoPBMHnyZL/fL5FTl/8vfzL46gVFUTi/B0hFwkvRRxNwJuX5ekoEFCBmzAmOSII6ERoS5gsEyK9XrLbEhlVwCMT6ELdvXq/3qaee6urqmjVr1vvvv28ymWDhhkKhw4cPFxQUTJgwQWzEUXZjpVJZXV2N56+D4/tAIODxeChecLMcxPiAWItgejP5d5ZyIHUulWg9EpOF705yrpqQBpxUJFYONCrB2hMjUMEhSLonDMN0dnY+88wzTqdz9uzZv/jFL4A5RaPRrq6ujo6O9evX89kVEQt4CoVCMI5ms7mtrQ3t+Gq1ury8vKurC/LK4kOTHGnidBmJRPx+Px+fRKsV/DZpVpougw4rfi+o/CZwwYMjyPJLxl1UI2F6kJDlo9HogQMHnn32WYfD8eCDD65btw7SuavV6hMnThQUFFRVVUksPoIgjEZjbm7u8PAwPFQqleC8Z7PZBJOUEJgNkmMX4xdTKpWQ4RsdDSRxr6t8SJ2VjhHAdzMiBWmBGOG7OgVJze12v//++z/60Y+CweDLL788bdo0hUIxMDDQ2dn54Ycfrly5UtqJCZw+PR4PGTO4Tp48ubm5GRLWAUPVaDRwLwd/KeMDh78C6TYrK6uwsBCym2eCdMQk7NFSmdMIsJ5BSU1l9NJAoHL0AyTDCZJIJBL5xz/+8eqrr6rV6nfffddisfT09NhstgMHDowfPx7PM8qpEOivp6cHUjEC61Uqlb29vUQsA0pWVlZxcXFpaalWqyWupEh81HDHUGQ4JElyeHgYLjCR2AdwlPgPJcqLFeD4+Yu1JTieYs8FsRrJlSA9gGLPUwo7BpAjmOMgiE0wGPzv//7vAwcOVFRU/Mu//Avc7NHf33/27NkVK1ZIrAGDwYB0FIqicnNz+/r64GaFSCQSCASsVmt3d3dvb28gEJBQ0mHvprAsoT6fz+FweDweOLaNq4UkKqCLbXzwUJrIkEIjyJzibqmjIkhIY5VOlJJedmjdi9WQl5fX1dXldrvvuuuu8vJypVI5ceLELVu2ZGVlCZanKGrx4sXbtm2DYySz2TxjxoysrCy4l1s+VihIA+Vjl2BvIwBIMxPLiZ7etjJaf4qQUvpFgeooSuz6BDi7B4fR7OxstVrNH/rBwcHvfve74XD4hRdeKC0tJQiiq6vr8uXL8+bNE9w9KYqaOHEi6ENqtTorKwsuPIYbYeT0BW2I8C9+H710T9MFYuqt2G28/2yQTBJXvtBDxvzW+EIGiIn5+fklJSVTp04dP358QUFBMBg8efLk0aNHL1++zNl5Dxw48POf//wHP/jBfffd19HR0dfX99FHH916662HDx/2er2odaSGT5o0CUx3arU6HA5brVa4CkxmRyDVLSLoEaYGae41MsiM8QWQDIEiORKxH3Q5OxSgYvd1kySp1+vhzsL8/HwgoMbGxuzs7IULFy5btqylpWXTpk2dnZ3oXiWGYX73u9/NnTu3rq5u4cKFu3btam1tVSgUixcvbmhoCAQCkGJJoVBEo1GapktKSi5cuAAIDA0N4YnrxQAwh9TMFouFYZj+/n5iBKcKLWPBFsmx4W6MgwS2GW86bgkxr1ipSmO0q9Foxo0bB8eYfX19Q0NDYF1XKpV6vb66uvrOO+8sKSl59913P/74Y/BcBnVnzpw5b7755tmzZ1955ZWenp7x48ffeOONNpuNoihIAGG32x0OR25u7scff/zHP/7xrbfegtu3SPEbw5CGbjAY8vLylixZYrfbe3p6+vr6enp6IF9zQnMgWB4knOTMpdJUK9i1RBVW9NWYWgMS+MTnoMn1hIyF8Lpcrv7+fnT/BrxVKBR+v/+LL744f/78zTffvGbNGpqmt27d6vF4oMWzZ89u2bLl3nvvveOOO9544422tjaz2XzNNdeMGzeusrKyv79///79cAOOXq9vbGwkMC9dwSkkSdJsNms0msLCwtraWovFYrVajx8/Pjw8LOdKbbE+8j9JxZLPimQvQ/0SVNhJLCJAJuWNKeokJPGJz0EVCkUSojrShQUlfVCc4YdGo6mpqdmwYYPD4fj973/f1tYG5QsKCl5//fVp06a9+OKLW7du1Wg0ubm5YHKfMmWK2+0eGhoqLCx84YUXli5dGolEhoeHyVhEBGLhaOYoiqqsrKyoqCgtLbVarWfOnOnr6wPxV2p0JOcb6h9rk/0Ng0wRKCE5u0BA6ChSqVQWFxc//vjjlZWVv/rVr86dO+f1ehmGqaio2Lx5cyQSWb9+vdlsrqmpAbN8T08PwzCFhYUrVqwoKSl55JFHcnNzL126hLvhoabBgKBSqeDzy5cvQ+weHkmSHIyiZPaNAXzHEJZt4lZBybijN1EAsw6qFhiq2WxetWrVypUrv/jii+3bt1++fDkSidx9992/+MUv3nvvvbNnz3Z3d2dnZ1dWVgaDwe3btxuNxsWLF0+ZMuXdd9/NysrauXMnOk/CjwPAxqlSqUwmk8fjgWuMpaVVRHljTVYTA1zr+logzAGJpR5fBkUbJf97RP7yZXP8K/zzaDQKwfJWq3XZsmUlJSXBYHB4ePjMmTOnTp266667WJbdv3+/zWbLzc2dN2/exIkTQRjw+Xx1dXWDg4O4zxsZC4mGIxm4y95ms4GsCeIHsFsJVOVQJ79MptmqhJz9taZOMYhvqJc44ot7pIYwAB5JxfLMsLw7DOCH1+sdGhrq6uoyGo1ut1un0+n1+rfffttqtS5fvvz73/8+y7I2m621tbWwsNBisWg0GqfTqVarnU4nxNygo5doNBoIBAKBgM/nC4VCkUgEKBg1JyG34J3iDx8emsfpJrL5kxjEHeGEQHDAM2fSl9+RFAskr8WnBXDkxBAForHZbHv37jUYDAzDuN3uzs7O5ubm5ubma665Bi6tGxgYgN1//PjxoVDo/PnzXq/X4/Ho9fpwOIz4KH8icdKUgzO4jPC9P6+99trh4WG73Q7qP9inEM+GS06gm0A3IE/j3ReM2efgOUZAPjJxS0qwA4mv4hNo6gIowkBMVAAAbSYQCKBQjWg06vP5fD5fU1PT4ODgLbfcMmnSpP7+fq/X297e7vf7g8FgZ2enWq3Ozc01Go0ulytd2xxJkkajEbmZIvjkk090Oh3Lsu3t7Y2NjWCOjUQier2epmmDwVBaWmo0GsHayjBMR0fHjh07PB7P8PAwyL5arRauuQdU8e2FpmlwiMbjqNCGIzF032CIT6DpUhTiEjps0IFAIBgM0jQN0wmzFQ6HBwcHBwcH77777vr6+mAwGAqFBgcHNRpNKBRSqVRerxeFeqWONkVRJpPp5ptvfu+99ziv3nnnnaKiosLCwrlz59bW1vp8PpVK5ff7A4GA2WxmWdZgMAQCAbvdzjAMHEbMnTs3Eol89dVXAwMDQ0NDJSUlly9fBjmBpmmHw6HX64FkwTN6eHh4cHBQoVBA12iadjqd/f39eIjVPw+ljhyBxm0FFBe/3x+JRJxOJ8uykUgEjkDh96FDh77//e8XFxe3trayLBsIBCiKslgsoE7BfAcCAQI7yuJbneKCQqHIy8u77bbb/vCHP3BeGQyGnTt3QjIIlUqVl5dnMBiAC+LuKf39/XCjiFKpLC0tve666/Lz86uqqurq6i5fvlxSUmIwGNxudyAQAHe+kydPOp1OiEE1mUwLFy6MRCIGg2FoaEir1V6+fPn06dPgzIrytRAEAUoePJHTKb5GGHdmMz31HE00STOToKIqqNFLdCbuW4IgQMsBVw+TyUTTtNvthhvlCIJQKpXXXnvt/fff39PT895773V0dGg0mnvuucflcg0NDanV6r6+vnA4jLxPgGgIghBT1XHTDDyBA9gZM2b86Ec/WrVqlSCSRDx5miNjgGDKMAzKFOR0OmE04GhNqVTCokKjZDAYNBqNyWRyOp1+vz8UCgWDQaRTKhQKnU5nMpmMRqPJZBoaGurt7QXmKrF7QEQ8eyUghOOOT+pkyjc+gGCj1WrBxzwcDg8NDfE/TN5ZRM7DuG85k41GGTY4nD0wDNPb23vhwoXs7OzvfOc7+/btKygoWLdu3VtvvRUKhYaHh0OhkF6vDwQC6L4lEgvxlmgdyX95eXnLly9/7LHHZsyYIdGFhGYLrhJlGCYUCoE8gMgRRwOvXDAoD5WBTQYSqRYVFS1cuLC5ufnEiRNgaBNDD1YC+MiC+ARpAOPOGn8ZJwcs7xSXZVnQMWC7MJvNCRAosn0SMUN9hlg9vujxA3FQmDhR7Var9eDBg0VFRRMnTvzRj36k0Wi6u7tDodC4ceOsVqtGo9HpdASPksDZhTNASAZQKBRGo9FisVRXV69atWrBggU1NTWZ6CPMB9+rn+DNvfT6Z1k2FAoNDAw4nc5AIKBUKouKiqLRaGtrK/jFgoDOqQSi/3Q6HUQNUBQVN08lp91Ebd4SVeFPYAGHQiGHwyH4lTCBKpVKtDOiU58k9A/51hN8mQLzh+WOj0soFOro6FAoFE1NTQ6Hw2g0HjlyZHBwUK/Xh0KhkpKS4eFhjirGxpIawMSQmN8qRVEFBQVlZWULFy6sra2tqKggCCLt1MnpeFrWOQxFOBwGhfKaa65RKpUWiwVElOHhYVi3qC24sVyj0UQiEY/HI5Pd8OW61DEXpByYMjEdWphA8VsJIV5MrHZpbNCHxJUkLggorogkSchgD4RFxm5QZhjGbrfD7127doGJEbQojUYzffr0vr4+Fss8CBduaDQamFGoiqZpmqb1en1FRcX69eurqqoikUhnZ+cHH3zw2muvye/d6ALIhaFQqKenx+l0FhQUoLjW7OzsQCAwMDCAy0vRaNTlcoGvI6qET3MSU4x4x8gozQiECZTlpXVNFDn8K8gCAiqnoMrCaYIgCJ1OBwZwjvU7Go0ODAyo1WqVSgWbAsuyIFTZ7XadTqfT6UiSBBV76tSphYWFhYWFOp3O7XY7nU7wdNbr9TU1NUVFRYFAYP/+/QcPHrx48WJ7e3si4/Z/mI+uxYdlWXAwgIXtcDhomoacK6CcAZIcgZ4PcXkQ0rHkk4F8ZVqCPYsqSXzhAz/pjtskErwIgohGo8hhXgzgCBTEfIqiAoFAXl5eZ2cniCm43gDZliGzCGR5ADYZiURKS0unT5++dOnSSZMmZWVloYB6pVIJhzogNvj9frvd3tDQ8Prrr3d3d4OXvjR6fEApCYgr5ZPUIVFpj2VZGDf4EIgVxg2INRgMClInx9oAVjmJVhLCSrAkX1WKW2ccLR4dbySEGQIk88XVFpEREZlggINGIhF0wyLDMOhc0eVyQUYAGFaGYSorK1euXFleXj40NPTll1/abLbGxsaenp5QKATWK5VKBYl0HA6H3W73+/0Q8J50v2Syk0S5LItFdyV0jIdbPAiCABuwnA4Cu8U9yjMHiY52HAIFQUe63rivEp0egiD8fr/H4wEigIzjer1erVa73W4QpDgsQalUTpkyBVI3wm0NsKkhAZplWZS+Rg7mEoCTjpy5T0L/xTW5VIiGYZhwOAwnCxL5wGD7ipuccVQgPoGmnUPEBZIkg8Ggy+UiYtoAwzCQQAH2aJg2JKSC9hoMBv/85z8fPnwY2faBjNBenHrGNgRJLLlEm2ZjkBhmQvVEo1HQFMEii79FywCOvlJsKxMg66iTyPzhLyIpPExUqVQicwkYVkDfKikpycrKunz5MhjzQDH/6quvjh8/jhsakV0pvcgjVOOu3lSGLo04wyrNy8tzOp1Op5OjyKPRHnWFTxBkpVWKK0Em1KSgdQMtZZqm1Wo1HL0Ifp6fn79u3brbb7+djeWH0Wq10Wj0+PHjwWAQtjM4HOLswnEtedL5jDiVyK82jUBiiWrxQeP85n8YDAY9Ho/ZbAavK1DzSZKEZP4SLr+Z7k7cMslEdcoRvBKSWXGehMjO7/dzljVJkjRNww1Mubm5oBupVKpgMAgJRTieoJyGJFCCPGGgq6VxNYoprUmDIBnJWSpgordYLIWFhbDtgJcqRN6CkTiNeMoEOYOZDIFmIkoJNQRqO03ToVAI7EQgU8KKD4fD4XC4tbV10qRJoNeTJAkHKjL9evgALISKAZEm94hRAQnMg8FgV1cXxF7n5+crlUqWZT0ej9FobG1t9Xg8kCpxrHU8GWcRTrgtn18mLdCAPgQLGtYAOkNCaiZJkm1tbRMmTCgsLHS5XMAJklsw0BF0Uo+iNQiMnSdRLadHKdaQKAgKvtAXCMwCB1az2ZyXl1dWVgbmEZfL5XA4BgcHYePKnPdFopCMux0njE6QoaYicYNZDomkwWAQv6yDIIjCwsK//e1vBw4c+OMf/wiGp7SsfhI7mEVVyalTeksZg8oHeMmAU9+4ceMgl1ttbW1XV9fp06fdbrfdbgc/o1HHPBkChfMbADmKKm7NHvUOi4FgR+TkBEDWSpldGwF6ldkEkKlSqQRXkqqqqmnTpuXm5oZCob6+vvr6eqvV6na7R9c+mowIn6gMOjKGqtECtPzS0kHcsE/EtmZcN89E1AfINuB5CMmFpkyZAil/v/rqK/CNSmOL+E4Vl5CSIVDB+IGEYAzueklDEmeS0rWh36Miv4J8lZubm5OTU11dbTKZjh492tHREQwGExWi0nLEkzCBgvFsLEgncmBkVkJyW4Qgbkmci2YCSJJUKBTZ2dm1tbVut9tqtUJaYCSYxqU8+JF6LxKWQYFAweKT9kEkSRKih5P73GAwwH3xREw0VCgUaEDHGttOLy1monckSUL8E2yYZrMZXHLh2nOxTSPNMo8cLDkESsZ8DeUsJvkAnpolJSWQ4gv8lUiSNJvN119/vcPhGDdu3DvvvLNq1ar29vZbb731lltuefDBB3t7exmGKSoq+n//7/8dPHjwvffeA988kiT1en1eXp5er2cYZnBwMBwOe71eTq5d+R1PC/B5LSnP4UtOzZlYfsCPiNiC12q1EF/qdrv5CSn4gnIaEJBGjtNnhAFEEUDkqxgrlS9OwRGRwWAwGo0QQ8xJtJSbmwtG+3A4XFBQoNVq165du3DhwrvuumtgYAAI7tprr/3xj3/8r//6r83NzUDZREzwLykpMZvNJSUlLMueP3/+8uXLiFI5oSwcxFIXoaSHRbAtVC2nJE7cfGsDGUtkkig+chDGmwbXHL1eb7PZOPGJYPSAEz5OpwgRcoo7gFKGev7H6AnuG5/KwgWHecjGzTAMpLrlj7Lf74d9X6lUQkKRCRMmsCxrt9vhvkOCICDl54MPPvizn/0M3dLJMIzT6fR4PCqVqr+//+677166dKndbj948OCZM2fA2odHX5GxyFI5M51cx8kYEDF/K+lMOGTs7hEmllySb5YGszE41qSdj3LqDIfDLpeLs7DBpwwcw5FrH4u5+RJJD1eK2CcHaHo0Gk1xcXEoFLLZbIFAQDDXOGRSgExgkD48Nzf3gw8+6O/vX7NmDfIpoSiqpqbm97///dNPP93Y2MiyLPAVkJiBCHQ63bhx4+rq6qqqqqLRqNVqPXXqVFtbGwgAqEUWg8z1HW+OEJ8/MpbsV4yUSZLUarUsy4KinXaEBYF/mkhiriq4U4TEGKbKQTMBMNxqtRqo02KxKBQKm82GlBtOYSDHoqKilpYWYK6RSCQcDufm5u7btw8vzLLsxYsX9+zZ8+ijjz755JMgyBMEAXciwuGC2+12uVytra15eXm1tbVz5sy54447tFrtkSNHGhsbbTYbxIWSsezM0rtEcnsWnxwRyQp+y4p7siIqDwQC0EHpptMI/OhZmdtOopCpWFJ+GRCxLRaLXq/Pz8+HnJ1ut3tgYMDj8fCXPpQvKirSarV9fX02mw21MnXq1N27d2/YsOGzzz7DxSCWZYuKijZt2vSb3/zmk08+wZkiB084RIXwzsmTJy9atKiwsNBqte7Zs6e7uxuEYLT60V+OdChBZIKLTfB53GGUY8NKr+I8YiBHQUz+niR8sqV3FmCEsL2CH93ly5eDwSAY1ZjYNZj4fqFUKsePHz9t2jSPx3Pq1CmHw4G/LSoqYhgG8jFxume1Wl977bXHH3/89OnT+CXyxJVzjBIceL1em8124sSJoqKisrKympqaWbNmNTQ0XLx4kSMNi6ksnC1betAlqE3sq+S4shwYI3Y3aRzSkPomrtwDwrLH42ltbWWELnHDORNs/VlZWeXl5Z2dna2trRwrAUmSVVVVHo+nvb0dfJM5kvjBgwe/9a1vPfHEEy+99JLdbufISagYEkyj0Sjg1tnZqdFoysvL4frarq4u/HMWc+7EeSoSv1gRmwD+hKZpNuY/hbrM58ScSnDnB8Ep4C8e6VmnsOsl0kuj1JXJ3SVAWrD5vwrThZk0gCCFchxzcMLHXaFQVFVVlZaWnj179vz589FoFKUYgS5RFDVx4kSCIPh+DFDA5XK9+uqrxcXF9957r8lkomLXHLJX3i/IGUTgqS6X69y5c0eOHAmFQuA6CQqKBIuCqsCswWBpo/kkBSFsFEWBCM7pu1grMHT4wuajwXkoh+Y46KUFcA1JDgKEDFRH9L74uKBUKqurq+fMmdPR0WG32ymKMhqNiEGizmRlZUFsDWg/8BBpu9FotL29/e23316xYsWaNWvMZjMl+z5WoAaXy9XR0UEQRFVVFRwciJlIBWlRAmDywAVT0CDKp85Em4gLYoIEcaUJLDlIu5400lq8GMAuWVZWVldXV19fPzAwAJwSchMTV86cwWDo7u6GPLcUdg8ssldHo1FIM7Z8+XKfz7dnz57h4WE5Z7PIVhIOh/v7+2marqysLCkpOX/+PCj4qZMIsHBYePKPtdILgjxY8HmK1aYOsoLm0t4qHxQKRW5ubklJyRdffNHc3EwQREFBwZQpUyBVMY4GFbsUHmYacVCCIKLRKLpEwel07t69++zZs2vXrr3//vsrKioMBgNQsDQmQN+gP7W2tjY2NgaDwZtuugnCJFLvKbhcQNpy4KO4gpUiA5MDI78exEAOJvEJFEXqiAF/QOMOMV+oLygoWLBgQSAQaGpqAmt8VVVVW1sbnvQGqVAajcZmsxEEwbKswWDA5TnwwIXfHR0dr7/++ubNm5cuXfrKK6/84Ac/WLJkSX5+PkiWYp1CLA20GZBKL1++PGvWLEj8lFBP+QDCLiT3Kikp0ev1KBxKZm1JDPjYBDloxydQvj7BLxD3iUQBhUKRk5OzaNEiu91+/PhxkDhNJtOCBQt6e3v5EhjInZAjnCCIG264QafTaTQayCiGrDwEQUQikYGBgU2bNn3nO9/ZuHHj+PHjX3zxxbfeeus//uM/brzxRohzwMdIUDiDnBGQIbaiooIzpklwI+gI5NgfGBjIy8tDDxNSL1JEIxOA2L/0ViCoIIqBrKjODBnMSJJUqVTFxcVz587t7e1taGgArZymaTgxdzgc/DmDFEuDg4MwqSaTyWAweDweOJQH4yWLmYTC4TBcbdPQ0FBRUTFnzpyZM2c+//zzNpvt73//+8GDB202W9zkU8FgsKWlpaqqSjBFchIAyENKRBzhMUJqyQFusiAkGaR8ikrDbccJLQgEFEXpdLqampolS5bYbDZIu0AQBJiZli5d+tJLL/FzN7AsC640Fy5cgCfAO4FeCd4Yod/RaNTpdJ45c6apqWnz5s3l5eULFy688847V6xY8fbbb9fX1wvmPsZr8Hg8vb29OTk5IP7K7ymAIP0xDANRlPxXGYKRNM6LNcQmki4gyZMk1DbK3wkNQ3RlXNO9Uqk0GAwzZ85csmQJ2B3R7RwGg+Huu+/evn17d3c33kPUKAidIJtGo1G4HLGrq0t63OEtKM5g77xw4cKuXbtuu+22J554wmKx7Ny5E26cF6sBfHVzcnIg0FTmWOEIyLErXQUOJEyg6NQEhAyapo1GI3AUUKgjkQjamgXtbQqFori4eMGCBVOmTNmzZw/EuUKFNE0vX77cZrPt3r1b0LOJJMmioiKUhJFlWZvNNn369NOnTwuW5wOiVJ/P197e/qc//clmsz344IORSOTAgQMoY5ngt8Fg0G63oxGQKDlmYSQ5qDQaRLpkUA5wZHm4LwJMjEBh4LzIYX7wAzLP5+TkLFu2TKvVbt68ubW1FfgWEG5paem8efNefvllr9cr1rHJkyfD1TPwpL29/ZZbbvn73//OIdC4QwDnOi6Xa8eOHdnZ2Q8//LDf76+vr8evdEHCPlpvnCtjEppvmSUlMMdVQPkVjhZIDA4c+crJG5z8WTz8Bd91hAf8CwCOmCzLQj4wnU5nNBorKioqKysdDse2bduGhobwpKlarfamm2767LPP+HchEJjcXV1d7fV6kftIb28vKFscmpYzeSCbDg0N/eUvfzGZTE8//fS4ceN27Njhcrlwqz5un0c/Ms2KcHkAJ8qvkS4lzR1kyvFpsDzjUwXKKVj1wJODIAiLxQI54c1mc1FRUXt7+44dOzgHMzRNV1RU5Ofnb968WWKzBi8nuBUJnvh8Po/HU15ezr9XUwJPBGDstNvt4AP1zDPPVFRU/O1vf4PU4IT43Q9owXDeIjsLceVKlg+czYdDqQlVlTRkevnJd6xOA4EKzjrcCYTskWfOnIHTbeBYYMXEuZHJZKqqqjp27BhcCCvWlsFgqKio2LVrF+5KfOzYserq6pMnT+IVkrxYdWklfXh4+De/+Y3dbr/nnntqa2s//PDDo0ePgp9/XGdCvGaOq3m6IF0VJl1PeklW/hClmYOi5glsLAKBgNVqheg2Mhb0gxOTWq0uKyvr7+8/deqUtK5jMBh0Ol1zczPOs1taWr71rW+RmM8eii6S3wuwSv7lL385duzYfffd9+ijj65atWrfvn0NDQ2XL1/2+Xyw6QuqfXhnxbTD5CATtC4TcCE7jSdVSLuVWT4NBAoJJiUKsBjwjwohhZXL5Wpra4O89ISIWyFJkhUVFRRF9fb24s97e3t9Pp9Go4HrZclE4htx2Y5lWb/ff/LkydbW1qqqqkWLFi1ZsmTp0qVtbW2nT58+ePDg0NAQx1zK3+jRE2LEJcVM7MvpNVagYcksgeJaJBnLWhgXOF0FLcpsNhcUFASDwZ6eHnzucTd7NO4URS1YsCAajTY1NeE1wwk+wzBwk3sgEED+JRKKNhm7wAlJmUDWYCY7fvz4yZMnx48fX1VVNW/evBUrVixfvnz//v0ff/wxGNE42zrKtiI9o+miIRgclFtZjLvzQX7rEiVTWX6J8uNkCBQi4tlYMJdMAyTqFfxQqVSQ8Nfj8fT19fEPcnBWBH9pmq6trWUYhiOnovAPiCfBjUQUdpsRH8BvQ+JVR0dHd3d3fX19cXHxsmXLli5dmp+f/49//AO/a5BlWYZhIEccihIRa1F6UmWSLxxnFBYWwkXzXq+Xs6WkDoJowHpAHtx4/HtC1SZE2ckY6tlYbANOQzK/hR7qdLrCwkKDwWC323t7e/mXnyLgPK+srIQrvPCHcDgEx0ug0MBQAskK+vATvI0GrQQSiz5jGAaac7lc7e3tkydPXrdu3QsvvPDrX//67NmzuKIWDoe1Wi1ctxz3TjcJ/sqxcbK8q5hIkjQajfPnzydJsqenJxwO829HTjvAeIKRGzpLiEuT6RVvkjHU4/TEsYPE/Rb6WVVVZbFYTp8+PTQ0BLu5TM5hMpnA3skR+yCDNT8uAk5i2XgBxAg3JChzUGIYxuv1nj59+rXXXvve9763evXqoaGh/v5+lAEFrsPT6/Umk8nn86ETdn4XxOYPli5N0yaTCRLvQ7ArTdM6nS4YDPr9fhDZJ06c6Ha7m5ubIbQ605Iu8gOMxiC9gmmc1pP4hqMlCKo+wo1RFBgyS0tLL1y4AFecM7G7tgSBxAC86SAWlFMMBYgilIAoYc/V6XSw+kHoBAMtv1GOBMkvEI1Ge3p6Nm3apFarb7vttrKyMkAJvfX5fEqlEm4HRaI5px6VSqVWq9GRGxiMUcpjo9Go0WjgADk7Ozs7O7u4uBhuCy8oKCguLs7LywP3P4fDAZkaMpesAclISDoXiyrDISEdKC6kJ+SDH3nM2ZXgN7iRz58//9SpUz09Pbh2wqmQjMXHoW+hDCgonCmHTUdsXBiGUavVKB8LYgP8khyuLLiFMQwDJ/jFxcW5ubkDAwO4FAs+UxaLpaSkpKenB0+1h9egUqlQGiPEU4EaAoEA8EVYkCqVanBw0OfzDQwMAEGr1Wp0Aodjy+8LykdCJEU05JWZozNhIpADaSBQ/i4j9m9WVtacOXNge+KkmsHLI8pAhAuDFQwGL168WF1dDTsg/pWYokbGHDvcbjcuAAgOt3Qv8LZaWlouXryoUqk40jMslYGBgZKSkoqKCrhqjKPy82VoRL6wiaOmUZo+lmV9Ph9FUR6PB5y5dDodyn8m2GuNRgOjhHieYF8kAJeLRhHSENUps/MURU2YMIGiqPr6+rh2U078LnLpHRgYAI8Tzidi6iRsTHAahO9NSTMDhA/4Q/EXRiQSGR4evnjxos/nq6yszMvL02g0gjIMLo/iiImtE5D+vV5vIBCAZIDg7cCvFjru8/nQhaXJdZZf7chXkgYCldMqSZJwEN/Z2YlnQ5APQF45OTkQEhmX/yEAHX8ktydgeJ2dnQMDA2VlZRMnToTAIzRQyMKQKFZg/PL7/XAZF6hTHDs0kDjcfJKuIOCEVGEJSGIWRiguXqVSVVRUOByOtrY2MUfPuJVA0KZCoSgqKuJrOWI1sCkktUplVsLhcF9f36VLlyiKKigoQAGcyI1GfpQcANL8IpFIKBRyu92RSASuNuRXxZeapCuXLpBevSchSIZAcZMhIWN5gXmosLCwra1NzBdEDrUBy7FarXPnzi0oKMDLSOAgk0CRrQAdzwAlydwfBBGIRCJDQ0MXLlwIBAJGoxFdkgkSAjruSpRSiZiACIKpTqdDd28ms4dSFIR5idWQLvaZHIxEwxDJjnvaJwEkSebm5u7cufN//ud/wOt548aNyCYKJ5bSZ1polCXUUlxzB62ZY/QVYyRIGxNkNhRFaTQaSBwp2GhC/Im80kKCziPwseVbD/BPiFhSZkjqZrFYfD6fnODBkYeRyCxCkqTb7eZfVp4olJeXm0ymY8eOqVSqJ598srS0tKmpCREEJ4sYH+Qo6SyWrQ6UdP5bfO5xDYZhGDxHM/4heO8ndzsKn3w5dgPQtTl2MTybAQcfkiRpmjabzUql0mKxwMNgMJiEC9gIQEYIFJ88GDLpmEk5VSkUipkzZzqdTsiG3NzcPHfu3JaWFpgeZFwEesW1Y+nK+QVghoDnQQZ+/K0gdaJXLMuqVCrOxY0AsHhkCgxJKE+Cz6nY7aN44AMZ84UgSdLlckHEtsRdA6MLGfQHTa/ep1Qqb7jhhsuXL4dCoUAg0NnZuXTp0r///e8+nw8VU6vVsM/SNA1mIEJyw2LFo9H5eXUEseI/p2lao9HwM+8Bi82cMMc3n+EpgzjrFoII8HyDGcIqdUiPmUlw3HEGFndi4vrsmUymmpqaEydOgPWkra2tqqqqqKgIfQgJaQH8fn84HJZDDWhD5PSCZVm/3y9oaMSBrzsjIyVN05w6xbxUpWWPpKkHxh8axY2sIBXAXRRj8P5tDiRPoGTMucFiscBZIlIDkQ2FjPlcctRhvgKORCh+AYIgKIqaNWuWxWK5ePEiFOvu7nY6nStXrkTqJxNLXx8Oh4FYkVOpnO7wFXZwUIr7OacvkA4XhDyNRsNfeHFREtSjpQvEBX4NcelSTJ3n40+KAPIpE9uI5EDyWzxk+MjLy5s/f34wGDx27Bi6wxnpGaBd0jQNWgK6vIa88tSbXznnoU6ne+qppwKBwBdffAHKls/nGxwcrKure/fdd3EfULwGUjxtO76zi6neTCzfrITeICiG+v3+UCiEbjRFs4XWMMflIi7LTLSAHDyly8tsRUxAwsunyKGTJ1A4HO/v729sbJw9e/bq1auzs7NdLld3dzfsjCCGa7XaSCRSUFAwODh46NCh7u5uh8MRjUYFr/UgeIsb6qmpqZk2bdr//u//9vf3A7n4/f7t27f//Oc/X7JkyZYtW5Aqw14ZoSsxOpzBFZSk3W53clIjg2WygLNZ2G3UanV5eXkoFBoeHgY2j67XIbAY7jG+7XIAjaQ0vSZZeUofkyRBEEqlUqPRjBs3rra2dsaMGTNmzAAvB5DhtFqtTqeDGVKr1T6f7+TJkx999NG5c+cE3Rnx3sInM2bM+NnPfjZ58uTVq1efOHECqcMFBQUbN25UqVRr167Fg+LxbUjC3QHJFbh0wY+CohK5Cx7/EC62QnQJ2aKzsrKmTZtWXl6O1Knu7u7m5uahoSGfzwcxTw6HYwzaIznA5yOCD1NfbGnzAAA+odVqp06dOjg4GAwGg8EgXL9psVgGBwf1en15efn8+fPr6upCodC+ffs+/fRTuEyDiClJSGWBCAqz2Txx4sQf/vCHs2bN2rp16zPPPAOKORHjrIsXL/7tb3+7YsWKtrY2kme+Brsj2mcJ8SknMcdHTpkkwojJK8NKKYqiaRqd1lAUpdVqKYoymUwFBQVVVVUGg4EgCNDtBgYG9uzZA0aAuJ6XYxA4s0CkvMzSQKBoCslY5BCL3XcBjBDyycM1jzU1NQ8//HBNTY3b7X7//fe//PJLyEIIvFav1xsMhqKiIshBUlNTYzQat23btnHjxpaWFsThQKQzm807d+78yU9+snfvXuLKsSBJEo6/wftTOlSIjJ3HcOJsEGdFhBJXvUAiAX9nQGwG7wI4fQKv1Wg0Op3O6XRClDPylkKNZmgbxbESg9FaJ+k01EMfcMUCnqCgCLi8q76+vrOzc+bMmbfddtuqVauuv/56hUIBBKpWqw0Gg8FgALdzv99/4cKF999//9ChQxAcwmkuEAgMDg6OHz+eFDoCCYfDuP4oQVtszEiJMCexgDtpQVam/sEncbCNI39ntBEBu9XpdKAL8nudnFgsDXGr5fdUjikgdUhPZhEcUb7uhivsQApwfRaIrWAPCgQCGo3G7/d3d3c3NDR4vd6LFy92dHR0dnYODw+jSGIE8C/EK4M1FPduhoY4jBO3jwiqqOAthcZdkOkmoQ7zGxL8FzUKyxjO3gT5ZYbIgi9TSjc0Mjx1hM7iiSvPhObNm/fMM89MmDBh+/btx48f7+3ttVqtcHIDHuk+nw/MyBJbM7y6cOFCZWWl2EG8oMyOb9yc8nIE1kwDG4tLGZXWiZhUxnc9GRXISG4mwRgjxMZyc3M3bNiQlZX1wgsv7NmzB248Ak8LKnaFq0zFmWXZ4eHhgoICCG8QwwdhFdcyl/oGKkdIHfn5lr/kgDrHjnKWEQ7K35IgnpogCKPReOutt+bn5//yl7/cunUrLmOBFZD/uQSQJAlXuuh0OnAyl48VXglxpSKCv0p0nsbIvOKQEHVS2J2Oo7KWODBCHvXAIDUaTU1NzfTp0zdv3rx7926cOvnKshxOxrLspUuX9Hp9WVmZWHmxqoBhg7VSUANItI/yIe2VcyrELQZ8b2jpgeKc3UuUTMLPOgkYOQIlYhcn7N+/f9u2beiGLgA+0xUz03CKXbp0yWq18i+I4VeFhlWhUGi12uzsbL1eD8IWG0syxdGicLlZsP4kZigTPElQi8LXvKDOyq9EpuUVKbsjwF9HiECBODQajdfr/eKLL2w2W6KOsfig4+ByuZqbmxctWsS/ZYuDAMQ2qNVqrVZL0zQE04E7D6JOiclLCNu4fRkB3sNikOm2MgcjeplsJBKBhCIej0e6pOD8IR2cwBhqOByur6+H4EkJnz2WZSFUDdKN+P1+j8cD50xQFSsZBs6yrGDlScx9XNJMC+1+rYkSh5EgUDTiPp/P5XIJKuky5SSCt/lGo9GGhgabzXbPPfcYjUa0TZMYQEnIsxUOhyEkF9wAEHVKb1hAoGlkexJMVGY6y38SGLmxgEwvsKXyb2XlTL8cJQnRk8vl2rx5c2Vl5eLFiyG3EcS7cWrA9ztEu/KtWqRQJlSZJEvyQKKPEukY/glhRBcrYhucQB8EaBpILPxXTDtBEIlEjh8/Pjw8fN9990GWBPAU5khgeOUIH04B6YUh+FaadMjYKT8iSuTNzV7po40A/BYkBicTgOMpPeAS+GQCw5EgUFzpA2rge9lxbk7H71IX5G0cDcDhcDQ0NJSUlEyYMAHyw/BDwDhqFr9mCX2CjV2iJ/8TTt+h++AELd01wcSwmdZ12CvTDQkWgB/4AIqVSSNkhEDjsqL09gSoZ+fOnZcuXVq2bJnRaJRgA+gTPg7oKyoGqbMEUobPufznowscAWlkGs0IgUosRJmQRP+dTudnn302adKkwsJCUtJgFJcs0ObLWWkJSZzgSgfOhxKFxxQtykFmhBEeIRmU0ys5ol5CNMqybDAYBL+T6dOnC8pScipESwvts0g44/dCEG0wZqnVarVaDbqa/F6kCzItHY4kjY6ORYNPr/iuSsauUUQgIbwjgCvCenp6Zs+eDeFQnEzKEmxVsGacoYqVQZ9zUGUYBuKNBBNNCnJlvAaOjBG37+grOLkVPN4U3BMkxkF68McU408/xOWgEMSTaJ1KpfKuu+46ePCgyWTKNBeRQGNkGvongVGzCUssQTaW50h+bUAW0Wi0ra0tOzvbaDSmA8dkINPq9j8bjNFDC/mZjAgs/Ihl2f7+fp/Pl5eXd5WNfTNgjBIoIX78jQBJSFqtVqVSgU7jdDrb29tLSkrSaCRKpYDMMumtQbA8Ls7y5dExu55HIuQjaRCT50DcRBkuSZKEq7OhsNVq1ev1kGUODzAneSZJCbUJIK7ajrz1cDu2oIVVoiqSF07OaR3GAS+DeiRmzeUodiipCb7mwXWGn8QeDRRflx156WXkYpKIRNzMyJjBnLjSUQNGjaIoi8WSnZ3NsqzX63W5XBRFqdVqcE3au3dvWVlZQUGBz+dzOp3ohhpET2igce9xVihCTZB0BJV6Eju65ITSo1eC64RDfHw9mohlKIEneAYyVJg/wjhpQkCzVqvVarUEQYCfOBXLRO7z+SDKGUXdwIccFwX+xEknBfp6Q0Y3lIKCghtvvNFsNufm5uJTOGZ3sTQCKeLoztnQOa/kV54GFL8WkMowxQWlUpmdna3RaHACTa4J6U/G4IRJUKfEV2N59Y4JQ316Aa57gyB3vtyWRhib5iS+4Mh/KP3JmILRUZL44nbaxwgkTjE1IkONijWEQE6LSWSDwpsDdojEVlQV/y//8zFIqaNDoLjyK7jEBTXZuDo1+o0O0/n6B2fupRkMp07BApzneJ58XOxjY7fh4Ho0h3qgQoiX4mSskOMGQGBXumu1WhQMCK7i8Bc9IbHLJvlq39ih4NEh0Exrf2jik85BICaTiWnceNP4D7A54DgIGgFwAGdZabOUoKDJxjJMgXEDCJHCLh7B86YIupwKdlOwwFVIA8TNMP/1BfJKGG10rsJVuApX4SpchatwFa7CVfgGwf8HBvJjwJAMC0wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x7F56717EA6A0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_regions(test_channels, False, disk_center, True, 80, \n",
    "                   True, [45,50], 'dark_center', \n",
    "                   image_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552faf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_regions(test_channels, True, disk_center, False, 80, \n",
    "                   False, [45,90], 'dark_center', \n",
    "                   image_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_regions(test_channels, True, disk_center, False, 80, \n",
    "                   False, [45,90], 'dark_center', \n",
    "                   image_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original model\n",
    "    train(data_dir, 0, [0,0], 'none')\n",
    "    \n",
    "    # skeletonized control\n",
    "    train(data_dir, 0, [0,0], 'none', skeleton =True, shadow = False, shadow_ring = False)\n",
    "    \n",
    "    # training 6 skeleton & shadow (no ring) models for experiment #2\n",
    "    \n",
    "    train(data_dir, 45, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # ---------------------\n",
    "    \n",
    "    train(data_dir, 45, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    train(data_dir, 60, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 60, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    train(data_dir, 90, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # --------------------- training\n",
    "    \n",
    "    train(data_dir, 90, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # training 2 skeleton & shadow (with ring) models for experiment #2\n",
    "    \n",
    "    train(data_dir, 0, [45, 90], 'dark_center',skeleton=True, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [45, 90], 'dark_background',skeleton=True, shadow = True, shadow_ring = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05f7ff70",
   "metadata": {},
   "source": [
    "#### Lambda Transforms Style :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2419fde",
   "metadata": {},
   "source": [
    "### Train Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4a6845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, radius, ring_radiuses, region, skeleton=False, shadow = False, shadow_ring = False,\n",
    "          num_classes=2, batch_size=64, num_epochs=50, lr=0.001, image_size = (224, 224)): \n",
    "    \n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") # \n",
    "    if device == 'cuda:1': # using all available gpus\n",
    "        torch.cuda.empty_cache()\n",
    "    if skeleton is True: # Experiment #2: skeleton true, shadow true\n",
    "        shadow = True\n",
    "        f_params = f'./outputs/checkpoints/model_shadow_regions_{region}_{radius}_skeletonized_epoch{num_epochs}.pt'\n",
    "        f_history = f'./outputs/histories/model_shadow_regions_{region}_{radius}_skeletonized_epoch{num_epochs}.json'\n",
    "        csv_name = f'./outputs/probabilities/shadow_regions_{region}_{radius}_skeletonized_epoch{num_epochs}.csv'\n",
    "    elif shadow is True: # Experiment #3: skeleton false, shadow true\n",
    "        f_params = f'./outputs/checkpoints/model_shadow_regions_{region}_{radius}_epoch{num_epochs}.pt'\n",
    "        f_history = f'./outputs/histories/model_shadow_regions_{region}_{radius}_epoch{num_epochs}.json'\n",
    "        csv_name = f'./outputs/probabilities/shadow_regions_{region}_{radius}_epoch{num_epochs}.csv'\n",
    "    else: # Original training: skeleton false, shadow false\n",
    "        f_params = f'./outputs/checkpoints/model_original_epoch{num_epochs}.pt'\n",
    "        f_history = f'./outputs/histories/model_original_epoch{num_epochs}.json'\n",
    "        csv_name = f'./outputs/probabilities/original_epoch{num_epochs}.csv'\n",
    "        \n",
    "    # fix these transforms w/ new optic disk. Done.\n",
    "    \n",
    "    optic_disk_csv = \"../../optic_disk/DeepROP/quality_assurance/QA.csv\"\n",
    "    QA_csv, checksum_dict = checksum(optic_disk_csv)\n",
    "    \n",
    "    train_transforms = transforms.Compose([transforms.Lambda\n",
    "                                      (lambda img: shadow_regions(img, skeleton, determine_image_center(img, image_size, QA_csv, checksum_dict), \n",
    "                                                                  shadow, radius, shadow_ring, ring_radiuses, region)), # image size pre-defined\n",
    "                                           # transforms.Resize(image_size),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.RandomVerticalFlip(),\n",
    "                                           transforms.RandomRotation(25),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                                [0.5, 0.5, 0.5])]) # why this normalizing?\n",
    "    \n",
    "    test_transforms = transforms.Compose([transforms.Lambda\n",
    "                                      (lambda img: shadow_regions(img, skeleton, determine_image_center(img, image_size, QA_csv, checksum_dict), \n",
    "                                                                  shadow, radius, shadow_ring, ring_radiuses, region)),\n",
    "                                          # transforms.Resize(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                               [0.5, 0.5, 0.5])])\n",
    "\n",
    "    train_folder = os.path.join(data_dir, 'train') # only training on segmentations      \n",
    "    val_folder = os.path.join(data_dir, 'val')\n",
    "    test_folder = os.path.join(data_dir, 'test')\n",
    "    \n",
    "    print (\"Train/Test/Val datasets to be created. Thank you for your patience.\")\n",
    "\n",
    "    # I guess this automatically creates 3 channels\n",
    "    train_dataset = datasets.ImageFolder(train_folder, train_transforms)\n",
    "    val_dataset = datasets.ImageFolder(val_folder, test_transforms)\n",
    "    test_dataset = datasets.ImageFolder(test_folder, test_transforms)\n",
    "    \n",
    "    print (\"Train/Test/Val datasets created.\")\n",
    "\n",
    "    labels = np.array(train_dataset.samples)[:,1]\n",
    "    \n",
    "    # what even does the below code do?    \n",
    "    labels = labels.astype(int) # idk what changed 6/17/22?? going from 0 and 1, to 1 and 2 labels. Ok, fixed. ipynb checkpoints!!\n",
    "    black_weight = 1 / len(labels[labels == 0]) \n",
    "    white_weight = 1 / len(labels[labels == 1])\n",
    "    sample_weights = np.array([black_weight, white_weight])\n",
    "    weights = sample_weights[labels]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
    "\n",
    "    print()\n",
    "    print(f'Data Directory: {data_dir}')\n",
    "    print(f'Skeletonize: {skeleton}')\n",
    "    print(f'Shadow: {shadow}')\n",
    "    print(f'Number of Classes: {num_classes}')\n",
    "    print(f'Number of black eyes: {len(labels[labels == 0])}')\n",
    "    print(f'Number of white eyes: {len(labels[labels == 1])}')\n",
    "    print(f'Batch Size: {batch_size}')\n",
    "    print(f'Number of Epochs: {num_epochs}')\n",
    "    print(f'Initial Learning Rate: {lr}')\n",
    "    print(f'Device: {device}')\n",
    "    print()\n",
    "\n",
    "    # maybe increase size of validation set??\n",
    "    \n",
    "    checkpoint = Checkpoint(monitor='valid_loss_best',\n",
    "                            f_params=f_params,\n",
    "                            f_history=f_history,\n",
    "                            f_optimizer=None,\n",
    "                            f_criterion=None)\n",
    "\n",
    "    # accuracy on train/validation?\n",
    "    \n",
    "    train_acc = EpochScoring(scoring='accuracy',\n",
    "                             on_train=True,\n",
    "                             name='train_acc',\n",
    "                             lower_is_better=False)\n",
    "\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    callbacks = [checkpoint, train_acc, early_stopping]\n",
    "\n",
    "    net = NeuralNetClassifier(PretrainedModel,\n",
    "                              criterion=nn.CrossEntropyLoss,\n",
    "                              lr=lr,\n",
    "                              batch_size=batch_size,\n",
    "                              max_epochs=num_epochs,\n",
    "                              module__output_features=num_classes,\n",
    "                              optimizer=optim.SGD,\n",
    "                              optimizer__momentum=0.9,\n",
    "                              iterator_train__num_workers=16,\n",
    "                              iterator_train__sampler=sampler,\n",
    "                              iterator_valid__shuffle=False,\n",
    "                              iterator_valid__num_workers=16,\n",
    "                              train_split=predefined_split(val_dataset),\n",
    "                              callbacks=callbacks,\n",
    "                              device=device)\n",
    "\n",
    "    print (\"Model Fitting\")\n",
    "    net.fit(train_dataset, y=None)\n",
    "\n",
    "    img_locs = [loc for loc, _ in test_dataset.samples]\n",
    "    test_probs = net.predict_proba(test_dataset)\n",
    "    test_probs = [prob[0] for prob in test_probs] # probability of being black\n",
    "    data = {'img_loc' : img_locs, 'probability' : test_probs}\n",
    "    pd.DataFrame(data=data).to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171174a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "186f12ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-ad753cd13b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# original model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# skeletonized control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if not os.path.isdir(os.path.join('outputs', 'probabilities')):\n",
    "        os.makedirs(os.path.join('outputs', 'probabilities'))\n",
    "    if not os.path.isdir(os.path.join('outputs', 'checkpoints')):\n",
    "        os.makedirs(os.path.join('outputs', 'checkpoints'))\n",
    "    if not os.path.isdir(os.path.join('outputs', 'histories')):\n",
    "        os.makedirs(os.path.join('outputs', 'histories'))\n",
    "\n",
    "    data_dir = os.path.join('dataset')\n",
    "\n",
    "    # original model\n",
    "    train(data_dir, 0, [0,0], 'none')\n",
    "    \n",
    "    # skeletonized control\n",
    "    train(data_dir, 0, [0,0], 'none', skeleton =True, shadow = False, shadow_ring = False)\n",
    "    \n",
    "    # training 6 skeleton & shadow (no ring) models for experiment #2\n",
    "    \n",
    "    train(data_dir, 45, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # ---------------------\n",
    "    \n",
    "    train(data_dir, 45, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    train(data_dir, 60, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 60, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    train(data_dir, 90, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # --------------------- training\n",
    "    \n",
    "    train(data_dir, 90, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # training 2 skeleton & shadow (with ring) models for experiment #2\n",
    "    \n",
    "    train(data_dir, 0, [45, 90], 'dark_center',skeleton=True, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [45, 90], 'dark_background',skeleton=True, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    # ---------------------\n",
    "    \n",
    "    # training 6 no skeleton & no shadow (no ring models for experiment #3) -- 4 already succesfully done??\n",
    "    \n",
    "    train(data_dir, 45, [0,0], 'dark_center',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 45, [0,0], 'dark_background',skeleton=False, shadow = True, shadow_ring = False)\n",
    "\n",
    "    train(data_dir, 60, [0,0], 'dark_center',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 60, [0,0], 'dark_background',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # ------------------------\n",
    "    \n",
    "    train(data_dir, 90, [0,0], 'dark_center',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 90, [0,0], 'dark_background',skeleton=False, shadow = True, shadow_ring = False)\n",
    "\n",
    "    \n",
    "    # the shadow rings now\n",
    "    \n",
    "    train(data_dir, 0, [45, 90], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [45, 90], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    # -------------------------\n",
    "    \n",
    "    # time for the new shadow rings, Experiment 4\n",
    "    \n",
    "    train(data_dir, 0, [0, 30], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [0, 30], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    train(data_dir, 0, [30, 60], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [30, 60], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    train(data_dir, 0, [60, 90], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [60, 90], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "        # --------------\n",
    "    \n",
    "    train(data_dir, 0, [0, 15], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [0, 15], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    train(data_dir, 0, [15, 30], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [15, 30], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    train(data_dir, 0, [30, 45], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [30, 45], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "            # --------------\n",
    "    \n",
    "    train(data_dir, 0, [45, 60], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [45, 60], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    train(data_dir, 0, [60, 75], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [60, 75], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    train(data_dir, 0, [75, 90], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, [75, 90], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    \n",
    "    # also I had the skeleton = True image sets for the above.\n",
    "    \n",
    "    # ----------------- time for Experiment 5. I have done most of this already. \n",
    "    # 0 - 15, 0 - 30, 0 - 45, 0 - 60, 0 - 90 are done. I just need to do 0 - 75, 0 - 105, 0 - 120 \n",
    "    # 120 is for: (maximum width is 112, but for outer regions)\n",
    "    \n",
    "    train(data_dir, 75, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 75, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "\n",
    "    train(data_dir, 105, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False) \n",
    "    train(data_dir, 105, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    train(data_dir, 120, [0,0], 'dark_center',skeleton=True, shadow = True, shadow_ring = False) \n",
    "    train(data_dir, 120, [0,0], 'dark_background',skeleton=True, shadow = True, shadow_ring = False)\n",
    "\n",
    "    # and now double for skeleton = False.  \n",
    "    \n",
    "    train(data_dir, 75, [0,0], 'dark_center',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    train(data_dir, 75, [0,0], 'dark_background',skeleton=False, shadow = True, shadow_ring = False)\n",
    "\n",
    "    train(data_dir, 105, [0,0], 'dark_center',skeleton=False, shadow = True, shadow_ring = False) \n",
    "    train(data_dir, 105, [0,0], 'dark_background',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    train(data_dir, 120, [0,0], 'dark_center',skeleton=False, shadow = True, shadow_ring = False) \n",
    "    train(data_dir, 120, [0,0], 'dark_background',skeleton=False, shadow = True, shadow_ring = False)\n",
    "    \n",
    "    # experiment 6, working with 3 double rings. Already done the 0 - 45 and 90 - 45 double ring (just a 0 - 90 ring)\n",
    "    \n",
    "    train(data_dir, 0, 2, [[0,15],[75,90]], 'dark_center',skeleton=True, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, 2, [[0,15],[75,90]], 'dark_background',skeleton=True, shadow = True, shadow_ring = True)\n",
    "\n",
    "    train(data_dir, 0, 2, [[0,30],[60,90]], 'dark_center',skeleton=True, shadow = True, shadow_ring = True) \n",
    "    train(data_dir, 0, 2, [[0,30],[60,90]], 'dark_background',skeleton=True, shadow = True, shadow_ring = True) \n",
    "    \n",
    "    \n",
    "    train(data_dir, 0, 2, [[0,15],[75,90]], 'dark_center',skeleton=False, shadow = True, shadow_ring = True)\n",
    "    train(data_dir, 0, 2, [[0,15],[75,90]], 'dark_background',skeleton=False, shadow = True, shadow_ring = True)\n",
    "\n",
    "    train(data_dir, 0, 2, [[0,30],[60,90]], 'dark_center',skeleton=False, shadow = True, shadow_ring = True) \n",
    "    train(data_dir, 0, 2, [[0,30],[60,90]], 'dark_background',skeleton=False, shadow = True, shadow_ring = True) \n",
    "    \n",
    "    # experiment 7, modified train function. only available in train1.py\n",
    "    \n",
    "    train(data_dir, [0, 60], 'skeleton_background', '#7(half_skeletonize)')\n",
    "    train(data_dir, [0, 60], 'skeleton_center', '#7(half_skeletonize)')\n",
    "    \n",
    "    train(data_dir, [0, 30], 'skeleton_background', '#7(half_skeletonize)')\n",
    "    train(data_dir, [0, 30], 'skeleton_center', '#7(half_skeletonize)')\n",
    "    \n",
    "    train(data_dir, [0, 15], 'skeleton_background', '#7(half_skeletonize)')\n",
    "    train(data_dir, [0, 15], 'skeleton_center', '#7(half_skeletonize)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59d518ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 23 20:57:10 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   57C    P0    60W / 149W |  10906MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K80           Off  | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    74W / 149W |    140MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla K80           Off  | 00000000:85:00.0 Off |                    0 |\r\n",
      "| N/A   90C    P0   128W / 149W |   2700MiB / 11441MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla K80           Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    74W / 149W |   6932MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
