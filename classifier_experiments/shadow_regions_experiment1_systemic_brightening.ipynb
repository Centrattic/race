{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccc8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import hickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageChops, ImageDraw\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numba import jit, cuda\n",
    "from utils import systemic_brightening\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993fee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/experimental/loss_scale.py:208: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "# set directory\n",
    "os.chdir(\"/users/riya/race/classifier_experiments\") # which one? yep\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import model\n",
    "segmentation_classifier = keras.models.load_model('models/MIMIC-256x25680-20-split-resnet-Float16_2-race_detection_rop_seg_data_rop_seg-0.001_20220321-054140_epoch:011.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513a2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.zeros((4546, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcfa453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2b81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_id(img_path, path_name):\n",
    "    arr = np.array(Image.open(img_path + path_name))\n",
    "    resized = cv2.resize(arr, (256,256))\n",
    "    channels = np.repeat(resized[:, :, np.newaxis], 3, axis=2).reshape((256,256,3))\n",
    "    \n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95f33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_from_id(img_id, race_csv_path):\n",
    "\n",
    "    \n",
    "    race_data = pd.read_csv(race_csv_path)\n",
    "    img_row = race_data.loc[race_data['image_id'] == int(img_id)] # they both must be ints\n",
    "    img_row = img_row.reset_index(drop=True) # for .at to work\n",
    "    img_race = img_row.at[0,'race']\n",
    "    \n",
    "    return img_race    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e649d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through classifier\n",
    "\n",
    "@jit         \n",
    "def predict_on_images(img_path, preds_df, colname,\n",
    "                     skeleton, thresh_type, intensity_change, brighten_sum,\n",
    "                     csv_name = \"brightened_predictions\", \n",
    "                     preds_path = \"/users/riya/race/classifier_experiments/predictions/experiment1_plus_systemic_brightening/\", \n",
    "                     race_csv_path = \"/users/riya/race/csv/image_race_data.csv\"): \n",
    "    \n",
    "    img_files = os.listdir(dataset_path)\n",
    "    num_images = len(img_files) - 4500\n",
    "    \n",
    "    id_arr = [0] * num_images\n",
    "    race_arr = [0] * num_images\n",
    "    img_arr = np.zeros((num_images, 256, 256, 3))\n",
    "    \n",
    "    preds_arr = [0] * num_images\n",
    "    \n",
    "    for i in tqdm(range(num_images)):\n",
    "        channels = image_from_id(img_path, img_files[i])\n",
    "        modified_img = systemic_brightening(channels, skeleton, thresh_type, intensity_change, brighten_sum,\n",
    "                                           image_size = (256, 256))\n",
    "        modified_img = np.array(modified_img) # .reshape((1,256,256,3)) np reshape, bc substitute? \n",
    "        img_arr[i] = modified_img\n",
    "                       \n",
    "        # getting id     \n",
    "        img_id = re.findall(r'\\d+', img_files[i])[0] # only one number\n",
    "        id_arr[i] = int(img_id) # be sure it's int\n",
    "        \n",
    "        # print(type(id_arr[i]))\n",
    "        \n",
    "        # getting race\n",
    "        img_race = get_race_from_id(img_id, race_csv_path)\n",
    "        race_arr[i] = img_race\n",
    "    \n",
    "    preds_df['id'] = id_arr\n",
    "    preds_df['race'] = race_arr\n",
    "  \n",
    "    # getting prediction    \n",
    "    prediction = segmentation_classifier(img_arr)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        preds_arr[i] = prediction.numpy()[i, 1] # returning the white prediction for each image\n",
    "  \n",
    "    preds_df[colname] = preds_arr           \n",
    "    preds_df.to_csv(preds_path + csv_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02042bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.DataFrame(columns = ['id', '30', '60', '90', '120', '150']) # from id I can get race\n",
    "\n",
    "dataset_path = \"/users/riya/race/dataset/segmentations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac833fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:07<00:00,  6.00it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_images(dataset_path, all_predictions, '30', False, 'below', 'brighten', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0cfb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
