{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b3ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695b6c6",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48e4c4",
   "metadata": {},
   "source": [
    "#### Very useful to mark succesful training\n",
    "\n",
    "https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842628d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/riya/race/gancode/GANTests_March'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b4be22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/riya/race/gancode/pytorch-CycleGAN-and-pix2pix'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/users/riya/race/gancode/pytorch-CycleGAN-and-pix2pix/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1521809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: True                          \t[default: False]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: /users/riya/race/gandataset   \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8100                          \t[default: 8097]\n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 100                           \t[default: 1]\n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 3,0                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 1.0                           \t[default: 100.0]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 2e-05                         \t[default: 0.0002]\n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: raceGAN_final5                \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 1623\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/raceGAN_final5/latest_net_G.pth\n",
      "loading the model from ./checkpoints/raceGAN_final5/latest_net_D.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 175, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 95, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 710, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 398, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 239, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 1281, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 1327, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 1276, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 1042, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 980, in send\n",
      "    self.connect()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 205, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 187, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fd0c83eb710>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 786, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8100): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd0c83eb710>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 590, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8100): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd0c83eb710>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /usr/local/bin/python -m visdom.server -p 8100 &>/dev/null &\n",
      "create web directory ./checkpoints/raceGAN_final5/web...\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0000200 -> 0.0000198\n",
      "(epoch: 100, iters: 100, time: 0.221, data: 0.139) G_GAN: 1.044 G_L1: 0.123 D_real: 0.618 D_fake: 0.426 \n",
      "(epoch: 100, iters: 200, time: 0.222, data: 0.002) G_GAN: 1.150 G_L1: 0.219 D_real: 0.873 D_fake: 0.436 \n",
      "(epoch: 100, iters: 300, time: 0.222, data: 0.001) G_GAN: 1.330 G_L1: 0.324 D_real: 0.571 D_fake: 0.351 \n",
      "(epoch: 100, iters: 400, time: 0.644, data: 0.001) G_GAN: 1.134 G_L1: 0.154 D_real: 0.887 D_fake: 0.400 \n",
      "(epoch: 100, iters: 500, time: 0.224, data: 0.001) G_GAN: 0.758 G_L1: 0.095 D_real: 0.699 D_fake: 0.737 \n",
      "(epoch: 100, iters: 600, time: 0.221, data: 0.002) G_GAN: 1.048 G_L1: 0.335 D_real: 0.690 D_fake: 0.486 \n",
      "(epoch: 100, iters: 700, time: 0.221, data: 0.001) G_GAN: 1.196 G_L1: 0.198 D_real: 0.566 D_fake: 0.446 \n",
      "(epoch: 100, iters: 800, time: 0.290, data: 0.002) G_GAN: 1.051 G_L1: 0.287 D_real: 0.358 D_fake: 0.537 \n",
      "(epoch: 100, iters: 900, time: 0.223, data: 0.001) G_GAN: 1.230 G_L1: 0.497 D_real: 0.116 D_fake: 0.518 \n",
      "(epoch: 100, iters: 1000, time: 0.222, data: 0.001) G_GAN: 1.253 G_L1: 0.137 D_real: 0.529 D_fake: 0.382 \n",
      "(epoch: 100, iters: 1100, time: 0.221, data: 0.001) G_GAN: 0.970 G_L1: 0.178 D_real: 0.230 D_fake: 0.690 \n",
      "(epoch: 100, iters: 1200, time: 0.297, data: 0.001) G_GAN: 1.402 G_L1: 0.177 D_real: 2.168 D_fake: 0.315 \n",
      "(epoch: 100, iters: 1300, time: 0.216, data: 0.001) G_GAN: 1.118 G_L1: 0.384 D_real: 0.563 D_fake: 0.567 \n",
      "(epoch: 100, iters: 1400, time: 0.224, data: 0.001) G_GAN: 1.502 G_L1: 0.163 D_real: 0.155 D_fake: 0.366 \n",
      "(epoch: 100, iters: 1500, time: 0.223, data: 0.001) G_GAN: 1.211 G_L1: 0.719 D_real: 0.567 D_fake: 0.540 \n",
      "(epoch: 100, iters: 1600, time: 0.298, data: 0.001) G_GAN: 1.038 G_L1: 0.387 D_real: 0.040 D_fake: 0.998 \n",
      "saving the model at the end of epoch 100, iters 1623\n",
      "End of epoch 100 / 200 \t Time Taken: 213 sec\n",
      "learning rate 0.0000198 -> 0.0000196\n",
      "(epoch: 101, iters: 77, time: 0.220, data: 0.002) G_GAN: 1.550 G_L1: 0.523 D_real: 0.029 D_fake: 0.443 \n",
      "(epoch: 101, iters: 177, time: 0.217, data: 0.001) G_GAN: 1.090 G_L1: 0.110 D_real: 1.092 D_fake: 0.422 \n",
      "(epoch: 101, iters: 277, time: 0.218, data: 0.001) G_GAN: 1.165 G_L1: 0.222 D_real: 0.880 D_fake: 0.368 \n",
      "(epoch: 101, iters: 377, time: 0.645, data: 0.001) G_GAN: 0.993 G_L1: 0.615 D_real: 0.821 D_fake: 0.556 \n",
      "(epoch: 101, iters: 477, time: 0.225, data: 0.002) G_GAN: 1.064 G_L1: 0.246 D_real: 0.807 D_fake: 0.454 \n",
      "(epoch: 101, iters: 577, time: 0.222, data: 0.001) G_GAN: 1.275 G_L1: 0.210 D_real: 0.240 D_fake: 0.490 \n",
      "(epoch: 101, iters: 677, time: 0.224, data: 0.001) G_GAN: 0.899 G_L1: 0.276 D_real: 0.426 D_fake: 0.880 \n",
      "(epoch: 101, iters: 777, time: 0.289, data: 0.001) G_GAN: 1.130 G_L1: 0.252 D_real: 0.521 D_fake: 0.477 \n",
      "(epoch: 101, iters: 877, time: 0.222, data: 0.001) G_GAN: 1.675 G_L1: 0.248 D_real: 1.202 D_fake: 0.204 \n",
      "(epoch: 101, iters: 977, time: 0.222, data: 0.001) G_GAN: 0.942 G_L1: 0.164 D_real: 0.844 D_fake: 0.480 \n",
      "(epoch: 101, iters: 1077, time: 0.220, data: 0.001) G_GAN: 1.662 G_L1: 0.290 D_real: 0.859 D_fake: 0.268 \n",
      "(epoch: 101, iters: 1177, time: 0.283, data: 0.001) G_GAN: 1.536 G_L1: 0.224 D_real: 0.308 D_fake: 0.381 \n",
      "(epoch: 101, iters: 1277, time: 0.221, data: 0.001) G_GAN: 0.963 G_L1: 0.170 D_real: 0.771 D_fake: 0.550 \n",
      "(epoch: 101, iters: 1377, time: 0.223, data: 0.001) G_GAN: 1.096 G_L1: 0.117 D_real: 0.148 D_fake: 0.970 \n",
      "(epoch: 101, iters: 1477, time: 0.223, data: 0.001) G_GAN: 1.095 G_L1: 0.146 D_real: 0.676 D_fake: 0.476 \n",
      "(epoch: 101, iters: 1577, time: 0.297, data: 0.001) G_GAN: 1.446 G_L1: 0.282 D_real: 0.051 D_fake: 0.309 \n",
      "End of epoch 101 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000196 -> 0.0000194\n",
      "(epoch: 102, iters: 54, time: 0.226, data: 0.002) G_GAN: 1.316 G_L1: 0.210 D_real: 0.411 D_fake: 0.365 \n",
      "(epoch: 102, iters: 154, time: 0.223, data: 0.001) G_GAN: 1.412 G_L1: 0.313 D_real: 0.193 D_fake: 0.369 \n",
      "(epoch: 102, iters: 254, time: 0.220, data: 0.003) G_GAN: 1.275 G_L1: 0.310 D_real: 0.195 D_fake: 0.536 \n",
      "(epoch: 102, iters: 354, time: 0.655, data: 0.002) G_GAN: 0.993 G_L1: 0.253 D_real: 1.042 D_fake: 0.502 \n",
      "(epoch: 102, iters: 454, time: 0.220, data: 0.003) G_GAN: 0.979 G_L1: 0.653 D_real: 0.287 D_fake: 0.582 \n",
      "(epoch: 102, iters: 554, time: 0.220, data: 0.003) G_GAN: 1.194 G_L1: 0.340 D_real: 0.740 D_fake: 0.452 \n",
      "(epoch: 102, iters: 654, time: 0.221, data: 0.002) G_GAN: 1.267 G_L1: 0.378 D_real: 0.353 D_fake: 0.422 \n",
      "(epoch: 102, iters: 754, time: 0.625, data: 0.002) G_GAN: 1.141 G_L1: 0.325 D_real: 0.535 D_fake: 0.360 \n",
      "(epoch: 102, iters: 854, time: 0.221, data: 0.003) G_GAN: 1.279 G_L1: 0.182 D_real: 0.314 D_fake: 0.414 \n",
      "(epoch: 102, iters: 954, time: 0.216, data: 0.002) G_GAN: 0.981 G_L1: 0.133 D_real: 0.697 D_fake: 0.549 \n",
      "(epoch: 102, iters: 1054, time: 0.223, data: 0.003) G_GAN: 0.684 G_L1: 0.195 D_real: 0.594 D_fake: 0.859 \n",
      "(epoch: 102, iters: 1154, time: 0.289, data: 0.003) G_GAN: 0.736 G_L1: 0.259 D_real: 0.831 D_fake: 0.892 \n",
      "(epoch: 102, iters: 1254, time: 0.220, data: 0.002) G_GAN: 1.118 G_L1: 0.442 D_real: 0.374 D_fake: 0.550 \n",
      "(epoch: 102, iters: 1354, time: 0.225, data: 0.002) G_GAN: 1.030 G_L1: 0.164 D_real: 0.544 D_fake: 0.661 \n",
      "(epoch: 102, iters: 1454, time: 0.220, data: 0.002) G_GAN: 1.123 G_L1: 0.262 D_real: 0.957 D_fake: 0.489 \n",
      "(epoch: 102, iters: 1554, time: 0.295, data: 0.001) G_GAN: 1.004 G_L1: 0.280 D_real: 0.586 D_fake: 0.559 \n",
      "End of epoch 102 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000194 -> 0.0000192\n",
      "(epoch: 103, iters: 31, time: 0.218, data: 0.002) G_GAN: 1.046 G_L1: 0.249 D_real: 0.729 D_fake: 0.520 \n",
      "(epoch: 103, iters: 131, time: 0.217, data: 0.003) G_GAN: 0.816 G_L1: 0.198 D_real: 0.143 D_fake: 1.019 \n",
      "saving the latest model (epoch 103, total_iters 5000)\n",
      "(epoch: 103, iters: 231, time: 0.220, data: 0.002) G_GAN: 1.197 G_L1: 0.286 D_real: 0.514 D_fake: 0.478 \n",
      "(epoch: 103, iters: 331, time: 0.648, data: 0.002) G_GAN: 1.187 G_L1: 0.224 D_real: 0.434 D_fake: 0.461 \n",
      "(epoch: 103, iters: 431, time: 0.216, data: 0.003) G_GAN: 1.296 G_L1: 0.163 D_real: 0.235 D_fake: 0.524 \n",
      "(epoch: 103, iters: 531, time: 0.218, data: 0.002) G_GAN: 1.017 G_L1: 0.301 D_real: 0.860 D_fake: 0.551 \n",
      "(epoch: 103, iters: 631, time: 0.222, data: 0.002) G_GAN: 1.393 G_L1: 0.602 D_real: 0.329 D_fake: 0.326 \n",
      "(epoch: 103, iters: 731, time: 0.292, data: 0.003) G_GAN: 1.045 G_L1: 0.173 D_real: 0.137 D_fake: 0.629 \n",
      "(epoch: 103, iters: 831, time: 0.222, data: 0.002) G_GAN: 0.991 G_L1: 0.167 D_real: 0.692 D_fake: 0.552 \n",
      "(epoch: 103, iters: 931, time: 0.219, data: 0.002) G_GAN: 1.343 G_L1: 0.251 D_real: 0.441 D_fake: 0.402 \n",
      "(epoch: 103, iters: 1031, time: 0.220, data: 0.003) G_GAN: 1.130 G_L1: 0.484 D_real: 0.131 D_fake: 0.548 \n",
      "(epoch: 103, iters: 1131, time: 0.717, data: 0.003) G_GAN: 1.080 G_L1: 0.123 D_real: 1.158 D_fake: 0.408 \n",
      "(epoch: 103, iters: 1231, time: 0.223, data: 0.002) G_GAN: 0.916 G_L1: 0.327 D_real: 0.215 D_fake: 0.640 \n",
      "(epoch: 103, iters: 1331, time: 0.221, data: 0.003) G_GAN: 1.605 G_L1: 0.335 D_real: 0.585 D_fake: 0.278 \n",
      "(epoch: 103, iters: 1431, time: 0.218, data: 0.001) G_GAN: 1.985 G_L1: 0.303 D_real: 0.089 D_fake: 0.211 \n",
      "(epoch: 103, iters: 1531, time: 0.289, data: 0.003) G_GAN: 1.149 G_L1: 0.232 D_real: 0.722 D_fake: 0.464 \n",
      "End of epoch 103 / 200 \t Time Taken: 208 sec\n",
      "learning rate 0.0000192 -> 0.0000190\n",
      "(epoch: 104, iters: 8, time: 0.218, data: 0.002) G_GAN: 1.290 G_L1: 0.401 D_real: 0.038 D_fake: 0.536 \n",
      "(epoch: 104, iters: 108, time: 0.219, data: 0.003) G_GAN: 1.230 G_L1: 0.334 D_real: 0.259 D_fake: 0.473 \n",
      "(epoch: 104, iters: 208, time: 0.219, data: 0.002) G_GAN: 1.591 G_L1: 0.229 D_real: 1.024 D_fake: 0.226 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 308, time: 0.684, data: 0.003) G_GAN: 1.262 G_L1: 0.300 D_real: 0.702 D_fake: 0.382 \n",
      "(epoch: 104, iters: 408, time: 0.216, data: 0.002) G_GAN: 1.484 G_L1: 0.267 D_real: 0.949 D_fake: 0.276 \n",
      "(epoch: 104, iters: 508, time: 0.221, data: 0.002) G_GAN: 1.332 G_L1: 0.352 D_real: 0.184 D_fake: 0.389 \n",
      "(epoch: 104, iters: 608, time: 0.218, data: 0.003) G_GAN: 1.115 G_L1: 0.171 D_real: 1.078 D_fake: 0.504 \n",
      "(epoch: 104, iters: 708, time: 0.292, data: 0.003) G_GAN: 0.727 G_L1: 0.311 D_real: 0.494 D_fake: 0.811 \n",
      "(epoch: 104, iters: 808, time: 0.220, data: 0.003) G_GAN: 0.801 G_L1: 0.162 D_real: 0.466 D_fake: 0.794 \n",
      "(epoch: 104, iters: 908, time: 0.221, data: 0.003) G_GAN: 0.890 G_L1: 0.390 D_real: 0.255 D_fake: 0.736 \n",
      "(epoch: 104, iters: 1008, time: 0.221, data: 0.003) G_GAN: 1.105 G_L1: 0.158 D_real: 0.777 D_fake: 0.444 \n",
      "(epoch: 104, iters: 1108, time: 0.290, data: 0.003) G_GAN: 1.041 G_L1: 0.156 D_real: 0.527 D_fake: 0.545 \n",
      "(epoch: 104, iters: 1208, time: 0.218, data: 0.002) G_GAN: 0.779 G_L1: 0.188 D_real: 0.471 D_fake: 0.717 \n",
      "(epoch: 104, iters: 1308, time: 0.218, data: 0.002) G_GAN: 0.978 G_L1: 0.260 D_real: 0.268 D_fake: 0.668 \n",
      "(epoch: 104, iters: 1408, time: 0.220, data: 0.003) G_GAN: 1.395 G_L1: 0.150 D_real: 0.865 D_fake: 0.290 \n",
      "(epoch: 104, iters: 1508, time: 0.608, data: 0.003) G_GAN: 1.120 G_L1: 0.477 D_real: 0.535 D_fake: 0.475 \n",
      "(epoch: 104, iters: 1608, time: 0.218, data: 0.002) G_GAN: 0.869 G_L1: 0.107 D_real: 0.808 D_fake: 0.563 \n",
      "End of epoch 104 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000190 -> 0.0000188\n",
      "(epoch: 105, iters: 85, time: 0.220, data: 0.002) G_GAN: 1.297 G_L1: 0.305 D_real: 0.553 D_fake: 0.428 \n",
      "(epoch: 105, iters: 185, time: 0.219, data: 0.003) G_GAN: 1.430 G_L1: 0.486 D_real: 0.361 D_fake: 0.351 \n",
      "(epoch: 105, iters: 285, time: 0.646, data: 0.003) G_GAN: 1.683 G_L1: 0.298 D_real: 0.686 D_fake: 0.208 \n",
      "(epoch: 105, iters: 385, time: 0.217, data: 0.003) G_GAN: 1.525 G_L1: 0.331 D_real: 0.074 D_fake: 0.293 \n",
      "(epoch: 105, iters: 485, time: 0.214, data: 0.003) G_GAN: 0.716 G_L1: 0.070 D_real: 0.539 D_fake: 0.799 \n",
      "(epoch: 105, iters: 585, time: 0.219, data: 0.003) G_GAN: 0.940 G_L1: 0.296 D_real: 0.381 D_fake: 0.662 \n",
      "(epoch: 105, iters: 685, time: 0.303, data: 0.002) G_GAN: 0.676 G_L1: 0.279 D_real: 0.543 D_fake: 0.918 \n",
      "(epoch: 105, iters: 785, time: 0.225, data: 0.002) G_GAN: 0.940 G_L1: 0.300 D_real: 0.464 D_fake: 0.626 \n",
      "(epoch: 105, iters: 885, time: 0.220, data: 0.002) G_GAN: 1.198 G_L1: 0.194 D_real: 0.688 D_fake: 0.438 \n",
      "(epoch: 105, iters: 985, time: 0.220, data: 0.003) G_GAN: 0.975 G_L1: 0.177 D_real: 1.016 D_fake: 0.494 \n",
      "(epoch: 105, iters: 1085, time: 0.296, data: 0.003) G_GAN: 0.883 G_L1: 0.277 D_real: 0.723 D_fake: 0.633 \n",
      "(epoch: 105, iters: 1185, time: 0.214, data: 0.003) G_GAN: 1.413 G_L1: 0.169 D_real: 0.750 D_fake: 0.270 \n",
      "(epoch: 105, iters: 1285, time: 0.216, data: 0.002) G_GAN: 1.454 G_L1: 0.371 D_real: 0.091 D_fake: 0.370 \n",
      "(epoch: 105, iters: 1385, time: 0.217, data: 0.003) G_GAN: 1.040 G_L1: 0.098 D_real: 0.583 D_fake: 0.534 \n",
      "(epoch: 105, iters: 1485, time: 0.290, data: 0.002) G_GAN: 0.906 G_L1: 0.370 D_real: 0.232 D_fake: 0.724 \n",
      "(epoch: 105, iters: 1585, time: 0.219, data: 0.002) G_GAN: 1.077 G_L1: 0.351 D_real: 0.875 D_fake: 0.464 \n",
      "saving the model at the end of epoch 105, iters 9738\n",
      "End of epoch 105 / 200 \t Time Taken: 210 sec\n",
      "learning rate 0.0000188 -> 0.0000186\n",
      "(epoch: 106, iters: 62, time: 0.220, data: 0.003) G_GAN: 1.145 G_L1: 0.395 D_real: 0.964 D_fake: 0.454 \n",
      "(epoch: 106, iters: 162, time: 0.215, data: 0.002) G_GAN: 1.206 G_L1: 0.161 D_real: 0.822 D_fake: 0.397 \n",
      "(epoch: 106, iters: 262, time: 0.621, data: 0.003) G_GAN: 1.037 G_L1: 0.218 D_real: 1.194 D_fake: 0.512 \n",
      "saving the latest model (epoch 106, total_iters 10000)\n",
      "(epoch: 106, iters: 362, time: 0.218, data: 0.002) G_GAN: 0.888 G_L1: 0.133 D_real: 0.818 D_fake: 0.563 \n",
      "(epoch: 106, iters: 462, time: 0.219, data: 0.003) G_GAN: 1.667 G_L1: 0.171 D_real: 0.010 D_fake: 0.506 \n",
      "(epoch: 106, iters: 562, time: 0.217, data: 0.002) G_GAN: 0.960 G_L1: 0.243 D_real: 1.054 D_fake: 0.624 \n",
      "(epoch: 106, iters: 662, time: 0.285, data: 0.003) G_GAN: 1.335 G_L1: 0.290 D_real: 0.584 D_fake: 0.401 \n",
      "(epoch: 106, iters: 762, time: 0.220, data: 0.003) G_GAN: 0.839 G_L1: 0.259 D_real: 0.094 D_fake: 0.932 \n",
      "(epoch: 106, iters: 862, time: 0.218, data: 0.003) G_GAN: 1.194 G_L1: 0.207 D_real: 0.621 D_fake: 0.384 \n",
      "(epoch: 106, iters: 962, time: 0.214, data: 0.002) G_GAN: 0.703 G_L1: 0.215 D_real: 0.729 D_fake: 0.912 \n",
      "(epoch: 106, iters: 1062, time: 0.286, data: 0.002) G_GAN: 1.229 G_L1: 0.311 D_real: 0.230 D_fake: 0.545 \n",
      "(epoch: 106, iters: 1162, time: 0.215, data: 0.002) G_GAN: 0.513 G_L1: 0.223 D_real: 0.469 D_fake: 1.173 \n",
      "(epoch: 106, iters: 1262, time: 0.220, data: 0.003) G_GAN: 1.406 G_L1: 0.335 D_real: 0.897 D_fake: 0.322 \n",
      "(epoch: 106, iters: 1362, time: 0.220, data: 0.002) G_GAN: 1.633 G_L1: 0.235 D_real: 1.312 D_fake: 0.202 \n",
      "(epoch: 106, iters: 1462, time: 0.303, data: 0.003) G_GAN: 0.639 G_L1: 0.120 D_real: 0.784 D_fake: 0.994 \n",
      "(epoch: 106, iters: 1562, time: 0.220, data: 0.003) G_GAN: 0.722 G_L1: 0.262 D_real: 1.046 D_fake: 0.939 \n",
      "End of epoch 106 / 200 \t Time Taken: 207 sec\n",
      "learning rate 0.0000186 -> 0.0000184\n",
      "(epoch: 107, iters: 39, time: 0.224, data: 0.003) G_GAN: 0.773 G_L1: 0.122 D_real: 0.598 D_fake: 0.793 \n",
      "(epoch: 107, iters: 139, time: 0.221, data: 0.002) G_GAN: 1.624 G_L1: 0.199 D_real: 1.001 D_fake: 0.201 \n",
      "(epoch: 107, iters: 239, time: 0.615, data: 0.002) G_GAN: 1.027 G_L1: 0.313 D_real: 0.821 D_fake: 0.469 \n",
      "(epoch: 107, iters: 339, time: 0.222, data: 0.003) G_GAN: 0.909 G_L1: 0.256 D_real: 1.200 D_fake: 0.606 \n",
      "(epoch: 107, iters: 439, time: 0.222, data: 0.003) G_GAN: 1.297 G_L1: 0.267 D_real: 0.424 D_fake: 0.411 \n",
      "(epoch: 107, iters: 539, time: 0.221, data: 0.003) G_GAN: 0.896 G_L1: 0.192 D_real: 0.858 D_fake: 0.691 \n",
      "(epoch: 107, iters: 639, time: 0.764, data: 0.003) G_GAN: 0.833 G_L1: 0.166 D_real: 0.743 D_fake: 0.587 \n",
      "(epoch: 107, iters: 739, time: 0.223, data: 0.003) G_GAN: 1.177 G_L1: 0.127 D_real: 0.705 D_fake: 0.394 \n",
      "(epoch: 107, iters: 839, time: 0.218, data: 0.003) G_GAN: 1.247 G_L1: 0.374 D_real: 0.514 D_fake: 0.372 \n",
      "(epoch: 107, iters: 939, time: 0.223, data: 0.002) G_GAN: 1.043 G_L1: 0.273 D_real: 0.027 D_fake: 0.756 \n",
      "(epoch: 107, iters: 1039, time: 0.300, data: 0.003) G_GAN: 1.066 G_L1: 0.168 D_real: 0.437 D_fake: 0.543 \n",
      "(epoch: 107, iters: 1139, time: 0.217, data: 0.002) G_GAN: 1.022 G_L1: 0.325 D_real: 0.257 D_fake: 0.673 \n",
      "(epoch: 107, iters: 1239, time: 0.219, data: 0.004) G_GAN: 0.992 G_L1: 0.127 D_real: 0.075 D_fake: 0.801 \n",
      "(epoch: 107, iters: 1339, time: 0.218, data: 0.002) G_GAN: 1.222 G_L1: 0.205 D_real: 0.800 D_fake: 0.375 \n",
      "(epoch: 107, iters: 1439, time: 0.301, data: 0.003) G_GAN: 1.132 G_L1: 0.234 D_real: 0.651 D_fake: 0.505 \n",
      "(epoch: 107, iters: 1539, time: 0.219, data: 0.003) G_GAN: 1.500 G_L1: 0.572 D_real: 0.050 D_fake: 0.448 \n",
      "End of epoch 107 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000184 -> 0.0000182\n",
      "(epoch: 108, iters: 16, time: 0.222, data: 0.003) G_GAN: 0.980 G_L1: 0.171 D_real: 1.366 D_fake: 0.602 \n",
      "(epoch: 108, iters: 116, time: 0.218, data: 0.003) G_GAN: 1.220 G_L1: 0.393 D_real: 0.847 D_fake: 0.414 \n",
      "(epoch: 108, iters: 216, time: 0.611, data: 0.002) G_GAN: 0.934 G_L1: 0.218 D_real: 0.070 D_fake: 0.941 \n",
      "(epoch: 108, iters: 316, time: 0.218, data: 0.002) G_GAN: 1.425 G_L1: 0.157 D_real: 0.775 D_fake: 0.334 \n",
      "(epoch: 108, iters: 416, time: 0.220, data: 0.002) G_GAN: 0.939 G_L1: 0.133 D_real: 0.400 D_fake: 0.740 \n",
      "(epoch: 108, iters: 516, time: 0.217, data: 0.003) G_GAN: 0.844 G_L1: 0.175 D_real: 1.131 D_fake: 0.620 \n",
      "(epoch: 108, iters: 616, time: 0.301, data: 0.002) G_GAN: 0.956 G_L1: 0.221 D_real: 0.695 D_fake: 0.553 \n",
      "(epoch: 108, iters: 716, time: 0.226, data: 0.002) G_GAN: 1.346 G_L1: 0.225 D_real: 0.316 D_fake: 0.378 \n",
      "(epoch: 108, iters: 816, time: 0.220, data: 0.003) G_GAN: 1.608 G_L1: 0.328 D_real: 0.089 D_fake: 0.349 \n",
      "(epoch: 108, iters: 916, time: 0.218, data: 0.003) G_GAN: 1.492 G_L1: 0.338 D_real: 1.343 D_fake: 0.242 \n",
      "(epoch: 108, iters: 1016, time: 0.617, data: 0.003) G_GAN: 1.066 G_L1: 0.341 D_real: 0.029 D_fake: 0.626 \n",
      "(epoch: 108, iters: 1116, time: 0.222, data: 0.003) G_GAN: 0.793 G_L1: 0.112 D_real: 0.592 D_fake: 0.633 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 108, iters: 1216, time: 0.214, data: 0.003) G_GAN: 1.227 G_L1: 0.121 D_real: 0.797 D_fake: 0.382 \n",
      "(epoch: 108, iters: 1316, time: 0.226, data: 0.003) G_GAN: 0.979 G_L1: 0.285 D_real: 0.824 D_fake: 0.512 \n",
      "(epoch: 108, iters: 1416, time: 0.297, data: 0.002) G_GAN: 0.692 G_L1: 0.131 D_real: 1.016 D_fake: 0.797 \n",
      "(epoch: 108, iters: 1516, time: 0.221, data: 0.003) G_GAN: 1.583 G_L1: 0.234 D_real: 0.784 D_fake: 0.318 \n",
      "(epoch: 108, iters: 1616, time: 0.221, data: 0.003) G_GAN: 1.014 G_L1: 0.188 D_real: 0.830 D_fake: 0.467 \n",
      "End of epoch 108 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000182 -> 0.0000180\n",
      "(epoch: 109, iters: 93, time: 0.225, data: 0.003) G_GAN: 1.036 G_L1: 0.328 D_real: 0.408 D_fake: 0.713 \n",
      "(epoch: 109, iters: 193, time: 0.607, data: 0.003) G_GAN: 1.282 G_L1: 0.333 D_real: 0.087 D_fake: 0.432 \n",
      "(epoch: 109, iters: 293, time: 0.216, data: 0.002) G_GAN: 0.743 G_L1: 0.199 D_real: 0.634 D_fake: 0.857 \n",
      "(epoch: 109, iters: 393, time: 0.216, data: 0.002) G_GAN: 1.166 G_L1: 0.293 D_real: 0.278 D_fake: 0.518 \n",
      "saving the latest model (epoch 109, total_iters 15000)\n",
      "(epoch: 109, iters: 493, time: 0.216, data: 0.002) G_GAN: 1.258 G_L1: 0.265 D_real: 0.040 D_fake: 0.486 \n",
      "(epoch: 109, iters: 593, time: 0.292, data: 0.002) G_GAN: 1.104 G_L1: 0.335 D_real: 0.545 D_fake: 0.548 \n",
      "(epoch: 109, iters: 693, time: 0.214, data: 0.002) G_GAN: 0.732 G_L1: 0.216 D_real: 0.723 D_fake: 0.921 \n",
      "(epoch: 109, iters: 793, time: 0.222, data: 0.003) G_GAN: 0.737 G_L1: 0.263 D_real: 0.797 D_fake: 1.011 \n",
      "(epoch: 109, iters: 893, time: 0.222, data: 0.003) G_GAN: 1.077 G_L1: 0.391 D_real: 0.747 D_fake: 0.455 \n",
      "(epoch: 109, iters: 993, time: 0.290, data: 0.005) G_GAN: 1.070 G_L1: 0.282 D_real: 0.765 D_fake: 0.643 \n",
      "(epoch: 109, iters: 1093, time: 0.221, data: 0.002) G_GAN: 1.224 G_L1: 0.303 D_real: 0.653 D_fake: 0.400 \n",
      "(epoch: 109, iters: 1193, time: 0.218, data: 0.003) G_GAN: 1.363 G_L1: 0.365 D_real: 0.206 D_fake: 0.356 \n",
      "(epoch: 109, iters: 1293, time: 0.217, data: 0.003) G_GAN: 1.516 G_L1: 0.404 D_real: 0.208 D_fake: 0.319 \n",
      "(epoch: 109, iters: 1393, time: 0.633, data: 0.003) G_GAN: 1.914 G_L1: 0.227 D_real: 0.071 D_fake: 0.228 \n",
      "(epoch: 109, iters: 1493, time: 0.222, data: 0.001) G_GAN: 0.780 G_L1: 0.295 D_real: 0.056 D_fake: 1.007 \n",
      "(epoch: 109, iters: 1593, time: 0.221, data: 0.003) G_GAN: 1.665 G_L1: 0.485 D_real: 0.744 D_fake: 0.242 \n",
      "End of epoch 109 / 200 \t Time Taken: 207 sec\n",
      "learning rate 0.0000180 -> 0.0000178\n",
      "(epoch: 110, iters: 70, time: 0.211, data: 0.002) G_GAN: 0.959 G_L1: 0.134 D_real: 0.820 D_fake: 0.470 \n",
      "(epoch: 110, iters: 170, time: 0.672, data: 0.003) G_GAN: 0.861 G_L1: 0.216 D_real: 1.027 D_fake: 0.644 \n",
      "(epoch: 110, iters: 270, time: 0.214, data: 0.002) G_GAN: 1.254 G_L1: 0.086 D_real: 0.418 D_fake: 0.495 \n",
      "(epoch: 110, iters: 370, time: 0.219, data: 0.001) G_GAN: 1.138 G_L1: 0.314 D_real: 0.758 D_fake: 0.536 \n",
      "(epoch: 110, iters: 470, time: 0.225, data: 0.003) G_GAN: 1.422 G_L1: 0.322 D_real: 0.440 D_fake: 0.375 \n",
      "(epoch: 110, iters: 570, time: 0.297, data: 0.003) G_GAN: 0.818 G_L1: 0.378 D_real: 0.628 D_fake: 0.892 \n",
      "(epoch: 110, iters: 670, time: 0.220, data: 0.002) G_GAN: 1.035 G_L1: 0.241 D_real: 0.669 D_fake: 0.488 \n",
      "(epoch: 110, iters: 770, time: 0.225, data: 0.003) G_GAN: 1.072 G_L1: 0.358 D_real: 1.058 D_fake: 0.646 \n",
      "(epoch: 110, iters: 870, time: 0.219, data: 0.003) G_GAN: 1.730 G_L1: 0.361 D_real: 0.045 D_fake: 0.384 \n",
      "(epoch: 110, iters: 970, time: 0.303, data: 0.003) G_GAN: 0.781 G_L1: 0.115 D_real: 0.248 D_fake: 0.872 \n",
      "(epoch: 110, iters: 1070, time: 0.217, data: 0.002) G_GAN: 1.106 G_L1: 0.371 D_real: 0.122 D_fake: 0.572 \n",
      "(epoch: 110, iters: 1170, time: 0.226, data: 0.002) G_GAN: 1.142 G_L1: 0.233 D_real: 0.077 D_fake: 0.643 \n",
      "(epoch: 110, iters: 1270, time: 0.224, data: 0.002) G_GAN: 1.131 G_L1: 0.194 D_real: 0.522 D_fake: 0.509 \n",
      "(epoch: 110, iters: 1370, time: 0.300, data: 0.003) G_GAN: 1.426 G_L1: 0.421 D_real: 0.291 D_fake: 0.449 \n",
      "(epoch: 110, iters: 1470, time: 0.217, data: 0.002) G_GAN: 1.238 G_L1: 0.177 D_real: 0.837 D_fake: 0.359 \n",
      "(epoch: 110, iters: 1570, time: 0.218, data: 0.003) G_GAN: 1.159 G_L1: 0.444 D_real: 0.084 D_fake: 0.527 \n",
      "saving the model at the end of epoch 110, iters 17853\n",
      "End of epoch 110 / 200 \t Time Taken: 214 sec\n",
      "learning rate 0.0000178 -> 0.0000176\n",
      "(epoch: 111, iters: 47, time: 0.214, data: 0.003) G_GAN: 0.799 G_L1: 0.168 D_real: 0.341 D_fake: 1.808 \n",
      "(epoch: 111, iters: 147, time: 0.726, data: 0.002) G_GAN: 1.222 G_L1: 0.211 D_real: 0.677 D_fake: 0.461 \n",
      "(epoch: 111, iters: 247, time: 0.215, data: 0.002) G_GAN: 1.071 G_L1: 0.317 D_real: 0.015 D_fake: 0.834 \n",
      "(epoch: 111, iters: 347, time: 0.218, data: 0.003) G_GAN: 1.034 G_L1: 0.234 D_real: 0.443 D_fake: 0.607 \n",
      "(epoch: 111, iters: 447, time: 0.222, data: 0.003) G_GAN: 1.110 G_L1: 0.146 D_real: 0.393 D_fake: 0.452 \n",
      "(epoch: 111, iters: 547, time: 0.301, data: 0.003) G_GAN: 1.120 G_L1: 0.502 D_real: 0.116 D_fake: 0.501 \n",
      "(epoch: 111, iters: 647, time: 0.225, data: 0.003) G_GAN: 1.339 G_L1: 0.305 D_real: 0.233 D_fake: 0.498 \n",
      "(epoch: 111, iters: 747, time: 0.216, data: 0.003) G_GAN: 0.877 G_L1: 0.203 D_real: 0.471 D_fake: 0.654 \n",
      "(epoch: 111, iters: 847, time: 0.220, data: 0.003) G_GAN: 1.150 G_L1: 0.220 D_real: 0.475 D_fake: 0.463 \n",
      "(epoch: 111, iters: 947, time: 0.294, data: 0.003) G_GAN: 1.619 G_L1: 0.468 D_real: 0.047 D_fake: 0.339 \n",
      "(epoch: 111, iters: 1047, time: 0.222, data: 0.003) G_GAN: 0.693 G_L1: 0.176 D_real: 0.428 D_fake: 1.076 \n",
      "(epoch: 111, iters: 1147, time: 0.221, data: 0.003) G_GAN: 1.427 G_L1: 0.314 D_real: 1.682 D_fake: 0.352 \n",
      "(epoch: 111, iters: 1247, time: 0.218, data: 0.002) G_GAN: 1.243 G_L1: 0.195 D_real: 0.259 D_fake: 0.479 \n",
      "(epoch: 111, iters: 1347, time: 0.298, data: 0.002) G_GAN: 0.859 G_L1: 0.436 D_real: 0.550 D_fake: 0.893 \n",
      "(epoch: 111, iters: 1447, time: 0.213, data: 0.002) G_GAN: 0.727 G_L1: 0.245 D_real: 0.585 D_fake: 0.990 \n",
      "(epoch: 111, iters: 1547, time: 0.220, data: 0.003) G_GAN: 1.414 G_L1: 0.495 D_real: 0.592 D_fake: 0.525 \n",
      "End of epoch 111 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000176 -> 0.0000174\n",
      "(epoch: 112, iters: 24, time: 0.218, data: 0.003) G_GAN: 0.799 G_L1: 0.212 D_real: 0.704 D_fake: 0.791 \n",
      "(epoch: 112, iters: 124, time: 0.647, data: 0.001) G_GAN: 1.735 G_L1: 0.213 D_real: 0.017 D_fake: 0.294 \n",
      "(epoch: 112, iters: 224, time: 0.219, data: 0.002) G_GAN: 1.553 G_L1: 0.344 D_real: 0.418 D_fake: 0.289 \n",
      "(epoch: 112, iters: 324, time: 0.222, data: 0.002) G_GAN: 1.109 G_L1: 0.147 D_real: 1.065 D_fake: 0.444 \n",
      "(epoch: 112, iters: 424, time: 0.220, data: 0.002) G_GAN: 1.085 G_L1: 0.259 D_real: 0.292 D_fake: 0.626 \n",
      "(epoch: 112, iters: 524, time: 0.657, data: 0.002) G_GAN: 1.083 G_L1: 0.211 D_real: 0.536 D_fake: 0.580 \n",
      "saving the latest model (epoch 112, total_iters 20000)\n",
      "(epoch: 112, iters: 624, time: 0.221, data: 0.002) G_GAN: 1.338 G_L1: 0.300 D_real: 0.153 D_fake: 0.894 \n",
      "(epoch: 112, iters: 724, time: 0.220, data: 0.002) G_GAN: 1.025 G_L1: 0.153 D_real: 0.911 D_fake: 0.452 \n",
      "(epoch: 112, iters: 824, time: 0.220, data: 0.003) G_GAN: 1.193 G_L1: 0.168 D_real: 1.060 D_fake: 0.366 \n",
      "(epoch: 112, iters: 924, time: 0.281, data: 0.003) G_GAN: 1.057 G_L1: 0.295 D_real: 0.785 D_fake: 0.513 \n",
      "(epoch: 112, iters: 1024, time: 0.215, data: 0.001) G_GAN: 1.446 G_L1: 0.163 D_real: 0.378 D_fake: 0.309 \n",
      "(epoch: 112, iters: 1124, time: 0.219, data: 0.002) G_GAN: 1.371 G_L1: 0.352 D_real: 0.862 D_fake: 0.494 \n",
      "(epoch: 112, iters: 1224, time: 0.216, data: 0.001) G_GAN: 1.138 G_L1: 0.442 D_real: 0.070 D_fake: 0.606 \n",
      "(epoch: 112, iters: 1324, time: 0.282, data: 0.001) G_GAN: 1.197 G_L1: 0.248 D_real: 0.689 D_fake: 0.466 \n",
      "(epoch: 112, iters: 1424, time: 0.223, data: 0.003) G_GAN: 0.836 G_L1: 0.289 D_real: 0.700 D_fake: 0.670 \n",
      "(epoch: 112, iters: 1524, time: 0.216, data: 0.003) G_GAN: 1.141 G_L1: 0.114 D_real: 0.583 D_fake: 0.399 \n",
      "End of epoch 112 / 200 \t Time Taken: 207 sec\n",
      "learning rate 0.0000174 -> 0.0000172\n",
      "(epoch: 113, iters: 1, time: 0.129, data: 0.001) G_GAN: 0.710 G_L1: 0.238 D_real: 0.296 D_fake: 0.888 \n",
      "(epoch: 113, iters: 101, time: 0.643, data: 0.003) G_GAN: 1.464 G_L1: 0.507 D_real: 0.691 D_fake: 0.292 \n",
      "(epoch: 113, iters: 201, time: 0.221, data: 0.002) G_GAN: 1.145 G_L1: 0.125 D_real: 0.241 D_fake: 0.629 \n",
      "(epoch: 113, iters: 301, time: 0.217, data: 0.001) G_GAN: 1.213 G_L1: 0.301 D_real: 0.052 D_fake: 0.522 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 113, iters: 401, time: 0.216, data: 0.002) G_GAN: 1.678 G_L1: 0.173 D_real: 0.082 D_fake: 0.296 \n",
      "(epoch: 113, iters: 501, time: 0.292, data: 0.001) G_GAN: 1.176 G_L1: 0.211 D_real: 0.397 D_fake: 0.435 \n",
      "(epoch: 113, iters: 601, time: 0.224, data: 0.003) G_GAN: 0.973 G_L1: 0.142 D_real: 0.534 D_fake: 0.614 \n",
      "(epoch: 113, iters: 701, time: 0.220, data: 0.002) G_GAN: 1.048 G_L1: 0.399 D_real: 0.388 D_fake: 0.552 \n",
      "(epoch: 113, iters: 801, time: 0.223, data: 0.003) G_GAN: 1.448 G_L1: 0.248 D_real: 0.590 D_fake: 0.340 \n",
      "(epoch: 113, iters: 901, time: 0.648, data: 0.003) G_GAN: 1.036 G_L1: 0.111 D_real: 1.209 D_fake: 0.390 \n",
      "(epoch: 113, iters: 1001, time: 0.220, data: 0.002) G_GAN: 1.186 G_L1: 0.502 D_real: 0.584 D_fake: 0.496 \n",
      "(epoch: 113, iters: 1101, time: 0.217, data: 0.002) G_GAN: 1.264 G_L1: 0.193 D_real: 0.377 D_fake: 0.391 \n",
      "(epoch: 113, iters: 1201, time: 0.219, data: 0.001) G_GAN: 1.025 G_L1: 0.237 D_real: 0.831 D_fake: 0.518 \n",
      "(epoch: 113, iters: 1301, time: 0.291, data: 0.001) G_GAN: 1.379 G_L1: 0.299 D_real: 0.553 D_fake: 0.365 \n",
      "(epoch: 113, iters: 1401, time: 0.223, data: 0.003) G_GAN: 1.154 G_L1: 0.258 D_real: 0.755 D_fake: 0.408 \n",
      "(epoch: 113, iters: 1501, time: 0.225, data: 0.003) G_GAN: 0.919 G_L1: 0.346 D_real: 0.650 D_fake: 0.604 \n",
      "(epoch: 113, iters: 1601, time: 0.221, data: 0.003) G_GAN: 1.138 G_L1: 0.250 D_real: 0.017 D_fake: 0.513 \n",
      "End of epoch 113 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000172 -> 0.0000170\n",
      "(epoch: 114, iters: 78, time: 0.739, data: 0.002) G_GAN: 1.469 G_L1: 0.320 D_real: 0.544 D_fake: 0.391 \n",
      "(epoch: 114, iters: 178, time: 0.218, data: 0.003) G_GAN: 0.994 G_L1: 0.223 D_real: 1.006 D_fake: 0.541 \n",
      "(epoch: 114, iters: 278, time: 0.219, data: 0.001) G_GAN: 1.098 G_L1: 0.170 D_real: 0.943 D_fake: 0.426 \n",
      "(epoch: 114, iters: 378, time: 0.221, data: 0.003) G_GAN: 0.954 G_L1: 0.311 D_real: 0.611 D_fake: 0.566 \n",
      "(epoch: 114, iters: 478, time: 0.293, data: 0.002) G_GAN: 0.750 G_L1: 0.183 D_real: 0.804 D_fake: 1.145 \n",
      "(epoch: 114, iters: 578, time: 0.222, data: 0.002) G_GAN: 0.827 G_L1: 0.144 D_real: 1.153 D_fake: 0.828 \n",
      "(epoch: 114, iters: 678, time: 0.220, data: 0.001) G_GAN: 0.933 G_L1: 0.320 D_real: 0.118 D_fake: 0.831 \n",
      "(epoch: 114, iters: 778, time: 0.220, data: 0.001) G_GAN: 0.878 G_L1: 0.198 D_real: 0.595 D_fake: 1.218 \n",
      "(epoch: 114, iters: 878, time: 0.289, data: 0.001) G_GAN: 1.674 G_L1: 0.448 D_real: 0.008 D_fake: 0.320 \n",
      "(epoch: 114, iters: 978, time: 0.221, data: 0.003) G_GAN: 1.283 G_L1: 0.258 D_real: 0.571 D_fake: 0.402 \n",
      "(epoch: 114, iters: 1078, time: 0.220, data: 0.002) G_GAN: 0.985 G_L1: 0.177 D_real: 0.545 D_fake: 0.587 \n",
      "(epoch: 114, iters: 1178, time: 0.219, data: 0.001) G_GAN: 1.617 G_L1: 0.383 D_real: 0.708 D_fake: 0.256 \n",
      "(epoch: 114, iters: 1278, time: 0.689, data: 0.002) G_GAN: 1.156 G_L1: 0.228 D_real: 0.010 D_fake: 0.486 \n",
      "(epoch: 114, iters: 1378, time: 0.219, data: 0.002) G_GAN: 1.273 G_L1: 0.173 D_real: 1.154 D_fake: 0.488 \n",
      "(epoch: 114, iters: 1478, time: 0.220, data: 0.002) G_GAN: 0.968 G_L1: 0.150 D_real: 0.968 D_fake: 0.474 \n",
      "(epoch: 114, iters: 1578, time: 0.219, data: 0.001) G_GAN: 1.107 G_L1: 0.204 D_real: 0.689 D_fake: 0.482 \n",
      "End of epoch 114 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000170 -> 0.0000168\n",
      "(epoch: 115, iters: 55, time: 0.644, data: 0.003) G_GAN: 1.188 G_L1: 0.105 D_real: 0.067 D_fake: 0.563 \n",
      "(epoch: 115, iters: 155, time: 0.220, data: 0.002) G_GAN: 1.002 G_L1: 0.371 D_real: 0.798 D_fake: 0.612 \n",
      "(epoch: 115, iters: 255, time: 0.219, data: 0.001) G_GAN: 1.023 G_L1: 0.232 D_real: 0.012 D_fake: 0.793 \n",
      "(epoch: 115, iters: 355, time: 0.220, data: 0.001) G_GAN: 1.026 G_L1: 0.185 D_real: 0.498 D_fake: 0.545 \n",
      "(epoch: 115, iters: 455, time: 0.292, data: 0.002) G_GAN: 2.915 G_L1: 0.181 D_real: 0.408 D_fake: 0.059 \n",
      "(epoch: 115, iters: 555, time: 0.219, data: 0.003) G_GAN: 1.604 G_L1: 0.236 D_real: 0.696 D_fake: 0.242 \n",
      "(epoch: 115, iters: 655, time: 0.215, data: 0.001) G_GAN: 1.028 G_L1: 0.245 D_real: 0.606 D_fake: 0.572 \n",
      "saving the latest model (epoch 115, total_iters 25000)\n",
      "(epoch: 115, iters: 755, time: 0.218, data: 0.002) G_GAN: 1.199 G_L1: 0.288 D_real: 0.458 D_fake: 0.506 \n",
      "(epoch: 115, iters: 855, time: 0.292, data: 0.002) G_GAN: 1.045 G_L1: 0.331 D_real: 0.728 D_fake: 0.589 \n",
      "(epoch: 115, iters: 955, time: 0.220, data: 0.002) G_GAN: 1.789 G_L1: 0.577 D_real: 0.041 D_fake: 0.321 \n",
      "(epoch: 115, iters: 1055, time: 0.219, data: 0.001) G_GAN: 0.894 G_L1: 0.157 D_real: 0.830 D_fake: 0.610 \n",
      "(epoch: 115, iters: 1155, time: 0.224, data: 0.003) G_GAN: 1.110 G_L1: 0.269 D_real: 0.739 D_fake: 0.442 \n",
      "(epoch: 115, iters: 1255, time: 0.292, data: 0.003) G_GAN: 1.101 G_L1: 0.178 D_real: 0.540 D_fake: 0.433 \n",
      "(epoch: 115, iters: 1355, time: 0.221, data: 0.002) G_GAN: 1.710 G_L1: 0.268 D_real: 0.674 D_fake: 0.289 \n",
      "(epoch: 115, iters: 1455, time: 0.219, data: 0.001) G_GAN: 1.654 G_L1: 0.259 D_real: 0.333 D_fake: 0.260 \n",
      "(epoch: 115, iters: 1555, time: 0.218, data: 0.001) G_GAN: 1.171 G_L1: 0.797 D_real: 0.543 D_fake: 0.499 \n",
      "saving the model at the end of epoch 115, iters 25968\n",
      "End of epoch 115 / 200 \t Time Taken: 211 sec\n",
      "learning rate 0.0000168 -> 0.0000166\n",
      "(epoch: 116, iters: 32, time: 0.609, data: 0.001) G_GAN: 1.076 G_L1: 0.343 D_real: 0.380 D_fake: 0.711 \n",
      "(epoch: 116, iters: 132, time: 0.223, data: 0.002) G_GAN: 1.451 G_L1: 0.163 D_real: 0.534 D_fake: 0.310 \n",
      "(epoch: 116, iters: 232, time: 0.224, data: 0.003) G_GAN: 0.782 G_L1: 0.249 D_real: 0.234 D_fake: 1.049 \n",
      "(epoch: 116, iters: 332, time: 0.221, data: 0.002) G_GAN: 0.762 G_L1: 0.164 D_real: 0.297 D_fake: 0.784 \n",
      "(epoch: 116, iters: 432, time: 0.295, data: 0.001) G_GAN: 0.949 G_L1: 0.188 D_real: 0.437 D_fake: 0.746 \n",
      "(epoch: 116, iters: 532, time: 0.220, data: 0.002) G_GAN: 1.340 G_L1: 0.457 D_real: 0.939 D_fake: 0.314 \n",
      "(epoch: 116, iters: 632, time: 0.217, data: 0.001) G_GAN: 1.076 G_L1: 0.148 D_real: 1.346 D_fake: 0.450 \n",
      "(epoch: 116, iters: 732, time: 0.220, data: 0.001) G_GAN: 1.073 G_L1: 0.212 D_real: 1.063 D_fake: 0.380 \n",
      "(epoch: 116, iters: 832, time: 0.289, data: 0.001) G_GAN: 1.053 G_L1: 0.299 D_real: 0.082 D_fake: 0.827 \n",
      "(epoch: 116, iters: 932, time: 0.218, data: 0.002) G_GAN: 1.120 G_L1: 0.387 D_real: 0.230 D_fake: 0.710 \n",
      "(epoch: 116, iters: 1032, time: 0.220, data: 0.001) G_GAN: 0.811 G_L1: 0.149 D_real: 0.301 D_fake: 0.810 \n",
      "(epoch: 116, iters: 1132, time: 0.224, data: 0.003) G_GAN: 1.436 G_L1: 0.491 D_real: 0.744 D_fake: 0.325 \n",
      "(epoch: 116, iters: 1232, time: 0.295, data: 0.002) G_GAN: 1.498 G_L1: 0.320 D_real: 0.280 D_fake: 0.298 \n",
      "(epoch: 116, iters: 1332, time: 0.219, data: 0.002) G_GAN: 1.233 G_L1: 0.170 D_real: 0.567 D_fake: 0.398 \n",
      "(epoch: 116, iters: 1432, time: 0.221, data: 0.003) G_GAN: 0.817 G_L1: 0.226 D_real: 0.596 D_fake: 0.840 \n",
      "(epoch: 116, iters: 1532, time: 0.218, data: 0.002) G_GAN: 1.493 G_L1: 0.487 D_real: 0.210 D_fake: 0.379 \n",
      "End of epoch 116 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000166 -> 0.0000164\n",
      "(epoch: 117, iters: 9, time: 0.675, data: 0.003) G_GAN: 1.395 G_L1: 0.185 D_real: 0.575 D_fake: 0.433 \n",
      "(epoch: 117, iters: 109, time: 0.220, data: 0.002) G_GAN: 0.600 G_L1: 0.118 D_real: 0.384 D_fake: 1.158 \n",
      "(epoch: 117, iters: 209, time: 0.217, data: 0.002) G_GAN: 0.848 G_L1: 0.295 D_real: 0.513 D_fake: 0.665 \n",
      "(epoch: 117, iters: 309, time: 0.217, data: 0.001) G_GAN: 1.341 G_L1: 0.417 D_real: 0.107 D_fake: 0.458 \n",
      "(epoch: 117, iters: 409, time: 0.656, data: 0.002) G_GAN: 0.755 G_L1: 0.223 D_real: 0.592 D_fake: 0.688 \n",
      "(epoch: 117, iters: 509, time: 0.221, data: 0.002) G_GAN: 0.744 G_L1: 0.118 D_real: 0.675 D_fake: 0.736 \n",
      "(epoch: 117, iters: 609, time: 0.218, data: 0.002) G_GAN: 1.464 G_L1: 0.211 D_real: 0.146 D_fake: 0.389 \n",
      "(epoch: 117, iters: 709, time: 0.216, data: 0.003) G_GAN: 1.023 G_L1: 0.455 D_real: 0.336 D_fake: 0.808 \n",
      "(epoch: 117, iters: 809, time: 0.291, data: 0.001) G_GAN: 1.591 G_L1: 0.126 D_real: 0.855 D_fake: 0.271 \n",
      "(epoch: 117, iters: 909, time: 0.221, data: 0.002) G_GAN: 1.385 G_L1: 0.436 D_real: 0.250 D_fake: 0.450 \n",
      "(epoch: 117, iters: 1009, time: 0.220, data: 0.002) G_GAN: 0.957 G_L1: 0.169 D_real: 0.350 D_fake: 0.659 \n",
      "(epoch: 117, iters: 1109, time: 0.216, data: 0.003) G_GAN: 0.947 G_L1: 0.132 D_real: 0.570 D_fake: 0.580 \n",
      "(epoch: 117, iters: 1209, time: 0.290, data: 0.006) G_GAN: 1.737 G_L1: 0.125 D_real: 1.188 D_fake: 0.176 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 117, iters: 1309, time: 0.223, data: 0.003) G_GAN: 0.849 G_L1: 0.249 D_real: 0.509 D_fake: 0.766 \n",
      "(epoch: 117, iters: 1409, time: 0.220, data: 0.002) G_GAN: 1.177 G_L1: 0.147 D_real: 1.110 D_fake: 0.405 \n",
      "(epoch: 117, iters: 1509, time: 0.225, data: 0.003) G_GAN: 1.199 G_L1: 0.145 D_real: 0.866 D_fake: 0.390 \n",
      "(epoch: 117, iters: 1609, time: 0.287, data: 0.003) G_GAN: 1.348 G_L1: 0.122 D_real: 0.824 D_fake: 0.367 \n",
      "End of epoch 117 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000164 -> 0.0000162\n",
      "(epoch: 118, iters: 86, time: 0.219, data: 0.001) G_GAN: 1.203 G_L1: 0.145 D_real: 0.752 D_fake: 0.401 \n",
      "(epoch: 118, iters: 186, time: 0.220, data: 0.003) G_GAN: 1.130 G_L1: 0.294 D_real: 0.823 D_fake: 0.548 \n",
      "(epoch: 118, iters: 286, time: 0.225, data: 0.002) G_GAN: 0.879 G_L1: 0.402 D_real: 0.388 D_fake: 0.663 \n",
      "(epoch: 118, iters: 386, time: 0.803, data: 0.002) G_GAN: 0.615 G_L1: 0.185 D_real: 0.346 D_fake: 1.016 \n",
      "(epoch: 118, iters: 486, time: 0.219, data: 0.002) G_GAN: 1.400 G_L1: 0.161 D_real: 0.471 D_fake: 0.386 \n",
      "(epoch: 118, iters: 586, time: 0.221, data: 0.002) G_GAN: 0.998 G_L1: 0.334 D_real: 0.477 D_fake: 0.585 \n",
      "(epoch: 118, iters: 686, time: 0.219, data: 0.002) G_GAN: 1.163 G_L1: 0.283 D_real: 0.664 D_fake: 0.490 \n",
      "(epoch: 118, iters: 786, time: 0.639, data: 0.002) G_GAN: 1.122 G_L1: 0.281 D_real: 0.955 D_fake: 0.485 \n",
      "saving the latest model (epoch 118, total_iters 30000)\n",
      "(epoch: 118, iters: 886, time: 0.219, data: 0.003) G_GAN: 1.490 G_L1: 0.379 D_real: 0.593 D_fake: 0.299 \n",
      "(epoch: 118, iters: 986, time: 0.218, data: 0.002) G_GAN: 1.400 G_L1: 0.319 D_real: 0.499 D_fake: 0.352 \n",
      "(epoch: 118, iters: 1086, time: 0.220, data: 0.001) G_GAN: 1.190 G_L1: 0.158 D_real: 0.646 D_fake: 0.394 \n",
      "(epoch: 118, iters: 1186, time: 0.297, data: 0.003) G_GAN: 1.304 G_L1: 0.275 D_real: 0.626 D_fake: 0.387 \n",
      "(epoch: 118, iters: 1286, time: 0.225, data: 0.002) G_GAN: 1.244 G_L1: 0.281 D_real: 0.506 D_fake: 0.476 \n",
      "(epoch: 118, iters: 1386, time: 0.223, data: 0.003) G_GAN: 1.158 G_L1: 0.186 D_real: 0.383 D_fake: 0.443 \n",
      "(epoch: 118, iters: 1486, time: 0.217, data: 0.002) G_GAN: 1.063 G_L1: 0.231 D_real: 0.872 D_fake: 0.499 \n",
      "(epoch: 118, iters: 1586, time: 0.298, data: 0.003) G_GAN: 0.872 G_L1: 0.226 D_real: 0.454 D_fake: 0.645 \n",
      "End of epoch 118 / 200 \t Time Taken: 211 sec\n",
      "learning rate 0.0000162 -> 0.0000160\n",
      "(epoch: 119, iters: 63, time: 0.222, data: 0.002) G_GAN: 1.045 G_L1: 0.162 D_real: 0.739 D_fake: 0.916 \n",
      "(epoch: 119, iters: 163, time: 0.225, data: 0.003) G_GAN: 1.092 G_L1: 0.261 D_real: 1.202 D_fake: 0.427 \n",
      "(epoch: 119, iters: 263, time: 0.220, data: 0.003) G_GAN: 0.929 G_L1: 0.307 D_real: 0.779 D_fake: 0.670 \n",
      "(epoch: 119, iters: 363, time: 0.768, data: 0.003) G_GAN: 0.976 G_L1: 0.502 D_real: 0.046 D_fake: 0.767 \n",
      "(epoch: 119, iters: 463, time: 0.216, data: 0.002) G_GAN: 0.784 G_L1: 0.337 D_real: 0.191 D_fake: 1.065 \n",
      "(epoch: 119, iters: 563, time: 0.224, data: 0.001) G_GAN: 0.907 G_L1: 0.167 D_real: 0.644 D_fake: 0.590 \n",
      "(epoch: 119, iters: 663, time: 0.222, data: 0.003) G_GAN: 1.109 G_L1: 0.151 D_real: 0.523 D_fake: 0.484 \n",
      "(epoch: 119, iters: 763, time: 0.289, data: 0.003) G_GAN: 0.846 G_L1: 0.132 D_real: 0.838 D_fake: 0.671 \n",
      "(epoch: 119, iters: 863, time: 0.215, data: 0.002) G_GAN: 1.241 G_L1: 0.396 D_real: 0.007 D_fake: 0.808 \n",
      "(epoch: 119, iters: 963, time: 0.218, data: 0.001) G_GAN: 1.229 G_L1: 0.161 D_real: 0.824 D_fake: 0.336 \n",
      "(epoch: 119, iters: 1063, time: 0.214, data: 0.003) G_GAN: 0.832 G_L1: 0.197 D_real: 0.662 D_fake: 0.740 \n",
      "(epoch: 119, iters: 1163, time: 0.691, data: 0.002) G_GAN: 0.712 G_L1: 0.153 D_real: 0.450 D_fake: 0.823 \n",
      "(epoch: 119, iters: 1263, time: 0.218, data: 0.002) G_GAN: 1.055 G_L1: 0.212 D_real: 0.967 D_fake: 0.483 \n",
      "(epoch: 119, iters: 1363, time: 0.212, data: 0.002) G_GAN: 0.971 G_L1: 0.090 D_real: 0.744 D_fake: 0.703 \n",
      "(epoch: 119, iters: 1463, time: 0.217, data: 0.003) G_GAN: 0.992 G_L1: 0.198 D_real: 0.555 D_fake: 0.537 \n",
      "(epoch: 119, iters: 1563, time: 0.293, data: 0.003) G_GAN: 1.011 G_L1: 0.127 D_real: 1.076 D_fake: 0.507 \n",
      "End of epoch 119 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000160 -> 0.0000158\n",
      "(epoch: 120, iters: 40, time: 0.223, data: 0.002) G_GAN: 1.540 G_L1: 0.278 D_real: 0.807 D_fake: 0.265 \n",
      "(epoch: 120, iters: 140, time: 0.216, data: 0.003) G_GAN: 1.108 G_L1: 0.134 D_real: 1.111 D_fake: 0.460 \n",
      "(epoch: 120, iters: 240, time: 0.220, data: 0.003) G_GAN: 1.010 G_L1: 0.529 D_real: 0.361 D_fake: 0.703 \n",
      "(epoch: 120, iters: 340, time: 0.688, data: 0.003) G_GAN: 1.042 G_L1: 0.185 D_real: 0.827 D_fake: 0.459 \n",
      "(epoch: 120, iters: 440, time: 0.218, data: 0.003) G_GAN: 1.204 G_L1: 0.240 D_real: 0.241 D_fake: 0.483 \n",
      "(epoch: 120, iters: 540, time: 0.221, data: 0.002) G_GAN: 0.818 G_L1: 0.064 D_real: 0.726 D_fake: 0.622 \n",
      "(epoch: 120, iters: 640, time: 0.216, data: 0.003) G_GAN: 0.674 G_L1: 0.313 D_real: 0.101 D_fake: 1.520 \n",
      "(epoch: 120, iters: 740, time: 0.286, data: 0.003) G_GAN: 1.113 G_L1: 0.301 D_real: 0.378 D_fake: 0.668 \n",
      "(epoch: 120, iters: 840, time: 0.217, data: 0.003) G_GAN: 1.260 G_L1: 0.351 D_real: 0.375 D_fake: 0.414 \n",
      "(epoch: 120, iters: 940, time: 0.215, data: 0.002) G_GAN: 1.231 G_L1: 0.277 D_real: 0.147 D_fake: 0.683 \n",
      "(epoch: 120, iters: 1040, time: 0.223, data: 0.003) G_GAN: 0.989 G_L1: 0.167 D_real: 0.724 D_fake: 0.539 \n",
      "(epoch: 120, iters: 1140, time: 0.289, data: 0.004) G_GAN: 1.275 G_L1: 0.192 D_real: 0.735 D_fake: 0.352 \n",
      "(epoch: 120, iters: 1240, time: 0.215, data: 0.002) G_GAN: 1.475 G_L1: 0.304 D_real: 0.065 D_fake: 0.517 \n",
      "(epoch: 120, iters: 1340, time: 0.213, data: 0.002) G_GAN: 1.237 G_L1: 0.193 D_real: 0.530 D_fake: 0.393 \n",
      "(epoch: 120, iters: 1440, time: 0.218, data: 0.003) G_GAN: 0.820 G_L1: 0.337 D_real: 0.456 D_fake: 0.951 \n",
      "(epoch: 120, iters: 1540, time: 0.828, data: 0.003) G_GAN: 0.959 G_L1: 0.171 D_real: 1.197 D_fake: 0.517 \n",
      "saving the model at the end of epoch 120, iters 34083\n",
      "End of epoch 120 / 200 \t Time Taken: 223 sec\n",
      "learning rate 0.0000158 -> 0.0000156\n",
      "(epoch: 121, iters: 17, time: 0.216, data: 0.003) G_GAN: 0.783 G_L1: 0.120 D_real: 1.251 D_fake: 0.784 \n",
      "(epoch: 121, iters: 117, time: 0.218, data: 0.002) G_GAN: 1.563 G_L1: 0.204 D_real: 0.595 D_fake: 0.256 \n",
      "(epoch: 121, iters: 217, time: 0.210, data: 0.003) G_GAN: 0.743 G_L1: 0.395 D_real: 0.988 D_fake: 0.804 \n",
      "(epoch: 121, iters: 317, time: 0.639, data: 0.003) G_GAN: 0.834 G_L1: 0.221 D_real: 0.281 D_fake: 0.915 \n",
      "(epoch: 121, iters: 417, time: 0.219, data: 0.003) G_GAN: 1.343 G_L1: 0.305 D_real: 0.667 D_fake: 0.353 \n",
      "(epoch: 121, iters: 517, time: 0.217, data: 0.003) G_GAN: 0.720 G_L1: 0.229 D_real: 0.532 D_fake: 0.895 \n",
      "(epoch: 121, iters: 617, time: 0.221, data: 0.002) G_GAN: 1.489 G_L1: 0.365 D_real: 1.230 D_fake: 0.281 \n",
      "(epoch: 121, iters: 717, time: 0.300, data: 0.003) G_GAN: 1.048 G_L1: 0.107 D_real: 0.824 D_fake: 0.620 \n",
      "(epoch: 121, iters: 817, time: 0.218, data: 0.002) G_GAN: 1.316 G_L1: 0.323 D_real: 0.395 D_fake: 0.384 \n",
      "(epoch: 121, iters: 917, time: 0.219, data: 0.003) G_GAN: 0.858 G_L1: 0.482 D_real: 0.732 D_fake: 0.687 \n",
      "saving the latest model (epoch 121, total_iters 35000)\n",
      "(epoch: 121, iters: 1017, time: 0.216, data: 0.002) G_GAN: 1.624 G_L1: 0.211 D_real: 0.923 D_fake: 0.257 \n",
      "(epoch: 121, iters: 1117, time: 0.297, data: 0.002) G_GAN: 1.043 G_L1: 0.176 D_real: 1.019 D_fake: 0.424 \n",
      "(epoch: 121, iters: 1217, time: 0.216, data: 0.002) G_GAN: 0.761 G_L1: 0.319 D_real: 0.641 D_fake: 0.922 \n",
      "(epoch: 121, iters: 1317, time: 0.217, data: 0.002) G_GAN: 1.029 G_L1: 0.106 D_real: 1.203 D_fake: 0.509 \n",
      "(epoch: 121, iters: 1417, time: 0.221, data: 0.002) G_GAN: 1.178 G_L1: 0.262 D_real: 1.088 D_fake: 0.387 \n",
      "(epoch: 121, iters: 1517, time: 0.286, data: 0.002) G_GAN: 0.959 G_L1: 0.313 D_real: 0.363 D_fake: 0.589 \n",
      "(epoch: 121, iters: 1617, time: 0.218, data: 0.002) G_GAN: 1.049 G_L1: 0.253 D_real: 0.518 D_fake: 0.485 \n",
      "End of epoch 121 / 200 \t Time Taken: 207 sec\n",
      "learning rate 0.0000156 -> 0.0000154\n",
      "(epoch: 122, iters: 94, time: 0.221, data: 0.002) G_GAN: 1.114 G_L1: 0.392 D_real: 0.246 D_fake: 0.495 \n",
      "(epoch: 122, iters: 194, time: 0.220, data: 0.003) G_GAN: 1.095 G_L1: 0.225 D_real: 0.567 D_fake: 0.523 \n",
      "(epoch: 122, iters: 294, time: 0.710, data: 0.003) G_GAN: 0.739 G_L1: 0.214 D_real: 0.402 D_fake: 0.862 \n",
      "(epoch: 122, iters: 394, time: 0.216, data: 0.003) G_GAN: 1.493 G_L1: 0.326 D_real: 1.022 D_fake: 0.387 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 122, iters: 494, time: 0.215, data: 0.003) G_GAN: 1.438 G_L1: 0.366 D_real: 0.023 D_fake: 0.476 \n",
      "(epoch: 122, iters: 594, time: 0.222, data: 0.003) G_GAN: 1.203 G_L1: 0.293 D_real: 0.246 D_fake: 0.515 \n",
      "(epoch: 122, iters: 694, time: 0.306, data: 0.003) G_GAN: 1.282 G_L1: 0.164 D_real: 0.971 D_fake: 0.383 \n",
      "(epoch: 122, iters: 794, time: 0.217, data: 0.002) G_GAN: 1.020 G_L1: 0.242 D_real: 0.751 D_fake: 0.535 \n",
      "(epoch: 122, iters: 894, time: 0.217, data: 0.003) G_GAN: 1.795 G_L1: 0.403 D_real: 0.007 D_fake: 0.342 \n",
      "(epoch: 122, iters: 994, time: 0.216, data: 0.003) G_GAN: 0.960 G_L1: 0.219 D_real: 0.426 D_fake: 0.568 \n",
      "(epoch: 122, iters: 1094, time: 0.309, data: 0.003) G_GAN: 0.922 G_L1: 0.200 D_real: 0.150 D_fake: 0.683 \n",
      "(epoch: 122, iters: 1194, time: 0.215, data: 0.003) G_GAN: 0.950 G_L1: 0.169 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 122, iters: 1294, time: 0.219, data: 0.003) G_GAN: 1.154 G_L1: 0.269 D_real: 0.880 D_fake: 0.455 \n",
      "(epoch: 122, iters: 1394, time: 0.216, data: 0.003) G_GAN: 0.999 G_L1: 0.254 D_real: 0.378 D_fake: 0.661 \n",
      "(epoch: 122, iters: 1494, time: 0.295, data: 0.003) G_GAN: 1.144 G_L1: 0.266 D_real: 0.828 D_fake: 0.544 \n",
      "(epoch: 122, iters: 1594, time: 0.217, data: 0.003) G_GAN: 1.315 G_L1: 0.276 D_real: 0.728 D_fake: 0.395 \n",
      "End of epoch 122 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000154 -> 0.0000152\n",
      "(epoch: 123, iters: 71, time: 0.218, data: 0.003) G_GAN: 0.888 G_L1: 0.464 D_real: 0.582 D_fake: 0.631 \n",
      "(epoch: 123, iters: 171, time: 0.215, data: 0.003) G_GAN: 1.245 G_L1: 0.162 D_real: 0.584 D_fake: 0.391 \n",
      "(epoch: 123, iters: 271, time: 0.710, data: 0.003) G_GAN: 1.110 G_L1: 0.123 D_real: 0.537 D_fake: 0.460 \n",
      "(epoch: 123, iters: 371, time: 0.212, data: 0.003) G_GAN: 0.534 G_L1: 0.323 D_real: 0.465 D_fake: 1.320 \n",
      "(epoch: 123, iters: 471, time: 0.218, data: 0.002) G_GAN: 1.155 G_L1: 0.192 D_real: 0.444 D_fake: 0.515 \n",
      "(epoch: 123, iters: 571, time: 0.225, data: 0.003) G_GAN: 0.776 G_L1: 0.190 D_real: 1.116 D_fake: 0.652 \n",
      "(epoch: 123, iters: 671, time: 0.698, data: 0.002) G_GAN: 1.209 G_L1: 0.271 D_real: 0.935 D_fake: 0.376 \n",
      "(epoch: 123, iters: 771, time: 0.215, data: 0.003) G_GAN: 0.717 G_L1: 0.235 D_real: 0.443 D_fake: 0.951 \n",
      "(epoch: 123, iters: 871, time: 0.214, data: 0.002) G_GAN: 1.207 G_L1: 0.234 D_real: 0.580 D_fake: 0.372 \n",
      "(epoch: 123, iters: 971, time: 0.218, data: 0.003) G_GAN: 1.069 G_L1: 0.332 D_real: 0.606 D_fake: 0.508 \n",
      "(epoch: 123, iters: 1071, time: 0.293, data: 0.003) G_GAN: 1.694 G_L1: 0.501 D_real: 0.051 D_fake: 0.341 \n",
      "(epoch: 123, iters: 1171, time: 0.209, data: 0.003) G_GAN: 0.750 G_L1: 0.147 D_real: 0.665 D_fake: 0.922 \n",
      "(epoch: 123, iters: 1271, time: 0.216, data: 0.003) G_GAN: 1.487 G_L1: 0.303 D_real: 0.259 D_fake: 0.366 \n",
      "(epoch: 123, iters: 1371, time: 0.218, data: 0.003) G_GAN: 1.356 G_L1: 0.355 D_real: 0.546 D_fake: 0.345 \n",
      "(epoch: 123, iters: 1471, time: 0.300, data: 0.003) G_GAN: 1.033 G_L1: 0.272 D_real: 0.738 D_fake: 0.467 \n",
      "(epoch: 123, iters: 1571, time: 0.219, data: 0.002) G_GAN: 1.010 G_L1: 0.420 D_real: 0.703 D_fake: 0.561 \n",
      "End of epoch 123 / 200 \t Time Taken: 206 sec\n",
      "learning rate 0.0000152 -> 0.0000150\n",
      "(epoch: 124, iters: 48, time: 0.216, data: 0.003) G_GAN: 1.244 G_L1: 0.163 D_real: 0.838 D_fake: 0.376 \n",
      "(epoch: 124, iters: 148, time: 0.220, data: 0.003) G_GAN: 1.548 G_L1: 0.191 D_real: 1.086 D_fake: 0.254 \n",
      "(epoch: 124, iters: 248, time: 0.854, data: 0.003) G_GAN: 1.099 G_L1: 0.457 D_real: 0.615 D_fake: 0.561 \n",
      "(epoch: 124, iters: 348, time: 0.207, data: 0.003) G_GAN: 1.032 G_L1: 0.301 D_real: 0.666 D_fake: 0.650 \n",
      "(epoch: 124, iters: 448, time: 0.217, data: 0.003) G_GAN: 1.557 G_L1: 0.221 D_real: 0.826 D_fake: 0.298 \n",
      "(epoch: 124, iters: 548, time: 0.216, data: 0.003) G_GAN: 1.062 G_L1: 0.287 D_real: 0.343 D_fake: 0.476 \n",
      "(epoch: 124, iters: 648, time: 0.306, data: 0.003) G_GAN: 1.084 G_L1: 0.461 D_real: 0.562 D_fake: 0.509 \n",
      "(epoch: 124, iters: 748, time: 0.216, data: 0.003) G_GAN: 0.926 G_L1: 0.455 D_real: 0.140 D_fake: 0.657 \n",
      "(epoch: 124, iters: 848, time: 0.216, data: 0.003) G_GAN: 1.021 G_L1: 0.235 D_real: 0.748 D_fake: 0.657 \n",
      "(epoch: 124, iters: 948, time: 0.220, data: 0.003) G_GAN: 1.339 G_L1: 0.277 D_real: 0.561 D_fake: 0.532 \n",
      "(epoch: 124, iters: 1048, time: 0.706, data: 0.003) G_GAN: 1.072 G_L1: 0.136 D_real: 0.759 D_fake: 0.500 \n",
      "saving the latest model (epoch 124, total_iters 40000)\n",
      "(epoch: 124, iters: 1148, time: 0.220, data: 0.003) G_GAN: 1.171 G_L1: 0.233 D_real: 0.263 D_fake: 0.453 \n",
      "(epoch: 124, iters: 1248, time: 0.220, data: 0.003) G_GAN: 0.955 G_L1: 0.398 D_real: 0.565 D_fake: 0.583 \n",
      "(epoch: 124, iters: 1348, time: 0.216, data: 0.003) G_GAN: 1.152 G_L1: 0.225 D_real: 0.829 D_fake: 0.432 \n",
      "(epoch: 124, iters: 1448, time: 0.301, data: 0.003) G_GAN: 1.272 G_L1: 0.304 D_real: 0.498 D_fake: 0.382 \n",
      "(epoch: 124, iters: 1548, time: 0.216, data: 0.004) G_GAN: 1.053 G_L1: 0.114 D_real: 0.756 D_fake: 0.486 \n",
      "End of epoch 124 / 200 \t Time Taken: 209 sec\n",
      "learning rate 0.0000150 -> 0.0000149\n",
      "(epoch: 125, iters: 25, time: 0.223, data: 0.003) G_GAN: 1.170 G_L1: 0.280 D_real: 0.170 D_fake: 0.554 \n",
      "(epoch: 125, iters: 125, time: 0.221, data: 0.003) G_GAN: 0.937 G_L1: 0.185 D_real: 0.779 D_fake: 0.534 \n",
      "(epoch: 125, iters: 225, time: 0.640, data: 0.003) G_GAN: 1.082 G_L1: 0.206 D_real: 0.485 D_fake: 0.705 \n",
      "(epoch: 125, iters: 325, time: 0.217, data: 0.002) G_GAN: 1.214 G_L1: 0.246 D_real: 0.520 D_fake: 0.458 \n",
      "(epoch: 125, iters: 425, time: 0.217, data: 0.001) G_GAN: 0.999 G_L1: 0.360 D_real: 0.563 D_fake: 0.594 \n",
      "(epoch: 125, iters: 525, time: 0.219, data: 0.001) G_GAN: 1.779 G_L1: 0.446 D_real: 0.435 D_fake: 0.247 \n",
      "(epoch: 125, iters: 625, time: 0.283, data: 0.002) G_GAN: 1.223 G_L1: 0.506 D_real: 0.992 D_fake: 0.427 \n",
      "(epoch: 125, iters: 725, time: 0.216, data: 0.002) G_GAN: 1.349 G_L1: 0.192 D_real: 0.991 D_fake: 0.398 \n",
      "(epoch: 125, iters: 825, time: 0.215, data: 0.001) G_GAN: 0.758 G_L1: 0.164 D_real: 0.536 D_fake: 0.802 \n",
      "(epoch: 125, iters: 925, time: 0.213, data: 0.001) G_GAN: 0.938 G_L1: 0.255 D_real: 0.789 D_fake: 0.549 \n",
      "(epoch: 125, iters: 1025, time: 0.289, data: 0.002) G_GAN: 1.474 G_L1: 0.339 D_real: 0.521 D_fake: 0.313 \n",
      "(epoch: 125, iters: 1125, time: 0.214, data: 0.001) G_GAN: 1.302 G_L1: 0.218 D_real: 0.749 D_fake: 0.379 \n",
      "(epoch: 125, iters: 1225, time: 0.217, data: 0.001) G_GAN: 1.002 G_L1: 0.106 D_real: 0.285 D_fake: 0.576 \n",
      "(epoch: 125, iters: 1325, time: 0.218, data: 0.002) G_GAN: 1.557 G_L1: 0.221 D_real: 0.280 D_fake: 0.374 \n",
      "(epoch: 125, iters: 1425, time: 0.651, data: 0.001) G_GAN: 0.891 G_L1: 0.371 D_real: 0.112 D_fake: 0.708 \n",
      "(epoch: 125, iters: 1525, time: 0.216, data: 0.002) G_GAN: 0.996 G_L1: 0.272 D_real: 0.441 D_fake: 0.535 \n",
      "saving the model at the end of epoch 125, iters 42198\n",
      "End of epoch 125 / 200 \t Time Taken: 210 sec\n",
      "learning rate 0.0000149 -> 0.0000147\n",
      "(epoch: 126, iters: 2, time: 0.267, data: 0.001) G_GAN: 1.078 G_L1: 0.110 D_real: 0.343 D_fake: 0.590 \n",
      "(epoch: 126, iters: 102, time: 0.211, data: 0.000) G_GAN: 0.800 G_L1: 0.187 D_real: 0.575 D_fake: 0.709 \n",
      "(epoch: 126, iters: 202, time: 0.646, data: 0.003) G_GAN: 0.726 G_L1: 0.104 D_real: 0.701 D_fake: 0.762 \n",
      "(epoch: 126, iters: 302, time: 0.216, data: 0.002) G_GAN: 1.084 G_L1: 0.367 D_real: 0.425 D_fake: 0.508 \n",
      "(epoch: 126, iters: 402, time: 0.224, data: 0.001) G_GAN: 1.076 G_L1: 0.573 D_real: 0.243 D_fake: 0.482 \n",
      "(epoch: 126, iters: 502, time: 0.217, data: 0.002) G_GAN: 1.047 G_L1: 0.411 D_real: 0.574 D_fake: 0.590 \n",
      "(epoch: 126, iters: 602, time: 0.277, data: 0.001) G_GAN: 1.005 G_L1: 0.229 D_real: 0.406 D_fake: 0.542 \n",
      "(epoch: 126, iters: 702, time: 0.219, data: 0.001) G_GAN: 1.436 G_L1: 0.194 D_real: 0.023 D_fake: 0.387 \n",
      "(epoch: 126, iters: 802, time: 0.224, data: 0.003) G_GAN: 1.216 G_L1: 0.243 D_real: 0.848 D_fake: 0.394 \n",
      "(epoch: 126, iters: 902, time: 0.220, data: 0.002) G_GAN: 1.140 G_L1: 0.277 D_real: 0.023 D_fake: 0.588 \n",
      "(epoch: 126, iters: 1002, time: 0.294, data: 0.001) G_GAN: 1.316 G_L1: 0.153 D_real: 0.813 D_fake: 0.331 \n",
      "(epoch: 126, iters: 1102, time: 0.219, data: 0.002) G_GAN: 1.195 G_L1: 0.219 D_real: 0.289 D_fake: 0.450 \n",
      "(epoch: 126, iters: 1202, time: 0.221, data: 0.002) G_GAN: 1.331 G_L1: 0.236 D_real: 0.605 D_fake: 0.313 \n",
      "(epoch: 126, iters: 1302, time: 0.217, data: 0.001) G_GAN: 1.360 G_L1: 0.182 D_real: 0.761 D_fake: 0.320 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 126, iters: 1402, time: 0.291, data: 0.001) G_GAN: 0.789 G_L1: 0.211 D_real: 0.745 D_fake: 0.720 \n",
      "(epoch: 126, iters: 1502, time: 0.220, data: 0.002) G_GAN: 2.066 G_L1: 0.265 D_real: 0.133 D_fake: 0.199 \n",
      "(epoch: 126, iters: 1602, time: 0.220, data: 0.001) G_GAN: 0.997 G_L1: 0.171 D_real: 1.115 D_fake: 0.540 \n",
      "End of epoch 126 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000147 -> 0.0000145\n",
      "(epoch: 127, iters: 79, time: 0.221, data: 0.003) G_GAN: 1.048 G_L1: 0.255 D_real: 0.398 D_fake: 0.521 \n",
      "(epoch: 127, iters: 179, time: 0.678, data: 0.003) G_GAN: 0.944 G_L1: 0.228 D_real: 0.465 D_fake: 0.586 \n",
      "(epoch: 127, iters: 279, time: 0.219, data: 0.002) G_GAN: 1.337 G_L1: 0.173 D_real: 0.876 D_fake: 0.337 \n",
      "(epoch: 127, iters: 379, time: 0.227, data: 0.002) G_GAN: 0.675 G_L1: 0.161 D_real: 0.705 D_fake: 0.965 \n",
      "(epoch: 127, iters: 479, time: 0.217, data: 0.002) G_GAN: 0.925 G_L1: 0.437 D_real: 0.776 D_fake: 0.583 \n",
      "(epoch: 127, iters: 579, time: 0.302, data: 0.003) G_GAN: 1.104 G_L1: 0.311 D_real: 0.864 D_fake: 0.456 \n",
      "(epoch: 127, iters: 679, time: 0.217, data: 0.002) G_GAN: 1.746 G_L1: 0.363 D_real: 0.022 D_fake: 0.346 \n",
      "(epoch: 127, iters: 779, time: 0.216, data: 0.001) G_GAN: 1.156 G_L1: 0.178 D_real: 0.800 D_fake: 0.387 \n",
      "(epoch: 127, iters: 879, time: 0.217, data: 0.002) G_GAN: 0.820 G_L1: 0.392 D_real: 0.595 D_fake: 0.645 \n",
      "(epoch: 127, iters: 979, time: 0.286, data: 0.002) G_GAN: 0.925 G_L1: 0.353 D_real: 0.667 D_fake: 0.729 \n",
      "(epoch: 127, iters: 1079, time: 0.219, data: 0.003) G_GAN: 1.133 G_L1: 0.114 D_real: 0.417 D_fake: 0.443 \n",
      "(epoch: 127, iters: 1179, time: 0.219, data: 0.001) G_GAN: 0.944 G_L1: 0.199 D_real: 0.662 D_fake: 0.523 \n",
      "saving the latest model (epoch 127, total_iters 45000)\n",
      "(epoch: 127, iters: 1279, time: 0.220, data: 0.002) G_GAN: 1.315 G_L1: 0.279 D_real: 0.027 D_fake: 0.501 \n",
      "(epoch: 127, iters: 1379, time: 0.283, data: 0.002) G_GAN: 1.957 G_L1: 0.552 D_real: 0.157 D_fake: 0.226 \n",
      "(epoch: 127, iters: 1479, time: 0.221, data: 0.002) G_GAN: 0.573 G_L1: 0.114 D_real: 1.021 D_fake: 1.014 \n",
      "(epoch: 127, iters: 1579, time: 0.222, data: 0.003) G_GAN: 0.969 G_L1: 0.365 D_real: 0.588 D_fake: 0.675 \n",
      "End of epoch 127 / 200 \t Time Taken: 208 sec\n",
      "learning rate 0.0000145 -> 0.0000143\n",
      "(epoch: 128, iters: 56, time: 0.218, data: 0.003) G_GAN: 1.516 G_L1: 0.345 D_real: 0.620 D_fake: 0.311 \n",
      "(epoch: 128, iters: 156, time: 0.665, data: 0.003) G_GAN: 1.218 G_L1: 0.127 D_real: 1.267 D_fake: 0.421 \n",
      "(epoch: 128, iters: 256, time: 0.216, data: 0.002) G_GAN: 1.187 G_L1: 0.267 D_real: 0.560 D_fake: 0.476 \n",
      "(epoch: 128, iters: 356, time: 0.220, data: 0.004) G_GAN: 1.143 G_L1: 0.214 D_real: 0.612 D_fake: 0.445 \n",
      "(epoch: 128, iters: 456, time: 0.221, data: 0.001) G_GAN: 0.989 G_L1: 0.288 D_real: 0.672 D_fake: 0.522 \n",
      "(epoch: 128, iters: 556, time: 0.671, data: 0.001) G_GAN: 1.044 G_L1: 0.145 D_real: 0.444 D_fake: 0.507 \n",
      "(epoch: 128, iters: 656, time: 0.216, data: 0.002) G_GAN: 0.900 G_L1: 0.362 D_real: 0.403 D_fake: 0.766 \n",
      "(epoch: 128, iters: 756, time: 0.215, data: 0.002) G_GAN: 0.850 G_L1: 0.206 D_real: 0.675 D_fake: 0.598 \n",
      "(epoch: 128, iters: 856, time: 0.215, data: 0.002) G_GAN: 1.323 G_L1: 0.161 D_real: 1.034 D_fake: 0.308 \n",
      "(epoch: 128, iters: 956, time: 0.300, data: 0.003) G_GAN: 0.703 G_L1: 0.208 D_real: 0.947 D_fake: 0.914 \n",
      "(epoch: 128, iters: 1056, time: 0.218, data: 0.003) G_GAN: 1.124 G_L1: 0.177 D_real: 0.715 D_fake: 0.444 \n",
      "(epoch: 128, iters: 1156, time: 0.216, data: 0.002) G_GAN: 0.803 G_L1: 0.202 D_real: 1.005 D_fake: 0.709 \n",
      "(epoch: 128, iters: 1256, time: 0.213, data: 0.003) G_GAN: 1.060 G_L1: 0.139 D_real: 0.637 D_fake: 0.457 \n",
      "(epoch: 128, iters: 1356, time: 0.289, data: 0.002) G_GAN: 1.035 G_L1: 0.120 D_real: 0.727 D_fake: 0.556 \n",
      "(epoch: 128, iters: 1456, time: 0.218, data: 0.002) G_GAN: 1.117 G_L1: 0.169 D_real: 0.818 D_fake: 0.409 \n",
      "(epoch: 128, iters: 1556, time: 0.222, data: 0.003) G_GAN: 1.144 G_L1: 0.576 D_real: 0.470 D_fake: 0.572 \n",
      "End of epoch 128 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000143 -> 0.0000141\n",
      "(epoch: 129, iters: 33, time: 0.222, data: 0.003) G_GAN: 1.056 G_L1: 0.209 D_real: 0.633 D_fake: 0.503 \n",
      "(epoch: 129, iters: 133, time: 0.676, data: 0.002) G_GAN: 0.970 G_L1: 0.229 D_real: 0.877 D_fake: 0.528 \n",
      "(epoch: 129, iters: 233, time: 0.220, data: 0.002) G_GAN: 0.818 G_L1: 0.133 D_real: 0.450 D_fake: 0.678 \n",
      "(epoch: 129, iters: 333, time: 0.217, data: 0.002) G_GAN: 1.113 G_L1: 0.137 D_real: 0.300 D_fake: 0.578 \n",
      "(epoch: 129, iters: 433, time: 0.220, data: 0.002) G_GAN: 1.244 G_L1: 0.272 D_real: 0.578 D_fake: 0.409 \n",
      "(epoch: 129, iters: 533, time: 0.286, data: 0.001) G_GAN: 0.665 G_L1: 0.145 D_real: 0.572 D_fake: 0.881 \n",
      "(epoch: 129, iters: 633, time: 0.222, data: 0.002) G_GAN: 1.606 G_L1: 0.334 D_real: 0.405 D_fake: 0.271 \n",
      "(epoch: 129, iters: 733, time: 0.217, data: 0.001) G_GAN: 0.985 G_L1: 0.198 D_real: 0.765 D_fake: 0.589 \n",
      "(epoch: 129, iters: 833, time: 0.219, data: 0.001) G_GAN: 0.827 G_L1: 0.298 D_real: 1.211 D_fake: 0.633 \n",
      "(epoch: 129, iters: 933, time: 0.649, data: 0.002) G_GAN: 1.389 G_L1: 0.184 D_real: 0.748 D_fake: 0.403 \n",
      "(epoch: 129, iters: 1033, time: 0.218, data: 0.002) G_GAN: 1.684 G_L1: 0.102 D_real: 1.143 D_fake: 0.214 \n",
      "(epoch: 129, iters: 1133, time: 0.217, data: 0.001) G_GAN: 1.256 G_L1: 0.207 D_real: 0.510 D_fake: 0.473 \n",
      "(epoch: 129, iters: 1233, time: 0.221, data: 0.001) G_GAN: 1.143 G_L1: 0.472 D_real: 0.024 D_fake: 0.514 \n",
      "(epoch: 129, iters: 1333, time: 0.289, data: 0.001) G_GAN: 1.271 G_L1: 0.162 D_real: 0.413 D_fake: 0.386 \n",
      "(epoch: 129, iters: 1433, time: 0.219, data: 0.002) G_GAN: 1.244 G_L1: 0.126 D_real: 0.629 D_fake: 0.360 \n",
      "(epoch: 129, iters: 1533, time: 0.219, data: 0.002) G_GAN: 1.015 G_L1: 0.263 D_real: 0.708 D_fake: 0.530 \n",
      "End of epoch 129 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000141 -> 0.0000139\n",
      "(epoch: 130, iters: 10, time: 0.228, data: 0.002) G_GAN: 1.270 G_L1: 0.217 D_real: 1.086 D_fake: 0.395 \n",
      "(epoch: 130, iters: 110, time: 0.759, data: 0.003) G_GAN: 1.293 G_L1: 0.161 D_real: 1.206 D_fake: 0.479 \n",
      "(epoch: 130, iters: 210, time: 0.220, data: 0.003) G_GAN: 1.356 G_L1: 0.065 D_real: 0.792 D_fake: 0.293 \n",
      "(epoch: 130, iters: 310, time: 0.220, data: 0.002) G_GAN: 1.100 G_L1: 0.247 D_real: 0.916 D_fake: 0.487 \n",
      "(epoch: 130, iters: 410, time: 0.218, data: 0.002) G_GAN: 1.359 G_L1: 0.188 D_real: 1.319 D_fake: 0.254 \n",
      "(epoch: 130, iters: 510, time: 0.291, data: 0.002) G_GAN: 1.086 G_L1: 0.087 D_real: 0.931 D_fake: 0.415 \n",
      "(epoch: 130, iters: 610, time: 0.222, data: 0.003) G_GAN: 0.513 G_L1: 0.172 D_real: 0.794 D_fake: 1.120 \n",
      "(epoch: 130, iters: 710, time: 0.223, data: 0.003) G_GAN: 1.061 G_L1: 0.326 D_real: 0.328 D_fake: 0.556 \n",
      "(epoch: 130, iters: 810, time: 0.226, data: 0.003) G_GAN: 1.165 G_L1: 0.389 D_real: 0.404 D_fake: 0.525 \n",
      "(epoch: 130, iters: 910, time: 0.294, data: 0.003) G_GAN: 1.068 G_L1: 0.230 D_real: 0.058 D_fake: 0.600 \n",
      "(epoch: 130, iters: 1010, time: 0.222, data: 0.002) G_GAN: 1.049 G_L1: 0.259 D_real: 0.297 D_fake: 0.538 \n",
      "(epoch: 130, iters: 1110, time: 0.223, data: 0.003) G_GAN: 1.159 G_L1: 0.357 D_real: 0.509 D_fake: 0.424 \n",
      "(epoch: 130, iters: 1210, time: 0.217, data: 0.003) G_GAN: 1.157 G_L1: 0.364 D_real: 0.328 D_fake: 0.440 \n",
      "(epoch: 130, iters: 1310, time: 0.688, data: 0.003) G_GAN: 0.765 G_L1: 0.142 D_real: 0.576 D_fake: 0.782 \n",
      "saving the latest model (epoch 130, total_iters 50000)\n",
      "(epoch: 130, iters: 1410, time: 0.216, data: 0.002) G_GAN: 1.056 G_L1: 0.231 D_real: 0.626 D_fake: 0.489 \n",
      "(epoch: 130, iters: 1510, time: 0.222, data: 0.002) G_GAN: 1.292 G_L1: 0.190 D_real: 0.739 D_fake: 0.428 \n",
      "(epoch: 130, iters: 1610, time: 0.219, data: 0.001) G_GAN: 0.946 G_L1: 0.279 D_real: 0.500 D_fake: 0.616 \n",
      "saving the model at the end of epoch 130, iters 50313\n",
      "End of epoch 130 / 200 \t Time Taken: 213 sec\n",
      "learning rate 0.0000139 -> 0.0000137\n",
      "(epoch: 131, iters: 87, time: 0.687, data: 0.002) G_GAN: 1.131 G_L1: 0.112 D_real: 0.734 D_fake: 0.419 \n",
      "(epoch: 131, iters: 187, time: 0.223, data: 0.002) G_GAN: 1.012 G_L1: 0.149 D_real: 0.447 D_fake: 0.669 \n",
      "(epoch: 131, iters: 287, time: 0.218, data: 0.003) G_GAN: 1.312 G_L1: 0.201 D_real: 0.507 D_fake: 0.442 \n",
      "(epoch: 131, iters: 387, time: 0.216, data: 0.003) G_GAN: 1.295 G_L1: 0.226 D_real: 0.690 D_fake: 0.433 \n",
      "(epoch: 131, iters: 487, time: 0.286, data: 0.002) G_GAN: 1.161 G_L1: 0.265 D_real: 0.014 D_fake: 0.530 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 131, iters: 587, time: 0.214, data: 0.002) G_GAN: 1.246 G_L1: 0.276 D_real: 0.745 D_fake: 0.484 \n",
      "(epoch: 131, iters: 687, time: 0.217, data: 0.002) G_GAN: 1.154 G_L1: 0.359 D_real: 0.325 D_fake: 0.503 \n",
      "(epoch: 131, iters: 787, time: 0.225, data: 0.003) G_GAN: 0.976 G_L1: 0.290 D_real: 0.173 D_fake: 0.953 \n",
      "(epoch: 131, iters: 887, time: 0.294, data: 0.002) G_GAN: 1.334 G_L1: 0.263 D_real: 0.008 D_fake: 0.412 \n",
      "(epoch: 131, iters: 987, time: 0.218, data: 0.002) G_GAN: 0.967 G_L1: 0.191 D_real: 0.623 D_fake: 0.583 \n",
      "(epoch: 131, iters: 1087, time: 0.220, data: 0.002) G_GAN: 1.304 G_L1: 0.254 D_real: 1.011 D_fake: 0.446 \n",
      "(epoch: 131, iters: 1187, time: 0.224, data: 0.003) G_GAN: 0.859 G_L1: 0.255 D_real: 0.390 D_fake: 0.711 \n",
      "(epoch: 131, iters: 1287, time: 0.296, data: 0.002) G_GAN: 1.303 G_L1: 0.141 D_real: 0.705 D_fake: 0.376 \n",
      "(epoch: 131, iters: 1387, time: 0.220, data: 0.002) G_GAN: 2.010 G_L1: 0.417 D_real: 0.222 D_fake: 0.227 \n",
      "(epoch: 131, iters: 1487, time: 0.218, data: 0.001) G_GAN: 1.111 G_L1: 0.186 D_real: 1.142 D_fake: 0.432 \n",
      "(epoch: 131, iters: 1587, time: 0.223, data: 0.002) G_GAN: 1.389 G_L1: 0.303 D_real: 0.572 D_fake: 0.350 \n",
      "End of epoch 131 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000137 -> 0.0000135\n",
      "(epoch: 132, iters: 64, time: 0.655, data: 0.002) G_GAN: 1.312 G_L1: 0.201 D_real: 0.624 D_fake: 0.345 \n",
      "(epoch: 132, iters: 164, time: 0.224, data: 0.002) G_GAN: 1.403 G_L1: 0.339 D_real: 1.167 D_fake: 0.302 \n",
      "(epoch: 132, iters: 264, time: 0.226, data: 0.002) G_GAN: 1.239 G_L1: 0.190 D_real: 0.410 D_fake: 0.391 \n",
      "(epoch: 132, iters: 364, time: 0.221, data: 0.005) G_GAN: 1.251 G_L1: 0.507 D_real: 0.422 D_fake: 0.412 \n",
      "(epoch: 132, iters: 464, time: 0.305, data: 0.003) G_GAN: 1.073 G_L1: 0.209 D_real: 0.503 D_fake: 0.474 \n",
      "(epoch: 132, iters: 564, time: 0.220, data: 0.002) G_GAN: 0.855 G_L1: 0.238 D_real: 0.655 D_fake: 0.655 \n",
      "(epoch: 132, iters: 664, time: 0.224, data: 0.002) G_GAN: 0.808 G_L1: 0.174 D_real: 0.831 D_fake: 1.119 \n",
      "(epoch: 132, iters: 764, time: 0.216, data: 0.003) G_GAN: 0.929 G_L1: 0.223 D_real: 0.576 D_fake: 0.637 \n",
      "(epoch: 132, iters: 864, time: 0.284, data: 0.002) G_GAN: 0.975 G_L1: 0.280 D_real: 0.336 D_fake: 1.133 \n",
      "(epoch: 132, iters: 964, time: 0.220, data: 0.002) G_GAN: 1.338 G_L1: 0.214 D_real: 0.461 D_fake: 0.394 \n",
      "(epoch: 132, iters: 1064, time: 0.227, data: 0.002) G_GAN: 0.874 G_L1: 0.306 D_real: 0.650 D_fake: 0.764 \n",
      "(epoch: 132, iters: 1164, time: 0.217, data: 0.003) G_GAN: 1.030 G_L1: 0.115 D_real: 0.364 D_fake: 0.585 \n",
      "(epoch: 132, iters: 1264, time: 0.289, data: 0.001) G_GAN: 0.856 G_L1: 0.210 D_real: 0.011 D_fake: 0.912 \n",
      "(epoch: 132, iters: 1364, time: 0.218, data: 0.002) G_GAN: 1.216 G_L1: 0.374 D_real: 0.016 D_fake: 0.535 \n",
      "(epoch: 132, iters: 1464, time: 0.218, data: 0.001) G_GAN: 0.718 G_L1: 0.099 D_real: 0.619 D_fake: 0.852 \n",
      "(epoch: 132, iters: 1564, time: 0.220, data: 0.002) G_GAN: 1.176 G_L1: 0.312 D_real: 0.637 D_fake: 0.443 \n",
      "End of epoch 132 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000135 -> 0.0000133\n",
      "(epoch: 133, iters: 41, time: 0.687, data: 0.002) G_GAN: 1.129 G_L1: 0.226 D_real: 1.028 D_fake: 0.436 \n",
      "(epoch: 133, iters: 141, time: 0.219, data: 0.002) G_GAN: 0.808 G_L1: 0.121 D_real: 0.439 D_fake: 0.703 \n",
      "(epoch: 133, iters: 241, time: 0.218, data: 0.003) G_GAN: 1.190 G_L1: 0.415 D_real: 0.496 D_fake: 0.409 \n",
      "(epoch: 133, iters: 341, time: 0.217, data: 0.002) G_GAN: 1.337 G_L1: 0.082 D_real: 0.493 D_fake: 0.346 \n",
      "(epoch: 133, iters: 441, time: 0.790, data: 0.002) G_GAN: 1.092 G_L1: 0.288 D_real: 1.103 D_fake: 0.543 \n",
      "(epoch: 133, iters: 541, time: 0.218, data: 0.002) G_GAN: 1.292 G_L1: 0.166 D_real: 0.672 D_fake: 0.385 \n",
      "(epoch: 133, iters: 641, time: 0.215, data: 0.003) G_GAN: 1.685 G_L1: 0.266 D_real: 0.320 D_fake: 0.241 \n",
      "(epoch: 133, iters: 741, time: 0.222, data: 0.002) G_GAN: 1.171 G_L1: 0.314 D_real: 0.533 D_fake: 0.413 \n",
      "(epoch: 133, iters: 841, time: 0.303, data: 0.002) G_GAN: 1.143 G_L1: 0.327 D_real: 1.151 D_fake: 0.378 \n",
      "(epoch: 133, iters: 941, time: 0.224, data: 0.002) G_GAN: 0.881 G_L1: 0.194 D_real: 0.403 D_fake: 0.610 \n",
      "(epoch: 133, iters: 1041, time: 0.221, data: 0.002) G_GAN: 0.960 G_L1: 0.090 D_real: 0.658 D_fake: 0.553 \n",
      "(epoch: 133, iters: 1141, time: 0.226, data: 0.003) G_GAN: 1.654 G_L1: 0.110 D_real: 0.744 D_fake: 0.215 \n",
      "(epoch: 133, iters: 1241, time: 0.287, data: 0.002) G_GAN: 1.356 G_L1: 0.208 D_real: 0.613 D_fake: 0.326 \n",
      "(epoch: 133, iters: 1341, time: 0.217, data: 0.002) G_GAN: 0.804 G_L1: 0.192 D_real: 0.957 D_fake: 0.653 \n",
      "(epoch: 133, iters: 1441, time: 0.222, data: 0.001) G_GAN: 0.847 G_L1: 0.171 D_real: 0.606 D_fake: 0.615 \n",
      "saving the latest model (epoch 133, total_iters 55000)\n",
      "(epoch: 133, iters: 1541, time: 0.217, data: 0.002) G_GAN: 0.951 G_L1: 0.192 D_real: 1.031 D_fake: 0.553 \n",
      "End of epoch 133 / 200 \t Time Taken: 208 sec\n",
      "learning rate 0.0000133 -> 0.0000131\n",
      "(epoch: 134, iters: 18, time: 0.672, data: 0.002) G_GAN: 1.154 G_L1: 0.217 D_real: 0.339 D_fake: 0.465 \n",
      "(epoch: 134, iters: 118, time: 0.220, data: 0.002) G_GAN: 0.788 G_L1: 0.173 D_real: 1.092 D_fake: 0.910 \n",
      "(epoch: 134, iters: 218, time: 0.216, data: 0.002) G_GAN: 1.474 G_L1: 0.230 D_real: 0.814 D_fake: 0.305 \n",
      "(epoch: 134, iters: 318, time: 0.222, data: 0.002) G_GAN: 1.089 G_L1: 0.192 D_real: 0.947 D_fake: 0.465 \n",
      "(epoch: 134, iters: 418, time: 0.301, data: 0.001) G_GAN: 1.176 G_L1: 0.107 D_real: 0.696 D_fake: 0.395 \n",
      "(epoch: 134, iters: 518, time: 0.221, data: 0.002) G_GAN: 0.997 G_L1: 0.231 D_real: 0.512 D_fake: 0.599 \n",
      "(epoch: 134, iters: 618, time: 0.217, data: 0.002) G_GAN: 1.214 G_L1: 0.647 D_real: 0.086 D_fake: 0.465 \n",
      "(epoch: 134, iters: 718, time: 0.218, data: 0.002) G_GAN: 1.010 G_L1: 0.277 D_real: 0.527 D_fake: 0.652 \n",
      "(epoch: 134, iters: 818, time: 0.680, data: 0.002) G_GAN: 0.983 G_L1: 0.185 D_real: 0.393 D_fake: 0.595 \n",
      "(epoch: 134, iters: 918, time: 0.217, data: 0.002) G_GAN: 0.878 G_L1: 0.245 D_real: 0.249 D_fake: 0.708 \n",
      "(epoch: 134, iters: 1018, time: 0.219, data: 0.001) G_GAN: 1.262 G_L1: 0.273 D_real: 0.845 D_fake: 0.317 \n",
      "(epoch: 134, iters: 1118, time: 0.217, data: 0.002) G_GAN: 1.526 G_L1: 0.482 D_real: 0.350 D_fake: 0.379 \n",
      "(epoch: 134, iters: 1218, time: 0.292, data: 0.003) G_GAN: 0.932 G_L1: 0.232 D_real: 0.597 D_fake: 0.621 \n",
      "(epoch: 134, iters: 1318, time: 0.221, data: 0.002) G_GAN: 0.942 G_L1: 0.240 D_real: 0.466 D_fake: 0.717 \n",
      "(epoch: 134, iters: 1418, time: 0.219, data: 0.002) G_GAN: 1.088 G_L1: 0.204 D_real: 0.357 D_fake: 0.511 \n",
      "(epoch: 134, iters: 1518, time: 0.216, data: 0.002) G_GAN: 1.127 G_L1: 0.173 D_real: 0.644 D_fake: 0.590 \n",
      "(epoch: 134, iters: 1618, time: 0.288, data: 0.002) G_GAN: 1.125 G_L1: 0.172 D_real: 0.722 D_fake: 0.434 \n",
      "End of epoch 134 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000131 -> 0.0000129\n",
      "(epoch: 135, iters: 95, time: 0.224, data: 0.002) G_GAN: 0.983 G_L1: 0.123 D_real: 0.352 D_fake: 0.550 \n",
      "(epoch: 135, iters: 195, time: 0.218, data: 0.002) G_GAN: 0.940 G_L1: 0.321 D_real: 0.543 D_fake: 0.620 \n",
      "(epoch: 135, iters: 295, time: 0.222, data: 0.002) G_GAN: 0.992 G_L1: 0.266 D_real: 0.108 D_fake: 0.839 \n",
      "(epoch: 135, iters: 395, time: 0.685, data: 0.002) G_GAN: 1.392 G_L1: 0.408 D_real: 0.004 D_fake: 0.423 \n",
      "(epoch: 135, iters: 495, time: 0.222, data: 0.002) G_GAN: 0.915 G_L1: 0.333 D_real: 1.653 D_fake: 0.701 \n",
      "(epoch: 135, iters: 595, time: 0.220, data: 0.002) G_GAN: 0.901 G_L1: 0.246 D_real: 0.566 D_fake: 0.619 \n",
      "(epoch: 135, iters: 695, time: 0.220, data: 0.003) G_GAN: 1.218 G_L1: 0.133 D_real: 0.867 D_fake: 0.486 \n",
      "(epoch: 135, iters: 795, time: 0.290, data: 0.002) G_GAN: 0.450 G_L1: 0.272 D_real: 0.685 D_fake: 1.440 \n",
      "(epoch: 135, iters: 895, time: 0.216, data: 0.002) G_GAN: 0.701 G_L1: 0.169 D_real: 0.552 D_fake: 0.827 \n",
      "(epoch: 135, iters: 995, time: 0.225, data: 0.002) G_GAN: 1.286 G_L1: 0.186 D_real: 0.374 D_fake: 0.445 \n",
      "(epoch: 135, iters: 1095, time: 0.216, data: 0.003) G_GAN: 1.259 G_L1: 0.499 D_real: 0.018 D_fake: 0.415 \n",
      "(epoch: 135, iters: 1195, time: 0.656, data: 0.002) G_GAN: 1.113 G_L1: 0.312 D_real: 0.087 D_fake: 0.552 \n",
      "(epoch: 135, iters: 1295, time: 0.220, data: 0.002) G_GAN: 1.033 G_L1: 0.248 D_real: 0.594 D_fake: 0.569 \n",
      "(epoch: 135, iters: 1395, time: 0.218, data: 0.002) G_GAN: 1.044 G_L1: 0.065 D_real: 0.492 D_fake: 0.512 \n",
      "(epoch: 135, iters: 1495, time: 0.219, data: 0.002) G_GAN: 1.073 G_L1: 0.219 D_real: 0.947 D_fake: 0.559 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 135, iters: 1595, time: 0.293, data: 0.002) G_GAN: 0.741 G_L1: 0.119 D_real: 0.723 D_fake: 0.753 \n",
      "saving the model at the end of epoch 135, iters 58428\n",
      "End of epoch 135 / 200 \t Time Taken: 210 sec\n",
      "learning rate 0.0000129 -> 0.0000127\n",
      "(epoch: 136, iters: 72, time: 0.220, data: 0.002) G_GAN: 0.652 G_L1: 0.237 D_real: 0.305 D_fake: 1.060 \n",
      "(epoch: 136, iters: 172, time: 0.217, data: 0.002) G_GAN: 0.875 G_L1: 0.086 D_real: 0.534 D_fake: 0.681 \n",
      "(epoch: 136, iters: 272, time: 0.218, data: 0.002) G_GAN: 1.411 G_L1: 0.373 D_real: 0.810 D_fake: 0.324 \n",
      "(epoch: 136, iters: 372, time: 0.772, data: 0.002) G_GAN: 1.008 G_L1: 0.209 D_real: 0.433 D_fake: 0.769 \n",
      "(epoch: 136, iters: 472, time: 0.220, data: 0.002) G_GAN: 0.913 G_L1: 0.362 D_real: 0.346 D_fake: 0.622 \n",
      "(epoch: 136, iters: 572, time: 0.223, data: 0.002) G_GAN: 0.894 G_L1: 0.375 D_real: 0.118 D_fake: 0.739 \n",
      "(epoch: 136, iters: 672, time: 0.221, data: 0.002) G_GAN: 0.981 G_L1: 0.154 D_real: 0.861 D_fake: 0.498 \n",
      "(epoch: 136, iters: 772, time: 0.287, data: 0.002) G_GAN: 0.627 G_L1: 0.257 D_real: 0.870 D_fake: 1.158 \n",
      "(epoch: 136, iters: 872, time: 0.221, data: 0.002) G_GAN: 1.063 G_L1: 0.865 D_real: 0.007 D_fake: 0.598 \n",
      "(epoch: 136, iters: 972, time: 0.218, data: 0.001) G_GAN: 1.233 G_L1: 0.101 D_real: 0.235 D_fake: 0.442 \n",
      "(epoch: 136, iters: 1072, time: 0.219, data: 0.001) G_GAN: 1.726 G_L1: 0.379 D_real: 0.048 D_fake: 0.288 \n",
      "(epoch: 136, iters: 1172, time: 0.286, data: 0.003) G_GAN: 1.125 G_L1: 0.264 D_real: 0.399 D_fake: 0.545 \n",
      "(epoch: 136, iters: 1272, time: 0.216, data: 0.003) G_GAN: 0.833 G_L1: 0.221 D_real: 0.394 D_fake: 0.850 \n",
      "(epoch: 136, iters: 1372, time: 0.214, data: 0.001) G_GAN: 1.284 G_L1: 0.351 D_real: 0.211 D_fake: 0.469 \n",
      "(epoch: 136, iters: 1472, time: 0.219, data: 0.003) G_GAN: 1.729 G_L1: 0.190 D_real: 1.784 D_fake: 0.172 \n",
      "(epoch: 136, iters: 1572, time: 0.663, data: 0.003) G_GAN: 0.788 G_L1: 0.151 D_real: 0.831 D_fake: 0.687 \n",
      "saving the latest model (epoch 136, total_iters 60000)\n",
      "End of epoch 136 / 200 \t Time Taken: 207 sec\n",
      "learning rate 0.0000127 -> 0.0000125\n",
      "(epoch: 137, iters: 49, time: 0.223, data: 0.002) G_GAN: 0.689 G_L1: 0.289 D_real: 0.616 D_fake: 1.586 \n",
      "(epoch: 137, iters: 149, time: 0.219, data: 0.002) G_GAN: 0.976 G_L1: 0.335 D_real: 0.406 D_fake: 0.689 \n",
      "(epoch: 137, iters: 249, time: 0.215, data: 0.002) G_GAN: 1.184 G_L1: 0.259 D_real: 0.544 D_fake: 0.450 \n",
      "(epoch: 137, iters: 349, time: 0.678, data: 0.001) G_GAN: 1.074 G_L1: 0.390 D_real: 0.597 D_fake: 0.472 \n",
      "(epoch: 137, iters: 449, time: 0.214, data: 0.002) G_GAN: 0.805 G_L1: 0.286 D_real: 0.640 D_fake: 0.867 \n",
      "(epoch: 137, iters: 549, time: 0.223, data: 0.002) G_GAN: 0.986 G_L1: 0.186 D_real: 0.458 D_fake: 0.563 \n",
      "(epoch: 137, iters: 649, time: 0.216, data: 0.003) G_GAN: 0.957 G_L1: 0.101 D_real: 0.721 D_fake: 0.618 \n",
      "(epoch: 137, iters: 749, time: 0.286, data: 0.001) G_GAN: 1.582 G_L1: 0.281 D_real: 0.531 D_fake: 0.258 \n",
      "(epoch: 137, iters: 849, time: 0.218, data: 0.002) G_GAN: 0.754 G_L1: 0.146 D_real: 0.559 D_fake: 0.769 \n",
      "(epoch: 137, iters: 949, time: 0.220, data: 0.002) G_GAN: 1.189 G_L1: 0.311 D_real: 0.391 D_fake: 0.619 \n",
      "(epoch: 137, iters: 1049, time: 0.217, data: 0.001) G_GAN: 1.662 G_L1: 0.251 D_real: 0.014 D_fake: 0.293 \n",
      "(epoch: 137, iters: 1149, time: 0.299, data: 0.002) G_GAN: 0.899 G_L1: 0.197 D_real: 0.704 D_fake: 0.682 \n",
      "(epoch: 137, iters: 1249, time: 0.221, data: 0.002) G_GAN: 1.752 G_L1: 0.333 D_real: 1.064 D_fake: 0.236 \n",
      "(epoch: 137, iters: 1349, time: 0.217, data: 0.002) G_GAN: 1.319 G_L1: 0.288 D_real: 0.029 D_fake: 0.598 \n",
      "(epoch: 137, iters: 1449, time: 0.222, data: 0.003) G_GAN: 1.287 G_L1: 0.235 D_real: 1.141 D_fake: 0.299 \n",
      "(epoch: 137, iters: 1549, time: 0.292, data: 0.003) G_GAN: 1.073 G_L1: 0.104 D_real: 0.626 D_fake: 0.472 \n",
      "End of epoch 137 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000125 -> 0.0000123\n",
      "(epoch: 138, iters: 26, time: 0.222, data: 0.002) G_GAN: 0.657 G_L1: 0.174 D_real: 0.236 D_fake: 1.054 \n",
      "(epoch: 138, iters: 126, time: 0.221, data: 0.002) G_GAN: 1.108 G_L1: 0.197 D_real: 0.546 D_fake: 0.464 \n",
      "(epoch: 138, iters: 226, time: 0.216, data: 0.002) G_GAN: 1.756 G_L1: 0.355 D_real: 0.020 D_fake: 0.237 \n",
      "(epoch: 138, iters: 326, time: 0.675, data: 0.001) G_GAN: 0.944 G_L1: 0.278 D_real: 1.045 D_fake: 0.549 \n",
      "(epoch: 138, iters: 426, time: 0.227, data: 0.003) G_GAN: 1.158 G_L1: 0.119 D_real: 0.228 D_fake: 0.526 \n",
      "(epoch: 138, iters: 526, time: 0.216, data: 0.002) G_GAN: 1.009 G_L1: 0.355 D_real: 0.513 D_fake: 0.653 \n",
      "(epoch: 138, iters: 626, time: 0.218, data: 0.001) G_GAN: 1.407 G_L1: 0.373 D_real: 0.600 D_fake: 0.319 \n",
      "(epoch: 138, iters: 726, time: 0.310, data: 0.001) G_GAN: 1.644 G_L1: 0.454 D_real: 0.151 D_fake: 0.262 \n",
      "(epoch: 138, iters: 826, time: 0.219, data: 0.001) G_GAN: 1.177 G_L1: 0.246 D_real: 0.534 D_fake: 0.411 \n",
      "(epoch: 138, iters: 926, time: 0.225, data: 0.003) G_GAN: 0.891 G_L1: 0.262 D_real: 0.450 D_fake: 0.681 \n",
      "(epoch: 138, iters: 1026, time: 0.219, data: 0.002) G_GAN: 1.105 G_L1: 0.185 D_real: 0.887 D_fake: 0.457 \n",
      "(epoch: 138, iters: 1126, time: 0.298, data: 0.003) G_GAN: 0.934 G_L1: 0.205 D_real: 0.468 D_fake: 0.633 \n",
      "(epoch: 138, iters: 1226, time: 0.219, data: 0.002) G_GAN: 0.927 G_L1: 0.172 D_real: 0.560 D_fake: 0.577 \n",
      "(epoch: 138, iters: 1326, time: 0.217, data: 0.001) G_GAN: 1.366 G_L1: 0.157 D_real: 1.119 D_fake: 0.309 \n",
      "(epoch: 138, iters: 1426, time: 0.217, data: 0.002) G_GAN: 1.178 G_L1: 0.361 D_real: 0.509 D_fake: 0.584 \n",
      "(epoch: 138, iters: 1526, time: 0.289, data: 0.002) G_GAN: 1.233 G_L1: 0.426 D_real: 0.158 D_fake: 0.546 \n",
      "End of epoch 138 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000123 -> 0.0000121\n",
      "(epoch: 139, iters: 3, time: 0.220, data: 0.002) G_GAN: 1.120 G_L1: 0.146 D_real: 0.650 D_fake: 0.463 \n",
      "(epoch: 139, iters: 103, time: 0.220, data: 0.001) G_GAN: 1.203 G_L1: 0.127 D_real: 0.911 D_fake: 0.385 \n",
      "(epoch: 139, iters: 203, time: 0.225, data: 0.002) G_GAN: 1.278 G_L1: 0.170 D_real: 0.964 D_fake: 0.338 \n",
      "(epoch: 139, iters: 303, time: 0.710, data: 0.002) G_GAN: 1.302 G_L1: 0.195 D_real: 0.059 D_fake: 0.441 \n",
      "(epoch: 139, iters: 403, time: 0.220, data: 0.002) G_GAN: 0.744 G_L1: 0.170 D_real: 0.339 D_fake: 0.839 \n",
      "(epoch: 139, iters: 503, time: 0.221, data: 0.002) G_GAN: 1.724 G_L1: 0.334 D_real: 0.632 D_fake: 0.288 \n",
      "(epoch: 139, iters: 603, time: 0.222, data: 0.002) G_GAN: 1.001 G_L1: 0.089 D_real: 1.011 D_fake: 0.466 \n",
      "(epoch: 139, iters: 703, time: 0.808, data: 0.002) G_GAN: 1.246 G_L1: 0.181 D_real: 0.627 D_fake: 0.403 \n",
      "(epoch: 139, iters: 803, time: 0.224, data: 0.003) G_GAN: 1.051 G_L1: 0.130 D_real: 0.811 D_fake: 0.512 \n",
      "(epoch: 139, iters: 903, time: 0.222, data: 0.002) G_GAN: 1.259 G_L1: 0.230 D_real: 0.949 D_fake: 0.338 \n",
      "(epoch: 139, iters: 1003, time: 0.224, data: 0.002) G_GAN: 1.273 G_L1: 0.188 D_real: 0.587 D_fake: 0.385 \n",
      "(epoch: 139, iters: 1103, time: 0.289, data: 0.002) G_GAN: 1.464 G_L1: 0.361 D_real: 1.262 D_fake: 0.304 \n",
      "(epoch: 139, iters: 1203, time: 0.221, data: 0.002) G_GAN: 1.144 G_L1: 0.429 D_real: 0.551 D_fake: 0.526 \n",
      "(epoch: 139, iters: 1303, time: 0.218, data: 0.001) G_GAN: 0.711 G_L1: 0.155 D_real: 0.558 D_fake: 0.820 \n",
      "(epoch: 139, iters: 1403, time: 0.222, data: 0.002) G_GAN: 1.230 G_L1: 0.154 D_real: 0.667 D_fake: 0.376 \n",
      "(epoch: 139, iters: 1503, time: 0.290, data: 0.002) G_GAN: 1.005 G_L1: 0.124 D_real: 0.868 D_fake: 0.500 \n",
      "(epoch: 139, iters: 1603, time: 0.220, data: 0.002) G_GAN: 1.250 G_L1: 0.274 D_real: 0.136 D_fake: 0.447 \n",
      "End of epoch 139 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000121 -> 0.0000119\n",
      "(epoch: 140, iters: 80, time: 0.221, data: 0.003) G_GAN: 0.911 G_L1: 0.213 D_real: 0.696 D_fake: 0.871 \n",
      "saving the latest model (epoch 140, total_iters 65000)\n",
      "(epoch: 140, iters: 180, time: 0.219, data: 0.002) G_GAN: 1.329 G_L1: 0.250 D_real: 0.348 D_fake: 0.340 \n",
      "(epoch: 140, iters: 280, time: 0.683, data: 0.002) G_GAN: 1.203 G_L1: 0.229 D_real: 0.718 D_fake: 0.448 \n",
      "(epoch: 140, iters: 380, time: 0.220, data: 0.002) G_GAN: 0.910 G_L1: 0.151 D_real: 0.773 D_fake: 0.605 \n",
      "(epoch: 140, iters: 480, time: 0.221, data: 0.002) G_GAN: 0.911 G_L1: 0.213 D_real: 0.761 D_fake: 0.698 \n",
      "(epoch: 140, iters: 580, time: 0.220, data: 0.001) G_GAN: 1.304 G_L1: 0.162 D_real: 0.564 D_fake: 0.401 \n",
      "(epoch: 140, iters: 680, time: 0.298, data: 0.003) G_GAN: 1.119 G_L1: 0.476 D_real: 0.679 D_fake: 0.491 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 140, iters: 780, time: 0.222, data: 0.002) G_GAN: 1.721 G_L1: 0.254 D_real: 0.081 D_fake: 0.271 \n",
      "(epoch: 140, iters: 880, time: 0.216, data: 0.003) G_GAN: 0.921 G_L1: 0.410 D_real: 0.064 D_fake: 0.824 \n",
      "(epoch: 140, iters: 980, time: 0.218, data: 0.002) G_GAN: 1.225 G_L1: 0.181 D_real: 0.271 D_fake: 0.439 \n",
      "(epoch: 140, iters: 1080, time: 0.682, data: 0.002) G_GAN: 1.488 G_L1: 0.384 D_real: 0.775 D_fake: 0.303 \n",
      "(epoch: 140, iters: 1180, time: 0.220, data: 0.002) G_GAN: 0.697 G_L1: 0.091 D_real: 0.478 D_fake: 0.817 \n",
      "(epoch: 140, iters: 1280, time: 0.220, data: 0.002) G_GAN: 1.019 G_L1: 0.159 D_real: 0.892 D_fake: 0.528 \n",
      "(epoch: 140, iters: 1380, time: 0.218, data: 0.002) G_GAN: 1.167 G_L1: 0.214 D_real: 0.145 D_fake: 0.507 \n",
      "(epoch: 140, iters: 1480, time: 0.284, data: 0.003) G_GAN: 0.914 G_L1: 0.309 D_real: 1.013 D_fake: 0.666 \n",
      "(epoch: 140, iters: 1580, time: 0.222, data: 0.003) G_GAN: 0.971 G_L1: 0.192 D_real: 0.694 D_fake: 0.628 \n",
      "saving the model at the end of epoch 140, iters 66543\n",
      "End of epoch 140 / 200 \t Time Taken: 212 sec\n",
      "learning rate 0.0000119 -> 0.0000117\n",
      "(epoch: 141, iters: 57, time: 0.216, data: 0.003) G_GAN: 1.141 G_L1: 0.151 D_real: 0.678 D_fake: 0.442 \n",
      "(epoch: 141, iters: 157, time: 0.216, data: 0.001) G_GAN: 1.498 G_L1: 0.339 D_real: 1.042 D_fake: 0.277 \n",
      "(epoch: 141, iters: 257, time: 0.681, data: 0.001) G_GAN: 1.125 G_L1: 0.219 D_real: 0.024 D_fake: 0.676 \n",
      "(epoch: 141, iters: 357, time: 0.217, data: 0.002) G_GAN: 1.146 G_L1: 0.328 D_real: 0.739 D_fake: 0.491 \n",
      "(epoch: 141, iters: 457, time: 0.221, data: 0.002) G_GAN: 0.969 G_L1: 0.199 D_real: 1.016 D_fake: 0.552 \n",
      "(epoch: 141, iters: 557, time: 0.216, data: 0.001) G_GAN: 1.319 G_L1: 0.198 D_real: 0.581 D_fake: 0.391 \n",
      "(epoch: 141, iters: 657, time: 0.299, data: 0.001) G_GAN: 1.021 G_L1: 0.441 D_real: 0.469 D_fake: 0.526 \n",
      "(epoch: 141, iters: 757, time: 0.220, data: 0.002) G_GAN: 0.902 G_L1: 0.411 D_real: 0.375 D_fake: 0.637 \n",
      "(epoch: 141, iters: 857, time: 0.217, data: 0.002) G_GAN: 1.345 G_L1: 0.167 D_real: 0.759 D_fake: 0.356 \n",
      "(epoch: 141, iters: 957, time: 0.220, data: 0.001) G_GAN: 1.169 G_L1: 0.256 D_real: 0.903 D_fake: 0.429 \n",
      "(epoch: 141, iters: 1057, time: 0.294, data: 0.001) G_GAN: 1.348 G_L1: 0.250 D_real: 0.588 D_fake: 0.320 \n",
      "(epoch: 141, iters: 1157, time: 0.220, data: 0.002) G_GAN: 1.367 G_L1: 0.303 D_real: 0.368 D_fake: 0.359 \n",
      "(epoch: 141, iters: 1257, time: 0.217, data: 0.001) G_GAN: 0.887 G_L1: 0.255 D_real: 0.473 D_fake: 1.048 \n",
      "(epoch: 141, iters: 1357, time: 0.220, data: 0.002) G_GAN: 0.911 G_L1: 0.157 D_real: 0.601 D_fake: 0.641 \n",
      "(epoch: 141, iters: 1457, time: 0.828, data: 0.002) G_GAN: 1.037 G_L1: 0.098 D_real: 0.390 D_fake: 0.535 \n",
      "(epoch: 141, iters: 1557, time: 0.219, data: 0.003) G_GAN: 0.813 G_L1: 0.158 D_real: 0.583 D_fake: 0.755 \n",
      "End of epoch 141 / 200 \t Time Taken: 205 sec\n",
      "learning rate 0.0000117 -> 0.0000115\n",
      "(epoch: 142, iters: 34, time: 0.224, data: 0.002) G_GAN: 0.896 G_L1: 0.147 D_real: 0.878 D_fake: 0.723 \n",
      "(epoch: 142, iters: 134, time: 0.220, data: 0.002) G_GAN: 1.342 G_L1: 0.139 D_real: 0.828 D_fake: 0.303 \n",
      "(epoch: 142, iters: 234, time: 0.682, data: 0.002) G_GAN: 1.205 G_L1: 0.217 D_real: 0.590 D_fake: 0.395 \n",
      "(epoch: 142, iters: 334, time: 0.219, data: 0.002) G_GAN: 0.876 G_L1: 0.347 D_real: 0.239 D_fake: 0.825 \n",
      "(epoch: 142, iters: 434, time: 0.216, data: 0.001) G_GAN: 1.483 G_L1: 0.212 D_real: 0.586 D_fake: 0.287 \n",
      "(epoch: 142, iters: 534, time: 0.217, data: 0.001) G_GAN: 0.673 G_L1: 0.196 D_real: 0.885 D_fake: 1.042 \n",
      "(epoch: 142, iters: 634, time: 0.297, data: 0.003) G_GAN: 1.286 G_L1: 0.255 D_real: 0.571 D_fake: 0.388 \n",
      "(epoch: 142, iters: 734, time: 0.221, data: 0.002) G_GAN: 0.525 G_L1: 0.146 D_real: 0.556 D_fake: 1.128 \n",
      "(epoch: 142, iters: 834, time: 0.221, data: 0.001) G_GAN: 0.981 G_L1: 0.316 D_real: 0.221 D_fake: 0.725 \n",
      "(epoch: 142, iters: 934, time: 0.216, data: 0.002) G_GAN: 0.825 G_L1: 0.177 D_real: 0.360 D_fake: 0.728 \n",
      "(epoch: 142, iters: 1034, time: 0.294, data: 0.002) G_GAN: 1.328 G_L1: 0.356 D_real: 0.693 D_fake: 0.395 \n",
      "(epoch: 142, iters: 1134, time: 0.223, data: 0.002) G_GAN: 0.923 G_L1: 0.293 D_real: 0.338 D_fake: 1.027 \n",
      "(epoch: 142, iters: 1234, time: 0.217, data: 0.002) G_GAN: 1.329 G_L1: 0.402 D_real: 0.183 D_fake: 0.408 \n",
      "(epoch: 142, iters: 1334, time: 0.218, data: 0.002) G_GAN: 1.296 G_L1: 0.155 D_real: 0.733 D_fake: 0.340 \n",
      "(epoch: 142, iters: 1434, time: 0.297, data: 0.001) G_GAN: 1.265 G_L1: 0.230 D_real: 0.749 D_fake: 0.420 \n",
      "(epoch: 142, iters: 1534, time: 0.220, data: 0.002) G_GAN: 1.485 G_L1: 0.281 D_real: 0.022 D_fake: 0.322 \n",
      "End of epoch 142 / 200 \t Time Taken: 204 sec\n",
      "learning rate 0.0000115 -> 0.0000113\n",
      "(epoch: 143, iters: 11, time: 0.226, data: 0.001) G_GAN: 0.956 G_L1: 0.319 D_real: 0.678 D_fake: 0.696 \n",
      "(epoch: 143, iters: 111, time: 0.219, data: 0.002) G_GAN: 0.732 G_L1: 0.211 D_real: 0.842 D_fake: 0.817 \n",
      "(epoch: 143, iters: 211, time: 0.704, data: 0.001) G_GAN: 1.276 G_L1: 0.186 D_real: 0.054 D_fake: 0.407 \n",
      "saving the latest model (epoch 143, total_iters 70000)\n",
      "(epoch: 143, iters: 311, time: 0.218, data: 0.002) G_GAN: 1.186 G_L1: 0.258 D_real: 1.240 D_fake: 0.441 \n",
      "(epoch: 143, iters: 411, time: 0.218, data: 0.002) G_GAN: 1.040 G_L1: 0.184 D_real: 0.630 D_fake: 0.491 \n",
      "(epoch: 143, iters: 511, time: 0.216, data: 0.002) G_GAN: 1.856 G_L1: 0.132 D_real: 0.229 D_fake: 0.224 \n",
      "(epoch: 143, iters: 611, time: 0.306, data: 0.002) G_GAN: 0.868 G_L1: 0.177 D_real: 1.018 D_fake: 0.676 \n",
      "(epoch: 143, iters: 711, time: 0.219, data: 0.002) G_GAN: 1.283 G_L1: 0.230 D_real: 0.822 D_fake: 0.359 \n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot /users/riya/race/gandataset --continue_train --epoch_count 100 --batch_size 1 --lambda_L1 1.0 --lr .00002 --name raceGAN_final5 --display_port 8100 --model pix2pix --gpu_ids 3,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a8481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
