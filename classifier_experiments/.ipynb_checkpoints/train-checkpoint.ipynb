{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cc1365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.60.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.24.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.9)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (2.1.0)\n",
      "Installing collected packages: skorch\n",
      "Successfully installed skorch-0.11.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762b1823",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp36-cp36m-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1982.2 MB 4.1 kB/s eta 0:00:011  |█                               | 61.6 MB 8.6 MB/s eta 0:03:44     |█████▌                          | 342.8 MB 10.5 MB/s eta 0:02:36     |██████████████████████▌         | 1393.1 MB 9.6 MB/s eta 0:01:02     |█████████████████████████████▉  | 1847.7 MB 8.6 MB/s eta 0:00:16\n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp36-cp36m-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.6 MB 144 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.8.0+cu111) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.9.0+cu111) (8.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0.dev20210415+cu101\n",
      "    Uninstalling torch-1.9.0.dev20210415+cu101:\n",
      "      Successfully uninstalled torch-1.9.0.dev20210415+cu101\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.10.0.dev20210510+cu101\n",
      "    Uninstalling torchvision-0.10.0.dev20210510+cu101:\n",
      "      Successfully uninstalled torchvision-0.10.0.dev20210510+cu101\n",
      "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1888ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.morphology import skeletonize\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import LRScheduler, Checkpoint, EpochScoring, EarlyStopping\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5d3557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 12 04:18:32 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K80           Off  | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   24C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla K80           Off  | 00000000:85:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla K80           Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   24C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893038fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/experimental/loss_scale.py:208: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_69 (ZeroPadding2 (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_69[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_70 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_70[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_71 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_71[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_72 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_72[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_73 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_73[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_74 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_74[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_75 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_75[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_76 (ZeroPadding2 (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_76[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_77 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_77[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_78 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_78[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_79 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_79[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_80 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_80[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_81 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_81[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_82 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_82[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_83 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_83[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_84 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_84[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_85 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_85[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_86 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_86[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_87 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_87[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_88 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_88[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_89 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_89[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 16, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_90 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_90[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_91 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_91[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 16, 16, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_92[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_93[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 16, 16, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_94[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_95[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 16, 16, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_96[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_97[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_98[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_99[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_100[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_101[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 8, 8, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_logits (Dense)            (None, 2)            1026        global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 2)            0           dense_logits[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 21,303,499\n",
      "Trainable params: 21,288,133\n",
      "Non-trainable params: 15,366\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "segmentation_classifier = keras.models.load_model('models/MIMIC-256x25680-20-split-resnet-Float16_2-race_detection_rop_seg_data_rop_seg-0.001_20220321-054140_epoch:011.hdf5')\n",
    "segmentation_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509dbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in one place, running in another directory\n",
    "# code is to be run in below directory\n",
    "\n",
    "os.chdir(\"/users/riya/race/classifier_experiments/CNN_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeced42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset  outputs\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270716f",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "We'll try a 70/10/20 split (train/val/test). We don't have access to info outside of black/white, so we'll just do a simple split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_data = pd.read_csv(\"/users/riya/race/csv/image_race_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ebf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(race_data['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279dfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1709 / (1709 + 2837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdcd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    \n",
    "    csv_path = \"/users/riya/race/csv/image_race_data.csv\"\n",
    "    data_path = \"/users/riya/race/dataset/segmentations/\"\n",
    "    save_path = \"/users/riya/race/classifier_experiments/CNN_train/dataset/\"\n",
    "    \n",
    "    race_data = pd.read_csv(csv_path)\n",
    "    race_data['stratify'] = race_data['race'] + '_' + race_data['variable'] \n",
    "    # new column so I can account for both variable and race in my stratification\n",
    "    \n",
    "    ratio_train = 0.7\n",
    "    ratio_val = 0.1\n",
    "    ratio_test = 0.2\n",
    "    \n",
    "    # split into 80% train and val, 20% test\n",
    "    \n",
    "    X_intermediate, X_test, y_intermediate, y_test = train_test_split(race_data, race_data['race'], test_size=ratio_test, \n",
    "                                                        stratify = race_data['stratify'], random_state=86)\n",
    "    \n",
    "    ratio_remaining = 1 - ratio_test\n",
    "    ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "    \n",
    "    # split into 70% train and 10% val\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_intermediate, X_intermediate['race'], test_size=ratio_val_adjusted, \n",
    "                                                        stratify = X_intermediate['stratify'], random_state=86)\n",
    "\n",
    "    \n",
    "    def populate_folders(data_df, data_type):\n",
    "    \n",
    "        for i in tqdm(range(len(data_df))):\n",
    "            data_df.reset_index(drop=True, inplace=True)\n",
    "            img_id = data_df['image_id'][i]\n",
    "            race = data_df['race'][i]\n",
    "\n",
    "            img = np.array(Image.open(data_path + str(img_id) + '.bmp'))\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "            img.save(save_path + str(data_type) + '/' + str(race) + '/' + str(img_id) + '.bmp')\n",
    "    \n",
    "    populate_folders(X_train, 'train')\n",
    "    populate_folders(X_val, 'val')\n",
    "    populate_folders(X_test, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22853a22",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5662523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e1c42",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f43e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already done this, before I saved my images\n",
    "# Yay, we did the same thing, repeating the image thrice to create the three layers. I can just do that part.\n",
    "\n",
    "# Oh, I see. Rather than saving ALL the images (as I wrongly did), it's so much easier to just make them in the train code!\n",
    "\n",
    "# depending on the inputs, I can run this code 8 times to train this model. It'll be easy to train at that point!\n",
    "\n",
    "def shadow_regions(img, skeleton, shadow, radius, region, image_size = (224, 224)):\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    \n",
    "    # defining channel which will be duplicated late (in case it's not already with Image Folder??)\n",
    "    channel = img[:,:,0]\n",
    "\n",
    "    if skeleton is True:\n",
    "        # can binarize all 3 channels, but will go 1 at a time\n",
    "        channel[channel > 0] = 255       \n",
    "        modified_img = skeletonize(channel, method='lee')\n",
    "    \n",
    "    if shadow is True:\n",
    "        # developing mask that darkens center portion\n",
    "        center_mask = np.full(image_size, 255, dtype=np.uint8) \n",
    "        # radius i changes, center, color, fill is the same\n",
    "        cv2.circle(center_mask, (int(image_size[0]/2), int(image_size[0]/2)), radius, (0, 0, 0), -1)\n",
    "\n",
    "        # developing mask that darkens background region\n",
    "        back_mask = cv2.bitwise_not(center_mask)\n",
    "\n",
    "        if (region == 'dark_center'):\n",
    "            modified_img = cv2.bitwise_or(channel, channel, mask=center_mask)\n",
    "\n",
    "        if (region == 'dark_background'):\n",
    "            modified_img = cv2.bitwise_or(channel, channel, mask=back_mask)\n",
    "    \n",
    "    if skeleton is not True and shadow is not True: # if condition here for clarity     \n",
    "        modified_img = channel\n",
    "        \n",
    "    img[:,:,0] = modified_img\n",
    "    img[:,:,1] = modified_img\n",
    "    img[:,:,2] = modified_img\n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678e451",
   "metadata": {},
   "source": [
    "Options for different saving:\n",
    "1. Skeleton = True,\n",
    "    Shadow = True then\n",
    "    Region has two options \n",
    "    Radius has two options\n",
    "2. Original Training: shadow = False & Skeleton = False\n",
    "3. no skeletonization training: Skeleton = false & Shadow = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46264722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.array(Image.open(\"/users/riya/race/dataset/segmentations/\" + str(7571) + '.bmp'))\n",
    "img = Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, interpolation = 'nearest', cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b271ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img_arr, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.repeat(img[:, :, np.newaxis], 3, axis=2).reshape((image_size[0],image_size[1],3)) # (1, 224, 224, 3)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0ff40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2419fde",
   "metadata": {},
   "source": [
    "### Train Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a6845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, radius, region, skeleton=False, shadow = False, num_classes=2, batch_size=64, num_epochs=10, lr=0.001):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") # \n",
    "    if device == 'cuda:1': # using all available gpus\n",
    "        torch.cuda.empty_cache()\n",
    "    if skeleton is True: # Experiment #2: skeleton true, shadow true\n",
    "        shadow = True\n",
    "        f_params = f'./outputs/checkpoints/model_shadow_regions_{region}_{radius}_skeletonized.pt'\n",
    "        f_history = f'./outputs/histories/model_shadow_regions_{region}_{radius}_skeletonized.json'\n",
    "        csv_name = f'./outputs/probabilities/shadow_regions_{region}_{radius}_skeletonized.csv'\n",
    "    elif shadow is True: # Experiment #3: skeleton false, shadow true\n",
    "        f_params = f'./outputs/checkpoints/model_shadow_regions_{region}_{radius}.pt'\n",
    "        f_history = f'./outputs/histories/model_shadow_regions_{region}_{radius}.json'\n",
    "        csv_name = f'./outputs/probabilities/shadow_regions_{region}_{radius}.csv'\n",
    "    else: # Original training: skeleton false, shadow false\n",
    "        f_params = f'./outputs/checkpoints/model_original.pt'\n",
    "        f_history = f'./outputs/histories/model_original.json'\n",
    "        csv_name = f'./outputs/probabilities/original.csv'\n",
    "        \n",
    "    train_transforms = transforms.Compose([transforms.Lambda(lambda img: shadow_regions(img, skeleton,\n",
    "                                                                                shadow, radius,\n",
    "                                                                                region)), # image size pre-defined\n",
    "                                           # transforms.Resize(image_size),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.RandomVerticalFlip(),\n",
    "                                           transforms.RandomRotation(25),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                                [0.5, 0.5, 0.5])]) # why this normalizing?\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.Lambda(lambda img: shadow_regions(img, skeleton,\n",
    "                                                                                shadow, radius,\n",
    "                                                                                region)),\n",
    "                                          # transforms.Resize(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                               [0.5, 0.5, 0.5])])\n",
    "\n",
    "    train_folder = os.path.join(data_dir, 'train') # only training on segmentations      \n",
    "    val_folder = os.path.join(data_dir, 'val')\n",
    "    test_folder = os.path.join(data_dir, 'test')\n",
    "\n",
    "    # I guess this automatically creates 3 channels\n",
    "    train_dataset = datasets.ImageFolder(train_folder, train_transforms)\n",
    "    val_dataset = datasets.ImageFolder(val_folder, test_transforms)\n",
    "    test_dataset = datasets.ImageFolder(test_folder, test_transforms)\n",
    "\n",
    "    \n",
    "    labels = np.array(train_dataset.samples)[:,1]\n",
    "    \n",
    "    # what even does the below code do?    \n",
    "    labels = labels.astype(int)\n",
    "    black_weight = 1 / len(labels[labels == 0])\n",
    "    white_weight = 1 / len(labels[labels == 1])\n",
    "    sample_weights = np.array([black_weight, white_weight])\n",
    "    weights = sample_weights[labels]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
    "\n",
    "    print()\n",
    "    print(f'Data Directory: {data_dir}')\n",
    "    print(f'Skeletonize: {skeleton}')\n",
    "    print(f'Shadow: {shadow}')\n",
    "    print(f'Number of Classes: {num_classes}')\n",
    "    print(f'Number of black eyes: {len(labels[labels == 0])}')\n",
    "    print(f'Number of white eyes: {len(labels[labels == 1])}')\n",
    "    print(f'Batch Size: {batch_size}')\n",
    "    print(f'Number of Epochs: {num_epochs}')\n",
    "    print(f'Initial Learning Rate: {lr}')\n",
    "    print(f'Device: {device}')\n",
    "    print()\n",
    "\n",
    "    # maybe increase size of validation set??\n",
    "    \n",
    "    checkpoint = Checkpoint(monitor='valid_loss_best',\n",
    "                            f_params=f_params,\n",
    "                            f_history=f_history,\n",
    "                            f_optimizer=None,\n",
    "                            f_criterion=None)\n",
    "\n",
    "    # accuracy on train/validation?\n",
    "    \n",
    "    train_acc = EpochScoring(scoring='accuracy',\n",
    "                             on_train=True,\n",
    "                             name='train_acc',\n",
    "                             lower_is_better=False)\n",
    "\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    callbacks = [checkpoint, train_acc, early_stopping]\n",
    "\n",
    "    net = NeuralNetClassifier(PretrainedModel,\n",
    "                              criterion=nn.CrossEntropyLoss,\n",
    "                              lr=lr,\n",
    "                              batch_size=batch_size,\n",
    "                              max_epochs=num_epochs,\n",
    "                              module__output_features=num_classes,\n",
    "                              optimizer=optim.SGD,\n",
    "                              optimizer__momentum=0.9,\n",
    "                              iterator_train__num_workers=16,\n",
    "                              iterator_train__sampler=sampler,\n",
    "                              iterator_valid__shuffle=False,\n",
    "                              iterator_valid__num_workers=16,\n",
    "                              train_split=predefined_split(val_dataset),\n",
    "                              callbacks=callbacks,\n",
    "                              device=device)\n",
    "\n",
    "    net.fit(train_dataset, y=None)\n",
    "\n",
    "    img_locs = [loc for loc, _ in test_dataset.samples]\n",
    "    test_probs = net.predict_proba(test_dataset)\n",
    "    test_probs = [prob[0] for prob in test_probs]\n",
    "    data = {'img_loc' : img_locs, 'probability' : test_probs}\n",
    "    pd.DataFrame(data=data).to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14495b06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: False\n",
      "Shadow: False\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4134bc15c77e43e9839d20a3addf3cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6863\u001b[0m        \u001b[32m0.5921\u001b[0m       \u001b[35m0.7495\u001b[0m        \u001b[31m0.4688\u001b[0m     +  22.8890\n",
      "      2       \u001b[36m0.8155\u001b[0m        \u001b[32m0.4124\u001b[0m       0.7407        0.5353        21.8471\n",
      "      3       \u001b[36m0.8368\u001b[0m        \u001b[32m0.3691\u001b[0m       \u001b[35m0.8154\u001b[0m        \u001b[31m0.4002\u001b[0m     +  21.8220\n",
      "      4       \u001b[36m0.8554\u001b[0m        \u001b[32m0.3248\u001b[0m       \u001b[35m0.8242\u001b[0m        0.4030        21.9117\n",
      "      5       \u001b[36m0.8752\u001b[0m        \u001b[32m0.2868\u001b[0m       \u001b[35m0.8440\u001b[0m        \u001b[31m0.3105\u001b[0m     +  21.9440\n",
      "      6       \u001b[36m0.8790\u001b[0m        \u001b[32m0.2809\u001b[0m       0.8440        \u001b[31m0.3081\u001b[0m     +  21.9060\n",
      "      7       \u001b[36m0.8950\u001b[0m        \u001b[32m0.2489\u001b[0m       0.8396        0.3381        22.0916\n",
      "      8       0.8887        0.2568       \u001b[35m0.8681\u001b[0m        \u001b[31m0.2731\u001b[0m     +  22.0817\n",
      "      9       \u001b[36m0.9010\u001b[0m        \u001b[32m0.2324\u001b[0m       0.8659        \u001b[31m0.2625\u001b[0m     +  22.1679\n",
      "     10       \u001b[36m0.9135\u001b[0m        \u001b[32m0.2148\u001b[0m       \u001b[35m0.8879\u001b[0m        \u001b[31m0.2351\u001b[0m     +  22.0017\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: True\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6837\u001b[0m        \u001b[32m0.5850\u001b[0m       \u001b[35m0.7363\u001b[0m        \u001b[31m0.4942\u001b[0m     +  23.5086\n",
      "      2       \u001b[36m0.7793\u001b[0m        \u001b[32m0.4635\u001b[0m       \u001b[35m0.7934\u001b[0m        \u001b[31m0.4601\u001b[0m     +  23.4378\n",
      "      3       \u001b[36m0.8057\u001b[0m        \u001b[32m0.4086\u001b[0m       0.7890        \u001b[31m0.4308\u001b[0m     +  23.4742\n",
      "      4       \u001b[36m0.8321\u001b[0m        \u001b[32m0.3735\u001b[0m       \u001b[35m0.8242\u001b[0m        \u001b[31m0.4060\u001b[0m     +  23.3949\n",
      "      5       \u001b[36m0.8394\u001b[0m        \u001b[32m0.3609\u001b[0m       0.8242        \u001b[31m0.3890\u001b[0m     +  23.3588\n",
      "      6       \u001b[36m0.8620\u001b[0m        \u001b[32m0.3088\u001b[0m       \u001b[35m0.8593\u001b[0m        \u001b[31m0.3359\u001b[0m     +  23.5151\n",
      "      7       \u001b[36m0.8677\u001b[0m        \u001b[32m0.2990\u001b[0m       0.8484        0.3363        23.5275\n",
      "      8       \u001b[36m0.8787\u001b[0m        \u001b[32m0.2933\u001b[0m       0.8396        0.3490        23.4173\n",
      "      9       0.8771        \u001b[32m0.2786\u001b[0m       0.8330        0.3480        23.5975\n",
      "     10       \u001b[36m0.8796\u001b[0m        \u001b[32m0.2783\u001b[0m       0.8088        0.4034        23.4199\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: True\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6771\u001b[0m        \u001b[32m0.6050\u001b[0m       \u001b[35m0.6484\u001b[0m        \u001b[31m0.6410\u001b[0m     +  24.5032\n",
      "      2       \u001b[36m0.7020\u001b[0m        \u001b[32m0.5666\u001b[0m       \u001b[35m0.6571\u001b[0m        \u001b[31m0.6002\u001b[0m     +  23.9270\n",
      "      3       \u001b[36m0.7171\u001b[0m        \u001b[32m0.5591\u001b[0m       \u001b[35m0.6813\u001b[0m        \u001b[31m0.5661\u001b[0m     +  23.6008\n",
      "      4       \u001b[36m0.7545\u001b[0m        \u001b[32m0.5044\u001b[0m       \u001b[35m0.7055\u001b[0m        \u001b[31m0.5655\u001b[0m     +  23.5230\n",
      "      5       \u001b[36m0.7611\u001b[0m        \u001b[32m0.4939\u001b[0m       0.6879        \u001b[31m0.5590\u001b[0m     +  23.5752\n",
      "      6       \u001b[36m0.7724\u001b[0m        \u001b[32m0.4857\u001b[0m       0.7011        0.5596        23.6434\n",
      "      7       0.7639        0.4957       \u001b[35m0.7341\u001b[0m        \u001b[31m0.5071\u001b[0m     +  23.4850\n",
      "      8       \u001b[36m0.7793\u001b[0m        \u001b[32m0.4614\u001b[0m       0.7143        0.5108        23.6856\n",
      "      9       0.7759        0.4682       0.6945        0.6057        23.5981\n",
      "     10       0.7784        0.4711       \u001b[35m0.7473\u001b[0m        \u001b[31m0.4973\u001b[0m     +  23.5429\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: True\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6287\u001b[0m        \u001b[32m0.6537\u001b[0m       \u001b[35m0.6571\u001b[0m        \u001b[31m0.5914\u001b[0m     +  23.5776\n",
      "      2       \u001b[36m0.6919\u001b[0m        \u001b[32m0.5619\u001b[0m       \u001b[35m0.7011\u001b[0m        \u001b[31m0.5295\u001b[0m     +  23.7156\n",
      "      3       \u001b[36m0.7350\u001b[0m        \u001b[32m0.5176\u001b[0m       \u001b[35m0.7275\u001b[0m        0.5300        23.5803\n",
      "      4       \u001b[36m0.7469\u001b[0m        \u001b[32m0.4989\u001b[0m       0.6989        0.5798        23.8487\n",
      "      5       0.7406        0.5188       0.7011        0.5647        23.7741\n",
      "      6       \u001b[36m0.7554\u001b[0m        \u001b[32m0.4842\u001b[0m       0.7209        0.5314        23.8142\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: True\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.7202\u001b[0m        \u001b[32m0.5440\u001b[0m       \u001b[35m0.7495\u001b[0m        \u001b[31m0.5068\u001b[0m     +  23.6630\n",
      "      2       \u001b[36m0.8218\u001b[0m        \u001b[32m0.4037\u001b[0m       \u001b[35m0.7868\u001b[0m        \u001b[31m0.4244\u001b[0m     +  23.7689\n",
      "      3       \u001b[36m0.8425\u001b[0m        \u001b[32m0.3617\u001b[0m       \u001b[35m0.8286\u001b[0m        \u001b[31m0.3553\u001b[0m     +  23.7849\n",
      "      4       \u001b[36m0.8642\u001b[0m        \u001b[32m0.3081\u001b[0m       \u001b[35m0.8440\u001b[0m        0.3556        23.6635\n",
      "      5       \u001b[36m0.8661\u001b[0m        0.3169       0.8088        0.4218        23.6942\n",
      "      6       \u001b[36m0.8670\u001b[0m        \u001b[32m0.2968\u001b[0m       0.7868        0.4533        23.6383\n",
      "      7       \u001b[36m0.8714\u001b[0m        \u001b[32m0.2913\u001b[0m       0.8132        0.3987        23.7484\n",
      "      8       \u001b[36m0.8915\u001b[0m        \u001b[32m0.2648\u001b[0m       \u001b[35m0.8637\u001b[0m        \u001b[31m0.3209\u001b[0m     +  23.5344\n",
      "      9       \u001b[36m0.8925\u001b[0m        \u001b[32m0.2535\u001b[0m       0.8527        0.3213        23.7103\n",
      "     10       \u001b[36m0.9000\u001b[0m        \u001b[32m0.2431\u001b[0m       \u001b[35m0.8659\u001b[0m        \u001b[31m0.2889\u001b[0m     +  23.6440\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if not os.path.isdir(os.path.join('outputs', 'probabilities')):\n",
    "        os.makedirs(os.path.join('outputs', 'probabilities'))\n",
    "    if not os.path.isdir(os.path.join('outputs', 'checkpoints')):\n",
    "        os.makedirs(os.path.join('outputs', 'checkpoints'))\n",
    "    if not os.path.isdir(os.path.join('outputs', 'histories')):\n",
    "        os.makedirs(os.path.join('outputs', 'histories'))\n",
    "\n",
    "    data_dir = os.path.join('dataset')\n",
    "\n",
    "    train(data_dir, 0, 0)\n",
    "    \n",
    "    # training 4 skeleton + shadow models for experiment #2\n",
    "    train(data_dir, 45, 'dark_center',skeleton=True, shadow = True)\n",
    "    train(data_dir, 45, 'dark_background',skeleton=True, shadow = True)\n",
    "    train(data_dir, 90, 'dark_center',skeleton=True, shadow = True)\n",
    "    train(data_dir, 90, 'dark_background',skeleton=True, shadow = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529114dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: False\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6841\u001b[0m        \u001b[32m0.5804\u001b[0m       \u001b[35m0.7231\u001b[0m        \u001b[31m0.5297\u001b[0m     +  22.4284\n",
      "      2       \u001b[36m0.7843\u001b[0m        \u001b[32m0.4495\u001b[0m       0.6374        0.7344        22.4209\n",
      "      3       \u001b[36m0.8255\u001b[0m        \u001b[32m0.3987\u001b[0m       \u001b[35m0.7934\u001b[0m        \u001b[31m0.4313\u001b[0m     +  22.4387\n",
      "      4       \u001b[36m0.8412\u001b[0m        \u001b[32m0.3616\u001b[0m       \u001b[35m0.7956\u001b[0m        \u001b[31m0.4073\u001b[0m     +  22.3537\n",
      "      5       \u001b[36m0.8434\u001b[0m        \u001b[32m0.3474\u001b[0m       0.6484        0.8646        22.3640\n",
      "      6       0.8428        \u001b[32m0.3353\u001b[0m       \u001b[35m0.8176\u001b[0m        \u001b[31m0.3857\u001b[0m     +  22.4248\n",
      "      7       \u001b[36m0.8535\u001b[0m        \u001b[32m0.3129\u001b[0m       \u001b[35m0.8242\u001b[0m        \u001b[31m0.3743\u001b[0m     +  22.4087\n",
      "      8       \u001b[36m0.8548\u001b[0m        0.3198       \u001b[35m0.8330\u001b[0m        \u001b[31m0.3701\u001b[0m     +  22.4373\n",
      "      9       \u001b[36m0.8658\u001b[0m        \u001b[32m0.3067\u001b[0m       0.8176        0.3980        22.4508\n",
      "     10       \u001b[36m0.8802\u001b[0m        \u001b[32m0.2767\u001b[0m       0.8264        \u001b[31m0.3610\u001b[0m     +  22.3977\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: False\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6573\u001b[0m        \u001b[32m0.6165\u001b[0m       \u001b[35m0.6637\u001b[0m        \u001b[31m0.6384\u001b[0m     +  22.3884\n",
      "      2       \u001b[36m0.7023\u001b[0m        \u001b[32m0.5661\u001b[0m       0.6527        \u001b[31m0.6212\u001b[0m     +  22.4154\n",
      "      3       \u001b[36m0.7190\u001b[0m        \u001b[32m0.5455\u001b[0m       \u001b[35m0.6967\u001b[0m        \u001b[31m0.5927\u001b[0m     +  22.3734\n",
      "      4       \u001b[36m0.7369\u001b[0m        \u001b[32m0.5296\u001b[0m       \u001b[35m0.7121\u001b[0m        \u001b[31m0.5576\u001b[0m     +  22.4173\n",
      "      5       \u001b[36m0.7680\u001b[0m        \u001b[32m0.4827\u001b[0m       \u001b[35m0.7253\u001b[0m        \u001b[31m0.5413\u001b[0m     +  22.2999\n",
      "      6       0.7551        0.5062       0.7165        0.5480        22.3652\n",
      "      7       \u001b[36m0.7689\u001b[0m        \u001b[32m0.4803\u001b[0m       0.7011        \u001b[31m0.5324\u001b[0m     +  22.4808\n",
      "      8       \u001b[36m0.7765\u001b[0m        \u001b[32m0.4728\u001b[0m       \u001b[35m0.7407\u001b[0m        \u001b[31m0.5093\u001b[0m     +  22.3133\n",
      "      9       0.7711        \u001b[32m0.4632\u001b[0m       0.7187        0.5514        22.2999\n",
      "     10       \u001b[36m0.7793\u001b[0m        0.4801       \u001b[35m0.7473\u001b[0m        \u001b[31m0.4980\u001b[0m     +  22.3882\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: False\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6401\u001b[0m        \u001b[32m0.6274\u001b[0m       \u001b[35m0.6484\u001b[0m        \u001b[31m0.6130\u001b[0m     +  22.3832\n",
      "      2       \u001b[36m0.6724\u001b[0m        \u001b[32m0.5990\u001b[0m       0.6396        \u001b[31m0.5788\u001b[0m     +  22.4246\n",
      "      3       \u001b[36m0.6815\u001b[0m        \u001b[32m0.5846\u001b[0m       \u001b[35m0.6901\u001b[0m        \u001b[31m0.5602\u001b[0m     +  22.3733\n",
      "      4       \u001b[36m0.7155\u001b[0m        \u001b[32m0.5530\u001b[0m       0.6769        0.5776        22.4247\n",
      "      5       \u001b[36m0.7312\u001b[0m        \u001b[32m0.5345\u001b[0m       \u001b[35m0.7033\u001b[0m        \u001b[31m0.5323\u001b[0m     +  22.4134\n",
      "      6       0.7259        \u001b[32m0.5334\u001b[0m       \u001b[35m0.7077\u001b[0m        \u001b[31m0.5280\u001b[0m     +  22.3893\n",
      "      7       \u001b[36m0.7438\u001b[0m        \u001b[32m0.5135\u001b[0m       0.7011        0.5400        22.4341\n",
      "      8       0.7419        \u001b[32m0.4986\u001b[0m       0.7033        0.5396        22.4645\n",
      "      9       \u001b[36m0.7551\u001b[0m        \u001b[32m0.4919\u001b[0m       0.7077        0.5668        22.3715\n",
      "     10       \u001b[36m0.7557\u001b[0m        \u001b[32m0.4871\u001b[0m       0.6813        0.6489        22.4284\n",
      "\n",
      "Data Directory: dataset\n",
      "Skeletonize: False\n",
      "Shadow: True\n",
      "Number of Classes: 2\n",
      "Number of black eyes: 1197\n",
      "Number of white eyes: 1984\n",
      "Batch Size: 64\n",
      "Number of Epochs: 10\n",
      "Initial Learning Rate: 0.001\n",
      "Device: cuda:1\n",
      "\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.6753\u001b[0m        \u001b[32m0.5935\u001b[0m       \u001b[35m0.7209\u001b[0m        \u001b[31m0.5333\u001b[0m     +  22.5078\n",
      "      2       \u001b[36m0.7975\u001b[0m        \u001b[32m0.4388\u001b[0m       \u001b[35m0.7297\u001b[0m        0.5435        22.5896\n",
      "      3       \u001b[36m0.8255\u001b[0m        \u001b[32m0.3850\u001b[0m       0.6308        0.8373        22.3826\n",
      "      4       \u001b[36m0.8390\u001b[0m        \u001b[32m0.3592\u001b[0m       0.6396        0.8415        22.4450\n",
      "      5       \u001b[36m0.8626\u001b[0m        \u001b[32m0.3246\u001b[0m       0.7165        0.6342        22.4555\n",
      "      6       \u001b[36m0.8658\u001b[0m        \u001b[32m0.3223\u001b[0m       \u001b[35m0.8549\u001b[0m        \u001b[31m0.3249\u001b[0m     +  22.3850\n",
      "      7       \u001b[36m0.8727\u001b[0m        \u001b[32m0.2851\u001b[0m       0.7868        0.4406        22.4680\n",
      "      8       \u001b[36m0.8865\u001b[0m        \u001b[32m0.2781\u001b[0m       0.7363        0.5986        22.4555\n",
      "      9       \u001b[36m0.8912\u001b[0m        \u001b[32m0.2589\u001b[0m       0.8484        \u001b[31m0.3025\u001b[0m     +  22.4168\n",
      "     10       0.8890        \u001b[32m0.2585\u001b[0m       \u001b[35m0.8571\u001b[0m        \u001b[31m0.2986\u001b[0m     +  22.4255\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if not os.path.isdir(os.path.join('outputs', 'probabilities')):\n",
    "        os.makedirs(os.path.join('outputs', 'probabilities'))\n",
    "    if not os.path.isdir(os.path.join('outputs', 'checkpoints')):\n",
    "        os.makedirs(os.path.join('outputs', 'checkpoints'))\n",
    "    if not os.path.isdir(os.path.join('outputs', 'histories')):\n",
    "        os.makedirs(os.path.join('outputs', 'histories'))\n",
    "\n",
    "    data_dir = os.path.join('dataset')\n",
    "    # training 4 no skeleton + shadow models for experiment #2\n",
    "    train(data_dir, 45, 'dark_center',skeleton=False, shadow = True)\n",
    "    train(data_dir, 45, 'dark_background',skeleton=False, shadow = True)\n",
    "    train(data_dir, 90, 'dark_center',skeleton=False, shadow = True)\n",
    "    train(data_dir, 90, 'dark_background',skeleton=False, shadow = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885d969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2f5ade",
   "metadata": {},
   "source": [
    "After, try training more than 10 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e6d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e52bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
